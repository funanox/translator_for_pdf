Chapter 26Surveillance or Privacy?Experience should teach us to be most on our guard to protectliberty when the government’s purposes are beneﬁcient.
.
.
The greatest dangers to liberty lurk in insidiousencroachment by men of zeal, well meaningbut without understanding.
– Supreme Court Justice Louis BrandeisEvery thing secret degenerates, even the administration of justice;nothing is safe that does not show howit can bear discussion and publicity.
– Lord ActonThe arguments of lawyers and engineers pass through oneanother like angry ghosts.
– Nick Bohm, Ian Brown and Brian Gladman26.
1IntroductionGovernments have ever more interests online, ranging from surveillance to cen-sorship, from privacy to safety, and from market competition to fair elections.
Their goals are often in tension with the reality of a globalised online world,and with each other too.
They crystallise around a number of speciﬁc pol-icy concerns, from terrorism and counterinsurgency, through national strategicand economic advantage, to the suppression of harmful or unpopular contentand the maintenance of human rights.
 In this chapter we explore the nexus ofsurveillance, censorship, forensics and privacy.
The Internet has transformed the world in lots of complicated ways, like otherbig technologies before it – electricity, the steam engine, writing, agriculture andﬁre.
 The relationship between the citizen and the state has changed everywhere,with the state usually acquiring more power and control.
 In the early years, asthe PC replaced the mainframe and the Internet opened up to all, many pioneers82026.
1.
 INTRODUCTIONwere utopians: we believed that free access to information would be liberatingat the personal level, and would destabilise authoritarian governments too.
 Yetgovernments and large companies learned in time to use the new tools.
 Theterrorist attacks of September 11, 2001, on New York and Washington had a realimpact, by creating the incentive for mass surveillance and weakening politicalopposition to it.
 The move of business online created the tools, and a commercialmarket for personal information to pay for them.
 While the pendulum swungback during the 2010s towards surveillance capitalism, the COVID-19 pandemiclooks set to increase state surveillance once more, with the trade-o↵ being notprivacy versus security but privacy versus health.
It’s been a boom time for surveillance.
 It’s not just the NSA capabilitiesrevealed in 2013 by Ed Snowden; nation-state competitors like Russia and Chinaalso have serious capabilities; while there are more primitive but still e↵ectivesystems in less developed countries like Syria.
The 2010s also saw growing cyber conﬂict and disruption with states inter-fering covertly in other states’ a↵airs.
 The USA and Israel used the Stuxnetmalware to damage and delay Iran’s push to acquire nuclear weapons, and thiscaused a rush by other states to acquire cyber-weapons of various kinds.
 Sincethe Russian interference in the 2016 US election, legislators in a number of coun-tries want to regulate social media: a lot of politicians have stopped ignoringtechnology once they realised their jobs were on the line.
There are many thorny issues.
 First, are open societies with democracy anda free press more vulnerable, because we’re easier to exploit? And if so whatcan we do about it? We face real challenges to our core values – expressed in theUSA as the Constitution, and in Europe as the Convention on Human Rights.
Since 9/11 we’ve seen one authoritarian measure after another, ranging fromlarge-scale surveillance of communications to detention without trial and eventorture.
 Many of these measures were not just illegal and immoral but ine↵ectiveor even counterproductive: torturing Iraqi secret policemen alongside al-Qaidaterrorists in the Abu Ghraib prison was what forged them into the core of IslamicState.
 Can’t we ﬁnd better ways to defend freedom? And how can we reassertand defend our core values?Second, there’s the political economy of security.
President Eisenhowerwarned in his valedictory speech that ‘we must guard against the acquisitionof unwarranted inﬂuence, whether sought or unsought, by the military indus-trial complex.
 The potential for the disastrous rise of misplaced power existsand will persist’.
 Since 9/11, we’ve seen a security-industrial complex capturingpolicy in the same ways that the defence industry did at the start of the ColdWar.
 Politicians of left and right have stoked a culture of fear, abetted by se-curity agencies and the press.
 This has been deepened since the ﬁnancial crisisof 2008 by the rise of nationalism.
Security technology arguments are often used to bamboozle or intimidatelegislators.
 For example, all through the Irish republican terrorist campaignfrom the 1970s through 1990s, the British police had to charge arrested terroristsuspects within four days.
 But after 9/11, this was quickly raised to 28 days;then the government said it needed 90 days, claiming they might have di�cultydecrypting data on PCs seized from suspects.
The real problem was policeSecurity Engineering821Ross Anderson26.
1.
 INTRODUCTIONine�ciency at managing forensics.
 Now if the police had just said ‘we need tohold suspects for 90 days because we don’t have enough Somali interpreters’ thencommon sense could have kicked in; Parliament might well have told them to usesta↵ from commercial translation agencies.
 But talk of decryption seems a goodway to turn legislators’ brains to mush.
 People who understand cryptographyhave a duty to speak out.
The focus on terrorism starved the rest of law enforcement.
 About half of allcrime is now online, and yet the resources devoted to ﬁghting it are tiny.
 Manyscammers operate with impunity.
There are further problems around censorship.
 Concerns about online abuseare real, but this is a di�cult area.
 Abuses range in seriousness from videos ofmurder and child rape at the top end, down through hate speech, rape threatsand cyber-bullying to news manipulation which, at scale, can be toxic.
 Countriesare starting to pass laws requiring ﬁrms like Facebook to do the censorship forthem, which causes many tensions.
 The companies don’t like the extra costs, andthoughtful citizens don’t like the idea of censorship being in the hands of privatemonopolies – or the idea that everything we upload, from pictures and videosto private messages, is ﬁltered.
 So the ﬁrms have an incentive to redesign theirsystems so that they’re harder to abuse; Facebook, for example, claims to berebuilding its systems to focus more on groups, which are harder for extremists togame, and to make more use of end-to-end encryption, so it can claim ignorance.
Such arguments cut no ice in major incidents, such as when a shooter killedpeople at two mosques in Christchurch, New Zealand, in March 2019 and usedFacebook to share live video of the crime.
 This forced the company to startcensoring white supremacist groups, a politically sensitive task it had previouslyavoided [1913].
 The COVID-19 pandemic led the company to rapidly do manythings that the industry had previously denounced as impossible, undesirableor impractical: removing misinformation, banning exploitative ads and pushingo�cial advice [984].
 The tensions between privacy and censorship may continueto work out in unpredictable ways.
Privacy regulation is already complex.
 U.
S.
 laws are fragmented, with federallaws on speciﬁc topics such as health data and video rentals and the FTC pun-ishing ﬁrms that violate their published privacy policies, while state laws drivesecurity-breach disclosure.
 Europe is very di↵erent: the General Data Protec-tion Regulation provides a comprehensive framework, backed up by human-rights law that has been used to strike down laws on surveillance.
 The over-all e↵ect, from the viewpoint of the IT industry, is that Europe is becomingthe world’s privacy regulator; Washington doesn’t care, and nobody else is bigenough to matter.
 (There are strong signs that this regulatory power will beextended steadily to safety as well, although we’ll leave that to the chapter onassurance.
)In this chapter, I’m going to discuss the evolution of surveillance, then lookat terrorism before discussing censorship and privacy regulation, and ﬁnallytrying to put the whole thing in context.
Security Engineering822Ross Anderson26.
2.
 SURVEILLANCE26.
2SurveillanceThe 2010s saw a huge increase in technical surveillance, not just by governmentsbut also by commercial ﬁrms monitoring our clickstream and location historyin order to target ads better – described by Shoshana Zubo↵ as ‘SurveillanceCapitalism’ [2075].
 The two interact in various ways.
 In some countries, likethe USA, law enforcement and intelligence agencies don’t just get informationfrom their own collection systems but use warrants to get it from ﬁrms likeGoogle and Facebook too.
 In others, like China, these ﬁrms are banned becausethey refused to give complete access to the authorities; in others, like Iran andSyria, the police agencies just beat people’s passwords out of them, or phishtheir friends, or hack their phones.
This is a huge subject, and all I can reasonably provide is a helicopter tour:to place surveillance in its historical context, sketch what’s going on, and providepointers to primary sources.
26.
2.
1The history of government wiretappingRulers have always tried to control communications.
 In classical times, courierswere checked at customs posts, and from the Middle Ages, many kings eitheroperated a postal monopoly or granted it to a crony.
 The letter-opening andcodebreaking facilities of early modern states, the so-called Black Chambers, aredescribed in David Kahn’s history, ‘The Codebreakers’ [1001].
When electronic communications came along, governments tried to keep con-trol.
 In most of Europe, the telegraph service was set up as part of the post o�ceand owned by the government; in Britain, the telegraph industry was national-ized by Gladstone in 1869.
 A profusion of national rules caused so much troublethat the International Telegraph Union (ITU) was set up in 1865 to standardisethings [1818].
 In the USA, Western Union was the ﬁrst nationwide industrialmonopoly and dominated the market through the nineteenth century.
 Unionand Confederate soldiers tapped each others’ telegraph lines, and the New YorkPolice Department started wiretapping operations in 1895.
The invention of the telephone led to tussles over privacy.
 In the USA, theSupreme Court ruled in 1928 in Olmstead vs United States that wiretappingdidn’t violate the fourth amendment provisions on search and seizure as therewas no physical breach of a dwelling; Justice Brandeis famously dissented.
 In1967, the Court reversed itself in Katz vs United States, ruling that the amend-ment protects people, not places.
 The following year, Congress legalized Federalwiretapping (in ‘title III’ of the Omnibus Crime Control and Safe Streets Act)following testimony on the scale of organized crime.
 In 1978, following an in-vestigation into the Nixon administration’s abuses, Congress passed the FederalIntelligence Surveillance Act (FISA), which controls wiretapping for national se-curity.
 In 1986, the Electronic Communications Protection Act (ECPA) relaxedthe Title III warrant provisions.
 By the early 1990s, the spread of deregulatedservices from mobile phones to call forwarding had started to undermine theauthorities’ ability to wiretap, as did technical developments such as adaptiveecho cancellation in modems.
Security Engineering823Ross Anderson26.
2.
 SURVEILLANCESo the 1994 Communications Assistance for Law Enforcement Act (CALEA)required all communications companies to make their networks tappable in waysapproved by the FBI.
 By 1999, over 2,450,000 telephone conversations werelegally tapped following 1,350 court orders [634, 1257]; by 2017 the numberof wiretap orders had almost tripled to 3,813, but 94% were against portabledevices such as cellphones [1927]1.
 A further 1,598 orders were granted in wholeor in part by the Foreign Intelligence Surveillance Court (FISC) while 26 weredenied.
Even before 9/11, some analysts believed that there were at least as manyunauthorized wiretaps as authorized ones [558].
 First was phone company col-lusion: while a phone company must give the police access if they present awarrant, in many countries they are also allowed to help – and there have beenmany reports over the years of phone companies being cosy with the government.
Second, there’s intelligence-agency arbitrage: if the NSA wants to wiretap anAmerican citizen without a warrant they can get an ally to do it, and return thefavour later.
 It was said, for example, that Margaret Thatcher used the Cana-dian intelligence services to wiretap ministers suspected of disloyalty [728].
 Suchpractices were denied by the agencies for years but the Snowden leaks showedthem to be reality; for example, the NSA got GCHQ to tap the links betweenGoogle data centres, as I described in 2.
1.
 Third, in some countries, wiretappingis uncontrolled if one of the subscribers consents – so calls from phone boxes arefree to tap (the owner of the phone box is the legal subscriber).
 Companies maywiretap their sta↵ to detect fraud and voluntarily pass the product to the policeor security agencies; there was a scandal in the UK when it emerged that thesecurity services were involved in an unlawful, clandestine scheme to blacklistconstruction industry sta↵ who had tried to organise unions [658].
 Finally, inmany countries, the police get hold of email and other stored communicationsby subpoena rather than warrant.
 They did this in America too before a courtstopped the practice in 2007 [1161] – but the judgment didn’t stop private ac-tors such as bounty hunters and bail agents buying phone location histories fromdata aggregators [489].
But even if the o�cial ﬁgures have to be doubled or tripled, democraticregimes use wiretapping very much less than authoritarian ones.
 The surveil-lance leader now is China, which uses pervasive technical monitoring in regionswith minority populations such as Xinjiang and Tibet, with surveillance camerasmounted over street corners, mosques and schools hooked up via face-recognitionsoftware to databases recording who was seen where and when.
 There are alsointrusive physical measures ranging from frequent street checkpoints, throughbilleting party members in the homes of minority families, to mass incarcerationin labour camps [1110].
The incidence of wiretapping has also been highly variable within and be-tween democracies.
 In the USA, for example, only about half the states use it,and for much of the 20th century most taps were in the ‘Maﬁa’ states of NewYork, New Jersey and Florida (though Nevada and California have now caughtup) [1927].
 There is similar variation in Europe.
 Wiretaps are very common inthe Netherlands: they have up to 1,000 taps on the go at once with a tenth of1The relevant law is 18 USC (US Code) 2510–2521, while FISA’s regulation of foreignintelligence gathering is now codiﬁed in US law as 50 USC 1801–1811.
Security Engineering824Ross Anderson26.
2.
 SURVEILLANCEAmerica’s population [356].
 In a Dutch homicide investigation, it’s routine totap everyone in the victim’s address book for a week to monitor how they reactto the death.
 The developed country with the most wiretaps is Italy, thanks toits history of organised crime [1160].
 In the UK, domestic wiretaps are supposedto need a ministerial warrant, and cannot be used in evidence; so the police useroom bugs and computer exploits instead.
 If you can root a gangster’s phoneor laptop you can record, and mail home, everything said nearby, whether it’ssaid to someone in the same room, or on a call.
 International calls have beenroutinely recorded for decades and stored for some days to weeks in case theyturn out to be of interest, a model followed by many other countries; for exam-ple, after the Mumbai massacre in 2008, India could dig out recordings of phonecalls the terrorists made to their controllers in Pakistan.
Automation is shifting the costs of wiretapping from per-call labour costs toone-o↵ capital costs.
 Before CALEA was introduced, in 1993, US police agenciesspent only $51.
7 million on wiretaps – perhaps a good estimate of their valuebefore the issue became politicised [862].
 The implementation of CALEA costover $500m, and that was before it was extended to VOIP in 2007.
 VOIP washarder: “The paradigm of VoIP intercept di�culty is a call between two roadwarriors who constantly change locations and who, for example, may call froma cafe in Boston to a hotel room in Paris and an hour later from an o�ce inCambridge to a giftshop at the Louvre” [220].
 During the 2010s things becameharder still as people moved from physical platforms, such as their cellphone,to virtual platforms such as Facebook, Skype and Signal.
So the trend forpolicymakers has been to make capital investments that cut the marginal costsof access.
 For example, ten years ago, if the UK police were investigating threesimilar rapes, they might have had to pay the phone companies thousands ofpounds to assemble cellsite dumps so they could look for any mobile phones thatwere present at all three locations.
 Now, after spending hundreds of millionsand getting several laws passed, they have access to databases of mobile phonelocations, and all it takes is a database query.
 This changes the nature of bothpolice and intelligence work.
The USA also changed its laws to facilitate bulk surveillance.
 43 days afterthe 9/11 attacks, Congress passed the Patriot Act, which allowed increasedaccess by law enforcement to stored records (including ﬁnancial, medical andgovernment records), ‘sneak-and-peek’ searches of homes and businesses withoutthe owner’s knowledge, and the use by the FBI of National Security Letters toget access to ﬁnancial, email and telephone records.
But this was not enough for the agencies.
 In December 2005, the New YorkTimes revealed that President Bush had signed a secret 2002 order mandat-ing warrantless wiretapping of US residents suspected of terrorism, contrary tolaw [1606].
 In 2006, USA Today revealed that the NSA had covertly obtainedfull call-data records (CDRs) for the 200m customers of AT&T, Verizon andBellSouth, the nation’s three biggest phone companies.
 The CDR program hadbeen started by the DEA in 1992 under the older President Bush, and tar-geted calls by Americans to and from certain countries; it was ramped up after9/11, when his son authorised the collection of CDRs for all internal US callstoo [877].
 Qwest did not cooperate, because its CEO at the time, Joe Nac-chio, maintained that the NSA needed a court order.
 The NSA put pressure onSecurity Engineering825Ross Anderson26.
2.
 SURVEILLANCEQwest by threatening to withhold classiﬁed contracts, so Qwest’s lawyers askedthe NSA to take its proposal to the FISA court.
 They refused, saying the courtmight not agree with them.
 It’s since emerged that they had put pressure onQwest to hand over data even before 9/11 [768].
 In October 2007, Verizon ad-mitted to senators that it had given the FBI second-generation call data on itscustomers against national security letters on 720 occasions since 2005 [1376].
In November 2007, the Washington Post revealed that the NSA had tapped alot of purely domestic phone calls and tra�c data, and had also tapped AT&T’speering centre in San Francisco to get access to Internet tra�c [1377].
 Aftertwo years of debate, Congress amended FISA to grant retroactive immunity tophone companies who cooperated with unlawful wiretapping, and to change thelaw so that the NSA no longer needs even a FISA warrant to tap a call if oneparty’s believed to be outside the USA or a non-US person.
 (This split bothparties, with Senators Obama and Feinstein supporting the amendment whileSenators McCain, Biden, Reid, Leahy and Clinton opposed it.
)26.
2.
2Call data records (CDRs)Historically, more police communications intelligence has come from the analysisof telephone call data records and other metadata rather than wiretaps.
 Wediscussed in the chapter on telecoms security how the police use such data totrace networks of criminal contacts, and how criminals respond by burying theirsignals in innocuous tra�c using techniques such as pre-paid mobile phones andPBX hacking.
Again, this is nothing new.
 Rulers have long used their control over postalservices to track the correspondents of suspects, even when the letters weren’topened.
 The introduction of postage stamps in 1840 was an advance for privacyas it made it much easier to send a letter anonymously.
 Some countries got soworried about the threat of sedition that they passed laws requiring a returnaddress to be written on the back of the envelope.
 The development of thetelegraph, on the other hand, was an advance for surveillance; as messages werelogged by sender, receiver and word count, tra�c totals could be compiled andwere found to be an e↵ective indicator of economic activity [1818].
 The FirstWorld War taught the combatants how much intelligence could be gleaned frommeasuring the volume of enemy radio tra�c, even when it couldn’t convenientlybe deciphered [1001, 1380].
 Later twentieth-century conﬂicts reinforced this.
When I wrote the ﬁrst edition of this book, I noted that the USA had1,329 wiretap applications approved in 1998, while there were 4886 subpoenas(plus 4621 extensions) for pen registers (devices which record all the numbersdialed from a target phone line) and 2437 subpoenas (plus 2770 extensions)for trap-and-trace devices (which record the calling line ID of incoming calls,even if the caller tries to block it).
 Law-enforcement agencies were also startingto switch in the 1990s to using subpoenas for the call-detail records in thephone companies’ databases.
 Bell Atlantic, for example, responded to 25,453subpoenas or court orders for toll billing records of 213,821 of its customersin 1989–92, while NYNEX processed 25,510 subpoenas covering an unrecordednumber of customers in 1992 alone [402].
 Scaled up across the seven Baby Bells,this suggests that perhaps half a million customers were having their recordsSecurity Engineering826Ross Anderson26.
2.
 SURVEILLANCEseized every year in the 1990s, and that tra�c data were collected on perhapsa hundred times as many people as were subjected to wiretapping.
Statistics went dark after 9/11, during the period of unlawful collection,although the NSA did reveal in 2006 that it wanted “to create a database ofevery call ever made within the nation’s borders” so it could map the entire USsocial network for the War on Terror [395].
 After Snowden revealed in 2013that it had built databases of pretty well all tra�c data for all communicationsworldwide, Congress passed the Freedom Act in 2015 and we started to get anannual Statistical Transparency Report from the Director of National Intelli-gence.
 The April 2018 report gives some ﬁgures for 2017; these relate only tonational-security matters, but give some feel for the balance between contentand tra�c data.
 Wiretap warrants are stable at about 1,500 per year in the USA(targeting about 300 US persons and 1000 others), as well as a rising numberof targets overseas – 106,469 in 2016 and 129,080 in 2017.
 In addition, therewere 7,512 US residents whose communications content was retrieved (e.
g.
 sub-poenas for email) while 16,924 residents had non-content (such as tra�c data)retrieved, along with 56,064 non-residents.
There were also 87,834 collectedbusiness records, which might include records of which subscriber was usingwhich IP address [1464].
Now the US intelligence community only considers a communication to be‘intercepted’ when a human analyst looks at it; analysis by software doesn’tcount (UK law counts both).
 As I described in Section 23.
3.
1, the usual proce-dure when hunting for suspects is contact chaining, also known as a ‘snowballsearch’.
 If someone blows themselves up in a terror attack, analysts will use soft-ware that looks at all the people they communicated with, and then everyonethese direct contacts communicated with, and exceptionally even out to a thirddegree of separation.
 The standard depth-two search typically gives some tensof thousands of indirect contacts.
 These contacts are then compared againstmillions of names on various suspect lists – religious extremists, right-wing hategroups, organised crime – and the analysts then home in on the links with anyknown suspects.
 (The analogy is rolling a snowball downhill, then melting itand seeing what dirt you ﬁnd in the bottom of the bucket.
) So the analyst maylook at only half a dozen people who were in contact with the dead terrorist andalso with members of some religious group, but tens of thousands of innocentpeople had their call data records looked at by the software.
 The DNI reportestimates that in 2017, 534,396,285 call data records (CDRs) were examinedautomatically in this way – a large increase from 151,230,968 in 2016.
Yet there was a long debate in Congress about allowing Section 215 of thePatriot Act (as amended by FISA) to lapse.
 This was the section that allowsthe bulk collection of CDRs [416]; the NSA has said that it doesn’t want it.
 Thebulk collection of communications data was one of the matters highlighted byEd Snowden that sparked the most controversy.
 On June 8th 2013, the pressdisclosed Boundless Informant, an NSA visualisation tool that shows a heat mapof where metadata are collected for both voice and computer communications;in a 30-day period ending in March 2013, 3 billion records were collected from504 sources (or SIGADs).
 Although the most intensive collection was in theMiddle East, Snowden said that more records were collected on Americans inAmerica than on Russians in Russia [756].
 On another reading of the material,Security Engineering827Ross Anderson26.
2.
 SURVEILLANCEBoundless Informant collected 3 billion phone records via US telecommunica-tions providers, plus a further 97 billion emails and 124 billion phone calls roundthe world [816, p.
 92]; overall, 20 billion events a day are collected [816, p.
 98].
However, a declassiﬁed report revealed that while the NSA call-data record pro-gram in the USA cost over $100m, it produced only two leads and one signiﬁcantinvestigation [1656].
 In 2020, the clause was allowed to lapse in March but rein-stated in May; the politics was messy.
 Susan Landau and Asaf Lubin explainedthat with 4g mobile networks, traditional CDRs don’t identify both the callerand the called party reliably any more [1126].
 In any case, the action is shiftingfrom the plain old telephone system to messaging systems.
As for targeted collection in speciﬁc criminal investigations, under 18 USC3123 [1925], the investigative o�cer merely has to certify to a magistrate ‘thatthe information likely to be obtained by such installation and use is relevant toan ongoing criminal investigation’.
 This can be any crime – felony or misde-meanour – and under either Federal or State law.
 Since CALEA, warrants arestill required for such communications data as the addresses to which a sub-scriber has sent e-mail messages, but basic toll records can be obtained undersubpoena – the subscriber need not be notiﬁed, and there is no court supervisiononce the order has been made.
 The US Department of Justice is required bylaw to publish statistics for its non-national-security law-enforcement activitiesbut appears reluctant to do so; the American Civil Liberties Union (ACLU)extracted ﬁgures for 2011–12 only after freedom-of-information (FOI) litigation,which revealed that the combined number of original orders for pen registers andtrap and trace devices used to spy on phones increased by 60%, from 23,535 in2009 to 37,616 in 2011 [765].
 I’ve been unable to ﬁnd anything more recent.
Bulk access to tra�c data has been also led to serious political tussles inEurope.
 The UK pushed through a Data Retention Directive in the EuropeanUnion in 2006, under which member states had to store telecommunicationsdata – including IP address and timing of every email, phone call and textmessage sent or received – for between 6 months and 24 months, and makeall this available to law enforcement and intelligence agencies.
 The Directivewas struck down in 2014 by the European Court of Justice after Digital RightsIreland brought a lawsuit arguing that blanket data collection violated the EUCharter of Fundamental Rights.
In Britain, targeted access to communications data requires only a noticefrom a senior police o�cer to the phone company or ISP, not a warrant; anddata can be provided to a wide range of public-sector bodies, just as in theUSA.
 Following the Data Retention Directive, the Blair government wanted tocentralise things; it argued that the police needed a ‘communications database’and pushed a law to establish it.
 Fate intervened when some wicked personstole a copy of all the expenses claims ﬁled by members of parliament and soldit to the Daily Telegraph.
 It turned out that numerous ministers and others hadbeen making embarrassing claims; several honourable members went to jail, andmost of the well-known politicians in Britain had to make repayments.
 (I toldthe tragic tale of the Home Secretary, Jacqui Smith – who had been promotingthe communications database – in section 8.
6.
5 above.
) We heard nothing moreof the communications database until Ed Snowden told us in 2013 that they’djust built it anyway, even without parliamentary approval.
Security Engineering828Ross Anderson26.
2.
 SURVEILLANCEAfter the European Court struck down data retention, and Snowden revealedsome highly objectionable activities by GCHQ, the UK passed the 2014 DRIPAct to assert that what GCHQ had been doing was legal after all.
 It was clearthat the European Court would object eventually, but some breathing space wasneeded and the Act gave this (it had a two-year sunset clause; Prime MinisterCameron’s liberal coalition partners wouldn’t give him any more).
 Eventually,in the wake of the Brexit vote, Parliament passed the Investigatory Powers Act,which pretty well enables GCHQ to do as it pleases and compel any companyin the jurisdiction to assist it.
 The interesting action in the future will be, ﬁrst,the extent to which the large US ﬁrms will help, and second, the line to be takenby the European Court of Human Rights2.
 I’ll return to these issues later.
26.
2.
3Search terms and location dataIt has become ever clearer over the past 20 years that the regulation of surveil-lance that evolved in the phone-company era is not really ﬁt for purpose inthe era of the Internet.
 Back then, you got either a full wiretap and recordedthe content, or made do with tra�c data from call data records.
 But as thingsmoved online, communications data and content got all mixed up, as what’s con-tent at one level of abstraction is often communications data at the next.
 Somepeople might think of a URL as just the address of a page to be fetched, but aURL such as http://www.
google.
com/search?q=marijuana+cultivation+UKcontains the terms entered into a search engine as well as the search engine’sname.
Clearly, some policemen would like a list of everyone who submittedsuch an enquiry.
 This became a live issue in 1999, when the UK governmentmodernised its surveillance law; academics, NGOs and industry managed to geta ‘Big Browser Amendment’ into the resulting Regulation of Investigatory Pow-ers Act of 2000 deﬁning tra�c data as the information necessary to identify thecommunicating machine; for URLs, this means everything up to the ﬁrst slash.
In the USA, the Department of Justice issued a subpoena to a number ofsearch engines to hand over two full months’ worth of search queries, as well asall the URLs in their index, claiming it needed the data to bolster its claimsthat the Child Online Protection Act did not violate the constitution and thatﬁltering could be e↵ective against child pornography.
 (Recall we discussed insection 11.
2.
3 how when AOL released some search histories, a number of themwere easily identiﬁable to individuals.
) AOL, Microsoft and Yahoo quietly com-plied, but Google resisted.
 A judge ﬁnally ruled in 2006 that the Departmentwould get no search queries, and only a random sample of 50,000 of the URLsit had originally sought [2035].
The next issue was mobile-phone location data, which ended up being treateddi↵erently in di↵erent jurisdictions.
 In Britain, all information about the loca-tion of mobile phones counts as tra�c data, and o�cials get it easily; but in theUSA, the Court of Appeals ruled in 2000 that when the police get a warrantfor the location of a mobile, the cell in which it is active is su�cient, and thatto require triangulation on the device (an interpretation the police had wanted)2Britain’s departure from the EU will let it escape the European Court of Justice, which isan EU institution, but not the Court of Human Rights, as this is an institution of the Councilof EuropeSecurity Engineering829Ross Anderson26.
2.
 SURVEILLANCEwould invade privacy [1926].
 Also, even cell-granularity location informationwould not be available under the lower standards applied to pen-register sub-poenas.
 Yet despite these rules, there were massive leaks of information.
 Itemerged in 2019 that AT&T and Sprint had both been selling their customers’location information to data brokers for years, including not just cellsite databut GPS; and this had routinely been bought by bounty hunters and bail agentsto track defaulters [489].
 Location data is now being collected by many govern-ments with a view to tracing contacts of COVID-19 su↵erers and epidemiologymore generally.
 It’s also collected by lots of apps: the Untappd beer-rating appis run by millions of beer drinkers who record hundreds of time-stamped loca-tions, which enabled journalists to track US military and intelligence personnelaround the world [1538].
26.
2.
4Algorithmic processingThe analysis of call data is only one aspect of a much wider issue: law-enforcementmatching of bulk datasets.
 The earliest serious use of multiple-source data ap-pears to have been in Germany in the late 1970s to track down safe housesused by the Baader-Meinhof terrorist group.
Investigators looked for rentedapartments with irregular peaks in utility usage, and for which the rent andelectricity bills were paid by remote credit transfer from a series of di↵erentlocations.
 This worked: it yielded a list of several hundred apartments amongwhich were several safe houses.
 The tools to do this kind of analysis are nowshipped with a number of the products used for tra�c analysis and for managingmajor police investigations.
 The extent to which they’re used depends on thelocal regulatory climate; there have been rows in the UK over police access todatabases of the prescriptions ﬁlled by pharmacists, while in the USA doctorsare alarmed at the frequency with which personal health information is subpoe-naed from insurance companies by investigators.
 There are also practical limitsimposed by the cost of understanding the many proprietary data formats usedby commercial and government data processors.
 But it’s common for police tohave access at least to utility data, such as electricity bills which get trawledto ﬁnd marijuana growers, and there’s little to stop them using commerciallyavailable data such as feeds from credit reference agencies.
Since AlphaGo beat Lee Sedol in 2016, there’s been a host of machine-learning startups, and quite a few aim to make law enforcement easier one wayor another.
 But it’s not as easy as it looks.
 Terrorists are so rare as a per-centage of the population that any tests you use to ‘detect’ them would requireextraordinary speciﬁcity if you’re not to drown in false positives.
 Combiningmultiple sensors is hard, and if you’re looking for a needle in a haystack, it’snot always smart to build a bigger haystack.
 As Je↵ Jonas, once the chief sci-entist at IBM’s data-mining operation, put it, “techniques that look at people’sbehavior to predict terrorist intent are so far from reaching the level of accu-racy that’s necessary that I see them as nothing but civil liberty infringementengines” [757].
Security Engineering830Ross Anderson26.
2.
 SURVEILLANCE26.
2.
5ISPs and CSPsThe 2000s saw rapid growth of intrusive surveillance at both Internet ServiceProviders (ISPs) and Communications Service Providers (CSPs – ﬁrms likeGoogle and Yahoo).
 Tapping data tra�c at an ISP is harder than voice usedto be; there are many obstacles, such as transient IP addresses given to mostcustomers and the increasingly distributed nature of tra�c.
 In the old days (say2002), an ISP might have had modem racks, and a LAN where a wiretap devicecould be located; nowadays many customers come in via DSL, and providers useswitched networks that often don’t have any obvious place to put a tap.
 TheISP simply became the natural control point.
Many countries now have laws requiring ISPs to help, and the usual way todo it at a large ISP is to have equipment already installed that will send copiesof packets of interest (or NetFlow records) to a separate classiﬁed network.
 TheFBI’s system, DCSNet, is very slick – allowing agents point-and-click accessto tra�c and content from participating phone companies [1761].
 (Informationabout which companies have been brought onboard is closely held, but smartbad guys use small ISPs.
) And things often go wrong because the police don’tunderstand ISPs; they subpoena the wrong things, or provide inaccurate times-tamps so that the wrong user is associated with an IP address.
 For an analysisof failure modes, see Clayton [442].
The smartphone revolution has changed the natural control point from theISP to the CSP.
 A modern criminal might get up, check his messages on Gmailor WhatsApp using his home wiﬁ, then get on a bus into town and do the sameusing his 3G or 4G data connection, then perhaps use wiﬁ at a Starbucks ora public library .
.
.
 and in none of these cases does a wiretap at the ISP tellanything much beyond the fact that a particular service has been used.
Asthe tra�c to that communications service is encrypted, the police have to servepaperwork on the service to get anywhere.
 This is what led the FBI to set upthe Prism system, whereby intelligence agencies can get customer data fromGoogle, Yahoo, Apple, Microsoft, Facebook and others at the press of a button.
It is also what led the UK, in its 2016 Investigatory Powers Act, to grant itselfthe power to order any company to do anything it physically can in order toassist law-enforcement of intelligence investigations.
 More and more countriesare passing such laws, which put the service providers in conﬂict with othercountries’ laws.
One big ﬂashpoint is the tension between EU privacy and data-protectionlaw, which requires due process for privacy infringement, and US surveillancelaw which demands that US ﬁrms hand over foreigners’ data on demand.
 Butthere are many more.
 Google left China rather than give the police unfetteredaccess to all user data.
 And as a senior Google executive told me, ‘If a familycourt in India orders you to hand over the Gmail of someone who lives in Canadaand imposes a lifelong secrecy order, how do you simultaneously employ peoplein India, and give believable assurances of privacy to people in Canada?’Finally, there are lots of issues around the much richer data available fromCSPs like Facebook, which not only collect highly sensitive data at scale butenable sensitive facts to be deduced from tra�c data in ways that were not pre-viously possible.
 As I discussed in section 11.
2.
5, Michal Kosinski and colleaguesSecurity Engineering831Ross Anderson26.
2.
 SURVEILLANCEﬁgured out that he could tell whether someone was straight or gay from fourFacebook likes [1086], after which some of his colleagues collected Facebook dataat industrial scale and weaponised it for political campaigning, leading to theCambridge Analytica scandal when it was discovered that social-network datahad been used in 2016 to intervene unlawfully and at scale in both the Brexitreferendum in the UK and the presidential election in the USA.
 What sort ofcontrols should there be on the use of social analysis methods by law-enforcementand intelligence agencies, or for that matter by public-health agencies? (We’llreturn to the broader issues raised by these techniques later.
)26.
2.
6The Five Eyes’ system of systemsWe discussed the technical meat of the Snowden revelations in 2.
2.
1.
 These didnot come entirely from the blue; there had been many previous disclosures aboutsignals intelligence collection.
 David Kahn’s inﬂuential history of cryptographysets the scene by describing what happened up till the start of World War2 [1001].
 An anonymous former NSA analyst, later identiﬁed as Perry Fellwock,then revealed the scale of NSA operations in 1972 [674].
 “Information gatheringby NSA is complete,” he wrote.
 “It covers what foreign governments are doing,planning to do, have done in the past: what armies are moving where andagainst whom; what air forces are moving where, and what their capabilitiesare.
 There really aren’t any limits on NSA.
 Its mission goes all the way fromcalling in the B-52s in Vietnam to monitoring every aspect of the Soviet spaceprogram.
”While Fellwock’s motive was opposition to Vietnam, the next major whistle-blower was a British wartime codebreaker, Frederick Winterbotham, who wantedto write a memoir of his wartime achievements and, as he was dying, was notbothered about prosecution.
 In 1974, he revealed the Allies’ success in breakingGerman and Japanese cipher systems during that war [2031], which led to manyfurther books on World War 2 signals intelligence (Sigint) [438, 1002, 2007].
Thereafter there was a slow drip of revelations by investigative journalists, quitea few of whose sources were concerned about corruption or abuse of the fa-cilities by o�cials monitoring targets they should not have, such as domesticpolitical groups.
 Whistleblower Peg Newsham revealed that the NSA had ille-gally tapped a phone call made by Senator Strom Thurmond [373, 374].
 JamesBamford pieced together a lot of information on the NSA from open sourcesand by talking to former employees [160], while New Zealand journalist NickyHager [849] dug up a lot of information following the New Zealand intelligencecommunity’s failure to obey an order from their Prime Minister to downgradeintelligence cooperation with the USA.
The ﬁrst high-proﬁle expos´e of US economic espionage was made in a 1999report to the European parliament [644], which was concerned that after the col-lapse of the USSR, European Union member nations were becoming the NSA’smain targets [377].
 By then, people who paid attention were aware that data,faxes and phone calls get collected at a large number of nodes ranging fromwhere international communications cables land in friendly countries (or aretapped clandestinely underwater), through observation of tra�c to and fromcommercial communications satellites and special Sigint satellites that collectSecurity Engineering832Ross Anderson26.
2.
 SURVEILLANCEtra�c over hostile countries, to listening posts in member states’ embassies [644].
During the Cold War, much of the e↵ort was military, aimed at understand-ing Soviet radar and communications, and at gaining a decisive advantage inlocation, jamming and deception.
 Without an ability to conduct electronic war-fare, a modern state is not competitive in air or naval warfare or even in tankbattles.
 Most of the personnel at NSA were military, and its director has alwaysbeen a serving general or admiral.
 A lot of e↵ort still goes into understandingthe signals of potential adversaries.
One might question whether this huge worldwide system of systems stillgives value for money.
 Politicians have justiﬁed its budgets since 9/11 in termsof terrorism, and there have indeed been some successes against terrorists –notably the arrest of an alleged 9/11 terrorism planner after he used a mobilephone SIM from a batch bought by a known terrorist in Switzerland.
 But elec-tronic warfare against insurgents in Iraq proved less productive, as I discussedin Chapter 19.
 And it’s clear that more e↵ort should have been put into humanintelligence.
 In an article published just before 9/11, an analyst wrote “TheCIA probably doesn’t have a single truly qualiﬁed Arabic-speaking o�cer ofMiddle Eastern background who can play a believable Muslim fundamentalistwho would volunteer to spend years of his life with shitty food and no women inthe mountains of Afghanistan.
 For Christ’s sake, most case o�cers live in thesuburbs of Virginia.
 We don’t do that kind of thing.
” Another put it even morebluntly: “Operations that include diarrhea as a way of life don’t happen” [758].
Nearly two decades after the start of the wars in Afghanistan, Iraq, Syria andNorth Africa, we haven’t trained enough soldiers to carry a basic conversationin Arabic, Dari or Pushtu.
Although other countries may complain about US Sigint collection, for themto moralise about it is hypocritical.
 Other countries also run intelligence oper-ations, and are often much more aggressive in conducting economic and othernon-military espionage.
The real di↵erence between the Five Eyes countriesand the others is that no-one else has built the ‘system-of-systems’.
 Indeed,there are network e↵ects in Sigint as elsewhere: while non-aligned countries likeIndia were happy to buy their warplanes from the old Soviet Union, they nowa-days tend to share intelligence with the USA, as it has a much bigger networkthan the Russians or the Chinese [84].
 The Snowden documents reveal NSAinformation sharing with over 60 other countries.
My own view is that, like the armed forces of which they are often a part,signals intelligence agencies are both necessary but potentially dangerous.
 Anarmy can be a good servant but is likely to be an intolerable master.
 The issue isnot whether such resources should exist, but how they are held accountable.
 Inthe USA, hearings by Senator Church in 1975 detailed a number of abuses suchas the illegal monitoring of US citizens [423]; this led to FISA.
 The Snowdenrevelations in turn led to action by all three arms of the US government, albeitof limited e↵ect3.
The structural problems remain, though.
 The NSA is responsible for both3President Obama set up the NSA review group and accepted most of its recommendations,but his positive work was undone by President Trump.
 Congress passed the USA FreedomAct which imposed some limits on the bulk collection of communications data on US residentsby US agencies.
 Chief Justice Roberts made some changes to the FISA court.
Security Engineering833Ross Anderson26.
2.
 SURVEILLANCEattack and defence, and defence tends to play second ﬁddle.
 Imagine that you’rethe Director of the NSA, and one of your engineers comes to you with a cool newzero-day exploit of Windows.
 Do you tell Microsoft, thereby protecting 300mAmericans, or do you keep it secret, so you can attack 1.
2bn Chinese? Stated inthose terms, the answer is obvious.
 This equities issue is the one issue on whichPresident Obama declined to follow the advice of the NSA review group.
 Thegroup recommended that in almost all cases, vulnerabilities that come to theattention of the NSA should be reported to vendors for ﬁxing; the NSA prefersto stockpile them instead.
 Indeed it has a $100m a year budget for Bullrun,a program to insert them into commercial products by means fair and foul, asdiscussed in section 2.
2.
1.
5.
 And when bugs occur naturally, the NSA uses themwhere it can; it was reported in 2014, for example, that the hugely disruptiveHeartbleed bug in SSL had been exploited by the NSA for two years before itwas discovered independently and ﬁxed [2065].
In some countries things are cleaner: in both France and Germany, there areseparate agencies for attack and defence.
 But in most countries, the oversightof intelligence isn’t even discussed.
 In the UK, it’s only the European courtsthat forced the government to admit to the scale of surveillance, and to legislatesome controls on it.
 New cases continually highlight excessive collection, byboth electronic and human methods.
 In 2019, the European Court of HumanRights ordered the UK police to delete from its ‘extremism’ database the recordsof some 60 demonstrations attended by John Catt, a 94-year-old protester withno criminal record – a verdict applauded even in the conservative press [2024].
That is the high-level picture of how surveillance has evolved over the pastfew decades.
 Another aspect is scale.
 Cross-border bandwidth increased from11Tbit/sec in 2007, when the systems described by Ed Snowden were being built,to 704Tbit/sec in 2017; this ﬁrehose creates yet more pressure for the agenciesto collect tra�c from CSPs or other edge systems rather than from ISPs orthe backbone, as they can target the collection much better.
The resultingpressure for government access to data is remarkably similar to the pressure forgovernment access to cryptographic keys in the 1990s, which was a formativeexperience for many governments (as well as for industry and civil society) onissues of surveillance and technology policy.
26.
2.
7The crypto warsTechnology policy during the 1990s was dominated by acrimonious debatesabout key escrow – the Clinton administration doctrine that anyone who en-crypted data should give the government a copy of the key, so that the civilianuse of cryptography would not interfere with intelligence gathering.
I was involved as one of the academics whose research and teaching wasunder threat from the proposed controls, and in 1998 I was one of the peoplewho set up the Foundation for Information Policy Research, a UK Internet-policy think-tank, which wrestled with crypto policy, export policy, copyrightand related issues.
 In 2003 we set up European Digital Rights (EDRi) alongwith other European NGOs to campaign on these issues in Brussels.
 In the nextfew sections I’ll lay out a brief background to the crypto wars, and then discusshow governments have failed to get to grips with the Internet.
Security Engineering834Ross Anderson26.
2.
 SURVEILLANCE26.
2.
7.
1The back story to crypto policyMany countries made laws in the mid-19th century banning the use of cryp-tography in telegraph messages, and some even forbade the use of languagesother than those on an approved list.
 Prussia went as far as to require telegraphoperators to keep copies of the plaintext of all messages [1818].
 Sometimes theexcuse was law enforcement – preventing people obtaining horse race resultsor stock prices in advance of the ‘o�cial’ transmissions – but the real concernwas national security.
 This pattern was to repeat itself again in the twentiethcentury.
After the immense success that the Allies had during World War 2 withsignals intelligence, the UK and US governments agreed in 1946 to continue in-telligence cooperation.
 This ‘BRUSA agreement’ was joined by Canada in 1948and by Australia and New Zealand in 1956, giving the ‘Five Eyes’ partnership insignals intelligence.
 They decided to prevent the proliferation of cryptographicequipment and know-how.
 Until the 1980s, about the only vendors were com-panies selling into government markets, who could mostly be trusted not to doanything overseas which would upset their major customers at home.
 This wasreinforced by export controls that were operated “in as covert a way as possible,with the minimum of open guidance to anyone wanting, for example, an exportlicence.
 Most things were done in behind-the-scenes negotiation between theo�cials and a trusted representative of the would-be exporter.
” [206]In these negotiations, the authorities would try to steer applicants towardsusing weak cryptography where possible, and where confronted with a moresophisticated user would try to see to it that systems had a ‘back door’ (knownin the trade as a red thread) which would give access to tra�c.
 Anyone whotried to sell decent crypto domestically could be dissuaded by various means.
 Ifthey were a large company, they would be threatened with loss of governmentcontracts; if a small one, they could be strangled with red tape as they triedto get licenses and product approvals.
 The upshot was that most governmentsused weak crypto, and the NSA could break it with ease.
 But this wasn’t thewhole story, as we learned in the B¨uhler case.
Hans B¨uhler worked as a salesman for the Swiss ﬁrm Crypto AG, a leadingsupplier of cryptographic equipment to governments without the technical ca-pability to build their own.
 He was arrested in 1992 in Iran when the authoritiesﬁgured out that the Iraqis had been reading their tra�c during the Iran-Iraqwar; they accused him of selling them cipher machines which had been tamperedwith so that the NSA could get at the plaintext.
 Crypto AG paid 1.
44 billionRials – then about a million US dollars – to bail him, but ﬁred him once hegot back to Switzerland.
 B¨uhler then alleged on Swiss radio and TV that theﬁrm was secretly controlled by the German intelligence services and that it hadbeen involved in intelligence work for years [335].
 One story was that when thefounder of Crypto AG, Boris Hagelin, decided to retire, he contacted WilliamFriedman, the NSA’s chief scientist; Friedman was a friend, and the US govern-ment had been a big customer, buying Hagelin machines during World War 2.
Hagelin sold his company secretly to the NSA, which had it secretly controlledby German nominees.
 The equipment it sold was routinely red threaded [1205].
Crypto AG’s line was that these allegations were concocted by the NSA toSecurity Engineering835Ross Anderson26.
2.
 SURVEILLANCEundermine the company, as it was one of the third world’s few sources of cryp-tographic equipment.
 B¨uhler’s story was told in a book by Res Strehle [1837].
It is now known that Crypto AG was run by the German Bundesnachrichten-dienst in collaboration with the agencies of Denmark, Sweden, the Netherlandsand France, and with the CIA.
 The backdoors in their equipment were used,for example, by the UK to decipher Argentinian communications during theFalklands war in 1982 – the outcome of which was “materially inﬂuenced, if notdecided” by this operation [970].
26.
2.
7.
2DES and crypto researchDespite the poor quality of early banking cryptosystems, the NSA still worriedin the seventies that the banking sector might evolve good algorithms that wouldescape into the wild.
 Many countries were still using rotor machines or otherequipment that could be broken using the techniques developed in World War2.
 How could the banking industry’s thirst for a respectable cipher be slaked,not just in the US but overseas, without this cipher being adopted by foreigngovernments and driving up the costs of intelligence collection?The solution was the Data Encryption Standard (DES).
 At the time, asI mentioned in section 5.
4.
3.
2, there was controversy about whether 56 bitswere enough.
We now know that this was deliberate.
The NSA did not atthe time have the machinery to do DES keysearch; that came later.
 But bygiving the impression that they did, they managed to stop most foreign gov-ernments adopting it.
 The rotor machines continued in service, in many casesreimplemented using microcontrollers; Crypto AG and other biddable vendorscontinued to thrive; and the tra�c continued to be harvested.
 Foreigners whoencrypted their important data with such ciphers merely marked that tra�c asworth collecting.
A second initiative was to undermine academic research in cryptology.
 Inthe 1970s this was done directly by harassing the people involved; by the 1980sit had evolved into a subtler strategy.
 While the Pentagon funded research intocomputer security, it tried to divert crypto research into theoretical channelsand claimed that more practical published research work was all old hat: ‘wedid all that stu↵ thirty years ago; why should the taxpayer pay for it twice?’ Theinsinuation that DES may have had a ‘trapdoor’ inserted into it ﬁtted well withthis playbook.
 A side e↵ect we still live with is that the crypto and computersecurity communities got separated from each other in the early 1980s as theNSA worked to sideline one and build up the other.
By the mid 1990s this line had become exhausted.
 Agency blunders in thedesign of key escrow systems debunked their story that they were way aheadof the rest of us in cryptology, and in any case the ﬁght moved to a di↵erentbattleﬁeld.
26.
2.
7.
3Crypto War 1 – the Clipper chipCrypto policy went mainstream in 1993 with the launch of the Clipper chip.
 Af-ter AT&T proposed the introduction to the US domestic market of an encryptingSecurity Engineering836Ross Anderson26.
2.
 SURVEILLANCEtelephone that would have used Di�e-Hellman key exchange and triple-DES toprotect tra�c, the NSA persuaded the Clinton administration to promote a dif-ferent standard.
 This would use a classiﬁed block cipher, Skipjack, implementedin a tamper-resistant chip and with a protocol that made a spare (‘escrowed’)key available to the agencies to decrypt tra�c.
 This ‘Escrowed Encryption Stan-dard’ led to a public outcry; an AT&T computer scientist, Matt Blaze, found aprotocol vulnerability in Clipper that defeated the escrow mechanism [258] andthe proposal was withdrawn.
Several more attempts were made through the 1990s to promote the useof cryptography with government access to keys.
 Key escrow acquired variousnew names, such as key recovery; certiﬁcation authorities which kept copies oftheir clients’ private decryption keys became known as Trusted Third Parties(TTPs) – somewhat emphasising the NSA deﬁnition of a trusted component asone which can break security.
 In the UK, a key escrow protocol was introducedfor the public sector [980], and this was used to try to get the private sector toadopt it as well; but we found a number of vulnerabilities in it too [115].
The pro-escrow people said that as crypto provided conﬁdentiality, and con-ﬁdentiality could help criminals, there needed to be some way to defeat it.
 Theanti-escrow lobby started out by arguing that since crypto was necessary for pri-vacy, there must not be a way to defeat it.
 Reality was more complex [56].
 Mostcrypto applications are about authentication rather than conﬁdentiality, so helpthe police rather than hindering them.
 As for criminals, they mainly requireunobtrusive communications – and back in the 1990s, encrypting a phone callwas a good way to bring attention to yourself.
 If you wanted to be unobtrusive,it was better to just buy a prepaid phone.
 As for privacy, most violations resultfrom abuse of authorized access by insiders.
 Finally, a much more severe prob-lem for policemen is to ﬁnd acceptable evidence, for which decent authenticationcan also be helpful.
The debate got rapidly tangled up with export controls on weapons, themeans by which cryptography was traditionally controlled.
 US software ﬁrmswere not allowed to export products containing cryptography that was too hardto break, and this was also used as a means of controlling cryptography athome; Americans who put cryptography software on their websites were liableto prosecution for making it available to foreigners.
 A US software author, PhilZimmermann, was hauled up before a grand jury for arms tra�cking after aprogram he wrote – PGP – ‘escaped’ on to the Internet.
 He became a folkhero and made a fortune as his product grabbed market leadership.
 Others,such as Bruce Schneier, printed cryptographic algorithms in books as a way ofexercising their constitutional right to free speech [1667].
 The conﬂict becameinternational: the US State Department tried hard to persuade other countriesto control cryptography too (I’ll go into more detail in Section 26.
2.
9 on exportcontrol below).
 Imposing American policy worldwide became one of the missionsof Vice-President Gore (a reason why many tech people contributed to the Bushcampaign in 2000).
The apparent resolution of Crypto War 1 came in two phases.
 In 1999, theEuropean Union’s Commissioner for the Single Market, Martin Bangemann,pushed through the Electronic Signature Directive, a law that banned the com-pulsory licensing of certiﬁcation authorities.
 This undermined the demand fromSecurity Engineering837Ross Anderson26.
2.
 SURVEILLANCEthe NSA and GCHQ that all private signing keys should be escrowed – not justdecryption keys, but also signature veriﬁcation keys.
 The Germans objectedthat escrowing signature keys would let the agencies not just read messages,but forge them too, undermining trust in electronic commerce and authentica-tion generally.
 When the EU followed the German line rather than the Britishone, it followed that individuals could either use their signature keypairs forencryption, or to authenticate Di�e-Hellman keys and use those for encryption.
European o�cials molliﬁed the US administration by passing an export controlregulation that extended EU export controls from physical goods to intangiblessuch as software, so that European ﬁrms faced the same export controls oncryptographic software as US ﬁrms [651].
Second, in 2000 when Al Gore was running for president and wanted to getSilicon Valley onside, the administration decided to call a halt.
 Meetings wereheld at the FBI o�ces in Quantico between the agencies and the tech majors,leading to an agreement that the agencies would no longer push for vulnerabilitesto be inserted into products and systems.
 Instead, the agencies would exploitthe many naturally-occurring vulnerabilities, and the NSA inveigled itself intothe patching cycle.
When a software vulnerability is reported to the CERTecosystem, it ﬁnds its way to the CERT at the Software Engineering Institutein Pittsburgh, which is sponsored by the DoD.
 This shares it with the NSA andalso reports it to the vendor for ﬁxing.
 The patch cycle typically takes a monthor two – sometimes more, if coordinating vulnerability disclosure and producttesting is hard – giving the NSA a window to exploit the bug.
Those of us who were active in digital rights in Europe were generally pleasedat the e-signature directive but appalled at intangible export controls; we setup European Digital Rights (EDRi) in 2003 to create a lobbying presence inBrussels, backed by dozens of individual NGOs in European countries.
Wethought that the surveillance issue had been largely settled and that futureﬁght would be over issues like software copyright and data protection.
 In 2013,Ed Snowden showed us how wrong we’d been.
 The NSA and the other agencieshad simply gone underground, and had been running a covert program calledBullrun with a budget of $100m a year to undermine commercial cryptography,interfering with standards, implementations, supply chains and much else.
 Butthat came later.
One of the engineering lessons from Crypto War 1 is that doing key escrowproperly is hard.
 Making two-party security protocols into three-party protocolsincreases the complexity and the risk of serious design errors, and centralizingthe escrow databases creates huge targets; I discussed this in a paper ‘The Risksof Key Recovery, Key Escrow, and Trusted Third-Party Encryption’ that I wrotewith ten other cryptographers and that became the most highly-cited referenceon the subject [4].
 Where escrow is required it’s usually better done with simplelocal mechanisms.
 In one army, every o�cer must write down his passphraseon a piece of paper, put it in an envelope, stamp it ‘Secret’ and hand it to hiscommanding o�cer, who puts it in his o�ce safe.
 That way the keys are keptin the same place as the documents whose electronic versions they protect, andthere’s no central database for an airplane to bomb or a spy to steal.
 But tryingto automate this and scale it up leads to trouble.
 The UK government idea wasthat everyone’s private key would be generated from their email address using aSecurity Engineering838Ross Anderson26.
2.
 SURVEILLANCEsuper-secret master key generated by GCHQ and kept in equipment controlledby their departmental security o�cer, so that both the department and GCHQcould decrypt tra�c if they had to.
 The result was a clunky system that couldn’teasily deal with the frequent changes of name as government departments werereorganised and renamed.
 The demand for customised central control leads tovast IT projects that run years late and millions over budget, or just never workat all.
Problems providing o�cials with working email systems led to themusing private accounts instead, and eventually the Cameron government moreor less gave up; routine email in the Cabinet O�ce (the stu↵ below Top Secret)started to use a branded version of G Suite, the paid-for version of Gmail.
 Bythe coronavirus pandemic, the cabinet was using Zoom for meetings, despiteknown insecurities; there did in fact exist a secure videoconferencing system,but as it was classiﬁed, ministers weren’t allowed to take it home.
Crypto War 1 left a signiﬁcant legacy, with both technical and political as-pects.
 On the technical front, the mandated use of weak cryptography madeDVDs easy to rip, made cars easier to steal, made Bluetooth easy to hack, andmade millions of building locks easy to defeat – including the building where Iwork4.
 The business models of ﬁrms selling hotel door locks have been under-mined as they can no longer lock in their customers to buying their proprietarycard stock.
 As for policy, authoritarian governments such as Russia’s passedharsh crypto control laws; Britain went from a laissez-faire policy under JohnMajor in the mid 1990s to Tony Blair’s Regulation of Investigatory Powers(RIP) Act of 2000 which enables the police to demand that I hand over a key orpassword in my possession, and the Export Control Act of 2002 instructs me toget an export licence if I send any cryptographic software outside Europe thatuses keys longer than 56 bits5.
 I’ll return to export control later.
26.
2.
8Crypto War 2 – Going spottyThe 2013 disclosures by Edward Snowden have led to a resumption, after afashion, of the crypto wars.
 In fact, the NSA and its partners never stopped,but just took their ‘crypto enabling’ activities underground.
 They were not onlyharvesting everyone’s SMSes and email from the backbone, and getting contentfrom major service providers using warrants at much larger scale than we imag-ined.
 They were hacking allies, as when GCHQ hacked Belgacom [734] – anamazing story about how one EU member state attacked the critical infrastruc-ture of another, and went on to wiretap the European Commission.
 Anotherexample was New Zealand’s contribution to the Five Eyes which includes spy-ing on small neighbours such as Samoa, Tonga and French Polynesia [850].
 TheNSA had lied to Congress, for example about collecting call data records on UScitizens.
 They were bypassing legal controls: GCHQ could get my gmail fromGoogle using Prism, as I’m not a US resident, and we’d always suspected this,but it had always been denied.
 They were also getting it from major services bycovert means – by tapping the communications between Google’s data centres.
4See section 4.
3.
1 for car theft, section 5.
7.
2.
2 for attacks on Bluetooth and section [?] forattacks on door locks.
5Thankfully, the person who does the exporting is the person who clicks on the link – soif you’re in Iran, you would be a very bad person if you clicked on the link on my website todownload the Serpent block cipher.
 You have been warned!Security Engineering839Ross Anderson26.
2.
 SURVEILLANCEIn 2015, a UK court ruled that for the UK to obtain mass surveillance data onUK residents via the USA had been unlawful, as it contravened the EuropeanConvention on Human Rights [304].
All this had a real e↵ect on behaviour.
 First, the service providers cleanedup their act; Google had been starting to encrypt its internal network but ac-celerated the program to ensure that the only way to get their users’ data wasthrough the front door, by a warrant.
 Microsoft and Yahoo followed.
 Second,most messaging systems o↵ered end-to-end encryption to reassure users (andalso to save system operators the cost of complying with warrants).
 Third, thepolicy conversation started tackling more realistic problems, such as jurisdic-tion; given that most of the material of interest to the world’s police forces iskept on servers belonging to US companies, who can get access to it, and onwhat terms? While countries like the UK worked at getting faster access toUS data, others went for localisation.
 India had already insisted that all pri-vate Blackberry users keep their messages on servers in India; China bannedFacebook and Google to ensure its residents used Chinese systems instead; andmany countries have passed data-localisation laws to ensure that some kindsof personal data are kept within the jurisdiction.
 Most countries in Africa, forexample, require ﬁnancial data to be kept locally; I’ll discuss the EuropeanUnion’s data-protection regulation and its interaction with US ﬁrms later.
Although the agencies no longer ask for access to all keys, the escrow ar-guments came back in new forms post-Snowden.
 GCHQ, along with the FBI,started to argue that providers of messaging services such as WhatsApp andFaceTime should be compelled to build in a facility whereby law enforcementcan be added as a silent conference-call party (so-called ‘ghost users’) whenthey get a warrant.
FBI Director James Comey led the charge along withGCHQ Director Robert Hannigan, who accused Facebook in 2014 of helpingterrorism [1566] by requiring him to go through the procedures of the UK/USAMutual Legal Assistance Treaty to get information.
 Facebook’s response wasthat they were just obeying US and EU privacy laws; the relevant service centrewas in Ireland, not the UK, so Hannigan couldn’t simply use UK law to forcethem to help him.
 He and Comey were supported by UK Prime Minister DavidCameron.
My cryptographer colleagues and I reconvened to write an update of ouranalysis, ‘Keys Under Doormats’, which explains how many of the problemswith 1990s key escrow proposals simply come back in a new form if you man-date government access to data instead of to keys [5].
 The e↵ects if anythingare likely to be worse, as we are now much more dependent on the Internet thanin the 1990s.
 It would be a bad thing if governments were to force designersto abandon security mechanisms such as forward secrecy, authenticated encryp-tion and strict transport security that have become widespread in the meantime;and because of the many interactions between systems that have been securedin di↵erent ways, the risk of mandated vulnerabilities having serious and unan-ticipated side-e↵ects is now much greater.
 Building in exceptional access alsocreates huge targets in the wiretapping systems themselves, and extra complex-ity that can lead to further security failures.
 Indeed, the 2010 Chinese hack ofGoogle’s wiretapping system suggests that even the best-run companies cannotkeep out state actors all the time – and that hack was aimed at the systemsSecurity Engineering840Ross Anderson26.
2.
 SURVEILLANCEGoogle built to service wiretaps.
 The Chinese obviously wanted to know whichof their agents in the USA was under suspicion.
 There are huge problems aroundjurisdiction.
 If Facebook carries a WhatsApp message from a user in France toa user in Argentina, do only these two governments get access, or does the NSAdemand it too? Since Snowden, everyone knows they will, and nobody believesthey could keep such a capability under control.
 Any demand for such systemsraises a lot of questions of both law and engineering, some of which we spelledout in our analysis [5].
The next move came in 2016 when the FBI tried to force Apple to producean operating system ‘upgrade’ for the iPhone that would unlock it, using astheir test case a locked iPhone that had been used in a terrorist attack inSan Bernardino.
 Apple’s Tim Cook had resisted pressure to install back doorsbefore, and saw the case as a serious threat to Apple users’ privacy and to theApple brand; he fought the FBI in court [1006].
 Comey testiﬁed that the agencywould not be able to get at such vital information without assistance from Apple.
The case divided American opinion, with Republicans supporting the FBI (andcandidate Trump, as he then was, calling for a boycott of Apple) while mostDemocrats, and the tech industry, supported Tim Cook.
 My colleague SergeiSkorobogatov worked out how to defeat the iPhone PIN retry counter [1777], asI discussed in 3.
4.
8.
3.
 As for the FBI, they bought a commercial iPhone exploitfrom an Israeli ﬁrm, Cellebrite, and dropped the case.
In the chaos following the Brexit referendum, the new UK Prime MinisterTheresa May (who as home secretary had been a surveillance hawk) pushed theInvestigatory Powers Act through UK parliament.
 This law grants ministersthe power to order any company to do anything physically possible to facilitatesignals intelligence collection, and to keep quiet about it forever.
 In 2018, twosenior GCHQ mathematicians, Ian Levy and Crispin Robinson, suggested howgovernment access to messaging services might work [1153]; their idea was thatwhen GCHQ presented Facebook with a warrant, they would add a GCHQ pub-lic key quietly to the target’s keyring, so that they’d become a silent conferenceparty to all his calls.
 My colleague Bruce Schneier responded in detail [1678]:the fact that such an approach would work with some systems (it would workwith WhatsApp but not with Signal) is actually a bug that’s being ﬁxed bybetter transparency mechanisms, and mandating it would prevent the bugﬁx.
In any case, such an access power is excessive; intelligence agencies should nothave it because of their history of abusing such access, or simply losing it.
 Insection 2.
2.
3 I described how the NSA tool EternalBlue was stolen and used bythe Russians against Ukraine in the NotPetya worm, causing billions of dollarsof collateral damage to US ﬁrms in 2016; by 2019 it was being used in ran-somware that shut down email and other services in the city of Baltimore, justup the road from the NSA [1529].
In 2019, Mark Zuckerberg announced that Facebook will shift its emphasisfrom public posts to emphemeral, end-to-end encrypted messaging by unifyingWhatsApp with Instagram and Messenger [1439].
 Some cynics suggested thatthis would make it easier to hide fake news and hate speech from both the mediaand the law, and cut the costs of moderation as well as the PR damage fromscandals; others that it was to prevent either the EU or the US governmentfrom ordering the breakup of the company [1911, 1931].
 In October, the USSecurity Engineering841Ross Anderson26.
2.
 SURVEILLANCEAttorney General joined the UK Home Secretary and the Australian Ministerfor Home A↵airs in asking Zuck to think again, highlighting the risk of ‘a singleplatform that would combine inaccessible messaging services with open proﬁles,providing unique routes for prospective o↵enders to identify and groom ourchildren’.
 Time will tell whether Zuck can do abuse detection using metadataalone; we’ll consider moderation and other forms of censorship below.
26.
2.
9Export controlOne spillover from the crypto wars was the imposition of more uniform exportcontrols than before, particularly in Europe; here’s a quick summary.
 Interna-tional arms control agreements (COCOM and Wassenaar) bind most govern-ments to implement export controls on cryptographic equipment, and the latteris implemented in the European Union by an EU regulation compelling MemberStates to control and license the export of dual-use goods – goods which haveboth civilian and military uses.
 Cryptanalytic products fall under the militaryregime, whereas software that just uses cryptography for protection falls underdual-use.
National policy used to vary more, and during the 1990s European re-searchers like me could write crypto software and publish it on our web pages,while our US colleagues were prevented from doing that by the US Interna-tional Tra�cking in Arms Regulations (ITAR).
 US ﬁrms complained and in1997, Vice-President Al Gore persuaded the incoming British Prime MinisterTony Blair to extend export control to intangibles.
 He initially tried to sell thisto the UK parliament, but the relevant committees weren’t keen, so Blair had itpushed through as an EU regulation and his ministers then happily told us“Ourhands are tied – we have to do this as it’s EU law”.
 (Such policy laundering,as it’s called, has been endemic in Europe and is one of the factors that fuelledthe movement to get Britain to leave the EU.
)Tens of thousands of academics and small software companies are now break-ing the law without knowing it by exporting products (or even by giving awaysoftware) containing crypto with keys longer than 56 bits.
 There are open gen-eral export licenses (OGELs) that you can use, but you have to understandthe mechanisms and ﬁle the paperwork.
 And it’s not just cryptography.
 Forexample, in our hardware tamper-resistance research we use an ion beam work-station, which is like an electron microscope only it ﬁres metal ions at the targetrather than electrons, so you can modify a chip by cutting tracks and addingnew ones.
 Like cryptography, this is on the dual-use list.
 In the old days, wehad to get an export licence when we bought one, and another seven years laterwhen we threw it in a skip.
 Now, we’re in theory supposed to get a licencewhenever we share a script we’ve written for the machine with someone whoisn’t an EU citizen or resident.
 The practical outcome is that tens of thousandsof scientists happily break the law – which can make them vulnerable to pres-sure from the agencies.
 The number has surely shot up now that the pandemichas led to many people working from home, often from overseas, and that theUK has left the EU.
 How I deal with such issues personally is to be very carefulthat all such software and scripts are on my website, which enables me to usea public-domain exemption, and rely on the fact that it’s the person who clicksSecurity Engineering842Ross Anderson26.
3.
 TERRORISMon the link who performs the export.
The civil war in Syria exposed the dark side of export control in 2012.
 Peoplefrom several digital rights NGOs lobbied the UK government, asking it to useexport control law to prevent a UK company selling bulk surveillance equipmentto the Assad government.
 UK NGOs argued that mass surveillance equipmentshould not just be on the dual-use list but the military list, that the intelligencecommunity includes bulk collection in ‘cryptanalysis’ which is military; and itssale to a government involved in wholesale abuses was against human-rightslaw.
 The lady from GCHQ fought this tooth and nail; the sales were goingthrough an arms dealer in Dubai so how could the vendor be sure of the desti-nation; they came from a German subsidiary so it was the Germans’ problem;Wassennaar was a forum for military issues rather than human rights ones; andeven that mass surveillance is also used for marketing.
 The real issue was thatGCHQ feared that UK troops would end up in Syria and they were determinedthat if President Assad was going to have black boxes on his network, theyshould be British black boxes rather than Ukrainian ones.
 Eventually the Ger-man chancellor Angela Merkel admitted in public that she had decided to allowsurveillance equipment to be sold to Syria, and that it was one of the hardestdecisions she’d taken.
 In August 2013, the UK Parliament voted against autho-rising military action in Syria, and President Obama decided not to go it alone.
In due course, the export control issue was referred to European agencies andquietly forgotten.
One unpleasant side-e↵ect of this ﬁght lingers: a system of vetting foreignstudents at UK universities.
 GCHQ was opposed to Chinese students studyingcryptography, and the security service briefed that an Iraqi woman who’d got aPhD in Britain had gone on to direct part of Saddam Hussein’s alleged researchprogramme into weapons of mass destruction.
Briefers raised a scare aboutpeople from countries on the terrorist list, such as Sudan, being allowed to studymedicine.
 Tony Minson, a professor of virology and Cambridge colleague, arguedthat nature can do much nastier things than people can, and if there were nocompetent public-health people in Khartoum when something like Ebola camedown the Nile, we’d regret it.
 He was of course ignored.
 We got an ‘AcademicTechnology Approval Scheme’, and graduate students coming to the UK haveto get an ‘ATAS clearance’ to get a visa.
26.
3TerrorismTalk about terrorism has driven a lot of policy around surveillance and privacy,especially since 9/11.
 The tide is starting to recede, but it’s still a card thatpoliticians play when they want to scare us, and the media often play along.
There has been talk of cyber-terrorism; that basically hasn’t happened, butthere are real concerns about encrypted chat services and social media beingused to groom and recruit young people to criminal organisations ranging fromright-wing hate groups to Islamic State.
 So what can we say about terrorism?Political violence is nothing new; anthropologists have found that tribal war-fare was endemic among early humans, as indeed it is among chimpanzees [1132].
Terror has long been used to cow subject populations – by the Maya, by theSecurity Engineering843Ross Anderson26.
3.
 TERRORISMInca, by William the Conqueror.
 Terrorism of the ‘modern’ sort also goes backcenturies.
 Guy Fawkes tried to blow up Britain’s Houses of Parliament in 1605;his successors, the Irish Republican Army, ran a number of campaigns againstthe UK.
 In the latest, from 1969–97, some three thousand people died, and theIRA even blew up a hotel where the Prime Minister, Margaret Thatcher, wasstaying for a party conference, killing several of her colleagues.
 During the ColdWar, the Russians supported not just the IRA but the Baader Meinhof Gangin Germany and many others; the West armed and supported jihadists ﬁghtingthe Russians in Afghanistan.
 Some terrorists, like Baader and Meinhof, endedup in jail, while others – such as the IRA leaders Gerry Adams and MartinMcGuinness, the Irgun leader Menachim Begin, the French resistance leaderCharles de Gaulle and the African anti-colonial leaders Jomo Kenyatta, RobertMugabe and Nelson Mandela – ended up in o�ce.
What general lessons can be drawn from this history? Well, there’s goodnews and bad news.
26.
3.
1Causes of political violenceThe biggest piece of good news is that the trend in terrorist violence has beensteadily downward [1350].
 There were many insurgencies in the 1960s and 70s,some ethnic, some anti-colonial, and some ideological.
 Many were ﬁnanced bythe Soviet Union or its allies as proxy conﬂicts in the Cold War, although ahandful (notably the Nicaraguan Contras and the resistance to the Soviets inAfghanistan) were ﬁnanced by the West.
 The end of the Cold War removed themotive and the money.
The second (and related) point is that the causes of civil conﬂict are partlyeconomic.
 An inﬂuential study by Paul Collier and Anke Hoe✏er for the WorldBank looked at wars from 1960-1999 to see whether they were caused largelyby grievances (such as high inequality, a lack of political rights, or ethnic andreligious divisions), or by greed (some rebellions are more economically viablethan others) [459].
The world has plenty of grievances, but the data showthat the incidence of rebellion was more determined by whether it could besustained.
 (Indeed, Cicero said two thousand years ago that “Endless moneyforms the sinews of war.
”) Thus the IRA campaign got signiﬁcant support fromthe Soviet bloc and Libya; the Tamil revolt in Sri Lanka was sustained by fundsfrom ethnic Tamils in the USA and India; and Al-Qaida was ﬁnanced by richdonors in the Gulf states.
 So we know one way to tackle an insurgency: cut o↵their money supply.
 It’s not entirely that simple, of course; the loss of Sovietsupport for the ANC (and Angola and Mozambique) reduced the pressure onthe last white government of South Africa but gave them the space to do ahistoric peace deal with Nelson Mandela.
26.
3.
2The psychology of political violenceLess encouraging ﬁndings come from scholars of psychology, politics and themedia.
Psychology gives a lot of insight into the underlying mechanisms.
Imentioned the a↵ect heuristic in Section 3.
2.
5: where people rely on a↵ect, orSecurity Engineering844Ross Anderson26.
3.
 TERRORISMemotion, calculations of probability tend to be disregarded.
 The prospect ofa happy event, such as winning the lottery, will blind most people to the longodds and the low expected return; similarly, a dreadful event, such as a terroristattack, will make most people disregard the fact that such events are exceedinglyrare [1787].
 Most of the Americans who died as a result of 9/11 probably didso since then in car crashes, after deciding to drive rather than ﬂy: the shiftfrom ﬂying to driving led to about 1,000 extra fatalities in the following threemonths, and about 500 a year since then [1677].
There are other e↵ects at the border between psychology and culture.
 Astudy of the psychology of terror by Tom Pyszczynski, Sheldon Solomon andJe↵ Greenberg looked at how people cope with the fear of death [1564].
 They got22 municipal court judges in Tucson, Arizona, to participate in an experiment inwhich they were asked to set bail for a drug-addicted prostitute.
 They were allgiven a personality questionnaire ﬁrst, in which half were asked questions such as‘Please brieﬂy describe the emotions that the thought of your own death arousesin you” to remind them that we all die one day.
 The judges for whom mortalityhad been made salient set an average bail of $455 while the control group set anaverage bond of $50 – a huge e↵ect for such an experiment.
 Further experimentsshowed that the mortality-salience group had not just become mean: they werealso prepared to give larger rewards to citizens who performed some public act.
It turns out that when you remind people of death, it makes them adhere morestrongly to their cultural norms and defend their worldview more vigorously.
This helps explain why cyber-terrorism just hasn’t happened.
 Hacking a coupleof substations and turning o↵ a town’s electricity can be mighty inconvenient,but it just doesn’t have the same emotional e↵ect as a bleeding child.
Themedia analysis conﬁrms this; coverage is strongly correlated with fatalities, andincreases by 46% for each extra dead body [1026].
The 9/11 attacks brought mortality to the forefront of people’s minds, andwere also an assault on symbols of national and cultural pride.
 It was natu-ral that the response included religion (the highest level of church attendancesince the 1950s), patriotism (in the form of a high approval rating for the Pres-ident), and for some people bigotry too.
 It was natural that, as the memory ofthe attacks receded, society would repolarise because of divergent core values.
Curiously, when they’re reminded that they’re mortal, both conservatives andliberals take a more polarised view of an anti-American essay written by a foreignstudent – except in experiments where they are ﬁrst reminded of the Constitu-tion, in which case conservatives defend the student’s right to free speech evenmore vigorously than liberals do [1564].
So a national leader trying to keep a country together following an attackshould constantly remind people what they’re ﬁghting for.
 This is what the bestleaders do, from Churchill’s radio broadcasts to Roosevelt’s ﬁreside chats.
 Inmore recent years, some countries have taken a bipartisan approach to terrorism– as when Germany faced the Baader-Meinhof Gang, and Britain the IRA.
 Inothers, politicians have given in to the temptation to use fearmongering to getre-elected.
A study by the University of Alabama of over 200,000 articles on the 136di↵erent attacks in the USA between 2005 and 2016 showed that attacks by Mus-lims get 357% more news coverage than other terrorist attacks [1026].
 IslamicSecurity Engineering845Ross Anderson26.
3.
 TERRORISMextremists were labelled terrorists 78.
4% of the time, whereas far-right extrem-ists were identiﬁed as terrorists only 23.
6% of the time.
Political leadershipdoes matter.
 Perhaps the best recent response was that of New Zealand PrimeMinister Jacinda Ardern to the Christchurch shooting; she not only described itimmediately as terrorism but refused to name the shooter.
 On the other hand,the Pittsburgh synagogue shooting was simply described as a ‘wicked act ofmass murder’ by the US President.
 In each case, the media followed [1335].
What are the dynamics here, and which approaches work best?26.
3.
3The role of institutionsThere’s a whole academic subject – public-choice economics – devoted to ex-plaining why governments act the way they do, and for which one of its foundersJames Buchanan won the Nobel prize in 1986.
 As he put it in his prize lecture,“Economists should cease pro↵ering policy advice as if they were employed by abenevolent despot, and they should look to the structure within which politicaldecisions are made.
” Much government behaviour is explained by the incentivesfacing individual public-sector decision makers.
 It’s natural for o�cials to buildempires as they’re ranked by their span of control rather than by the proﬁtsthey generate.
 Similarly, politicians maximise their chances of reelection ratherthan the abstract welfare of the public.
 Understanding their decisions requiresmethodological individualism – analysis of the incentives facing individual pres-idents, congressmen, generals, police chiefs and newspaper editors, rather thanthe potential gains or losses of a nation.
 We know it’s prudent to design in-stitutions so that their leaders’ incentives are aligned with its goals – we givecompany managers stock options to make them act like shareholders.
 But thisis harder in a polity.
 What’s the equivalent for presidents and prime ministers?How is the national interest even to be deﬁned?Public-choice scholars argue that both markets and politics are instrumentsof exchange.
 In the former we seek to optimise our utility individually, while inthe latter we do the same but using collective actions to achieve goals that wecannot attain in markets because of externalities or other failures.
 The politi-cal process in turn is thus prone to speciﬁc types of failure.
 Intergenerationalbargaining is hard: it’s easy for politicians to borrow money to buy votes now,and leave the bill with the next generation, who can’t vote yet.
 But then whydo some countries have much worse public debt than others? The short answeris that institutions matter.
 Political results depend critically on the rules thatconstrain political action.
Although public-choice economics emerged in response to problems in publicﬁnance in the 1960s, it has some clear lessons.
 Constitutions matter, as theyset the ground rules of the political game.
So do administrative structures,as o�cials are self-interested agents too.
 In the UK, for example, the initialresponse to 9/11 was to increase the budget for the security service; but thishundred million dollars or so didn’t o↵er real pork to the security-industrialcomplex.
 So all the pet projects got dusted o↵, and the political beauty contestwas won by a national ID card, a grandiose project that in its original formwould have cost £20 billion [1182].
 Washington insiders remarked that a similardynamic was involved in the decision to invade Iraq: although the 2001 invasionSecurity Engineering846Ross Anderson26.
3.
 TERRORISMof Afghanistan had been successful, it had not given much of a role to thePentagon barons who’d spent careers assembling ﬂeets of tanks, capital shipsand ﬁghter-bombers, or much of a payo↵ to the defense industry either.
 Indeed,USAF Colonel Karen Kwiatkowski retired at the start of the Iraq war, describedhow intelligence assessments were politically manipulated, and later ran forCongress [1113].
 Similar things were said in the aftermath of World War 1,which was blamed on the ‘merchants of death’.
An institution of particular concern must be the media, whether the old-fashioned press or the social media that are taking over some of their functions.
‘If it bleeds, it leads’, as the saying goes; bad news sells more papers than good.
The self-interest of media owners combines with that of politicians who want toget re-elected, o�cials who want to build empires, and vendors who want to sellsecurity stu↵.
 They pick up on, and amplify, the temporary blip in patriotismand the need for heroes that terrorist attacks naturally instil.
 Fearmongeringgets politicians on the front page and helps them control the agenda.
 And therecommender algorithms of many social media platforms learn to promote fearand outrage, as they increase the time people spend on the platform and thenumber of ads they click on.
26.
3.
4The democratic responseYet people also learn over time.
 The worldwide reaction to 9/11 was sharp;it was more muted four years later, in July 2005, when four suicide bomberskilled 52 people on London’s public transport and injured about 700.
 The initialresponse of the public was gritty resignation: ‘Oh, well, we knew something likethis was going to happen – bad luck if you were there, but life goes on.
’6And as populations learn, so might political elites.
 John Mueller has writtena history of the attitudes to terrorism of successive US administrations [1350].
Presidents Kennedy, Johnson, Nixon and Ford ignored terrorism.
PresidentCarter made a big deal of the Iran hostage crisis, and like 9/11 it gave him ahuge boost in the polls at the beginning, but later it ended his presidency.
 HisSecretary of State Cyrus Vance later admitted they should have played down thecrisis rather than giving undeserved credibility to the Iranian ‘students’ who’dkidnapped US diplomats.
 President Reagan mostly ignored provocations, butsuccumbed to temptation over the Lebanese hostages and shipped arms to Iranto secure their release.
 However, once he’d distanced himself from this error, hisratings recovered quickly.
 In America, people got fed up with President Bush’sfear-based policies and elected President Obama whose line was “9/11 is not away to scare up votes but a challenge that should unite America and the worldagainst the common threats of the 21st century”.
 Much the same happened inthe UK, where Margaret Thatcher was re-elected twice after treating terroristsas common criminals.
 Later, Tony Blair played the fear game, and his departurefrom o�ce was met with a sigh of relief; his successor Gordon Brown forbadeministers from using the phrase ‘war on terror’, and David Cameron’s govern-ment continued that.
 Mature voters prefer politicians who stand up to terrorists6The press went along with this for a couple of days: then there was an explosion offearmongering.
It seems that ministers needed a day or two of meetings to sort out theirshopping lists and decide what they would try to shake out of Parliament.
Security Engineering847Ross Anderson26.
4.
 CENSORSHIPrather than using them as props in their re-election campaigns.
The harshest teacher may be the coronavirus.
 For years, a pandemic hasbeen at the top of Britain’s risk register, yet far less was spent preparing for onethan on anti-terrorist measures, many of which were ostentatious rather thane↵ective.
 This misallocation of resources looks set to cost far more of us our livesthan any terrorist could have dreamed of.
 The US and UK governments justiﬁedtorture in the 2000s by talking of an al-Qaida cell stealing a nuclear bomb anddetonating it in New York or London.
 Yet a 10 kT atomic demolition munitionset o↵ in a major city might cost 50–100,000 lives, compared with the 50–100million who died in the 1918–19 pandemic.
 The rhetoric of terror pu↵ed up thesecurity agencies at the expense of public health, predisposing governments inAmerica, Europe, India and Africa to disregard the lesson of SARS in 2003 –unlike the governments of China, Singapore, Taiwan and South Korea.
26.
4CensorshipI wrote in the ﬁrst edition that “the 1990s debate on crypto policy is likely to bea test run for an even bigger battle, which will be over anonymity, censorshipand copyright.
” By the second edition, I noted that “copyright law has largelystabilised”, and it was during 2008 that power over content distribution shiftedfrom the music majors and Hollywood to tech ﬁrms like Apple and Amazon.
 Ialso noted that “censorship has become a much bigger issue over the past fewyears”.
 Now, a decade later, censorship is front and centre.
 It has two faces:state censorship, and content ﬁltering by service companies.
Rulers have long censored books, although the invention of the printing pressmade their job a whole lot harder.
 When John Wycli↵e translated the Bible intoEnglish in 1380–1, the Lollard movement he started was suppressed along withthe Peasants’ Revolt.
 But when William Tyndale had another go in 1524–5,printing let him spread the word so widely that the princes and bishops couldnot suppress it.
 They had him burned at the stake, but by then over 50,000copies of the New Testament had been printed, and the Reformation was underway.
 After that upset, printers were closely licensed and controlled; things onlyeased up in the eighteenth century.
Censorship nowadays is done for a variety of motives.
 Most countries blockimages of child sex abuse; during the 1990s, as the dotcom boom got underway,governments started looking for some handle on the Internet, and a view arosethat images of child sex abuse were about the one thing that all states couldagree should be banned.
 In due course the 2004 Cybercrime Convention obligedsignatory states to ban sexual images of under-18s.
 Most governments go furtherand block some kinds of hate speech.
 Britain bans websites that ‘radicalise’young people by glorifying terrorism.
 Finally, censorship is sometimes imposedby the courts.
The invention of the Internet has made the censors’ job easier in some waysand harder in others.
 It’s easier for the authorities to order changes in materialthat not many people care about: for example, courts that ﬁnd a newspaperguilty of libel order the o↵ending material to be removed.
 Changing the histor-Security Engineering848Ross Anderson26.
4.
 CENSORSHIPical record wasn’t possible when it consisted of physical copies in libraries, andthe centralisation of human knowledge in the servers of a small number of ﬁrms– from Amazon’s e-book system to the servers of the major news organisations –takes us, in some sense, back to the 15th century.
 It’s also easier for the author-ities to observe the transmission of disapproved material, as they can monitorelectronic communications more easily than physical packages.
 On the otherhand, nowadays everyone can be a publisher; much of the really unpleasantmaterial online comes from millions of individuals posting sort-of anonymouslyto social media, to the comment pages of newspapers, and to individuals whomthey wish to harass and intimidate.
 Censors have learned to harness this.
 Whilea decade ago China had tens of thousands of people who took down dissidentspeech, now they have millions of citizen volunteers who drown it out.
 Once,speech was scarce, and the censors tried to silence the speaker; now it’s thelistener’s attention that’s scarce, and so di↵erent tactics work.
To tease out the issues, let’s look at some contexts.
26.
4.
1Censorship by authoritarian regimesWhen I wrote the second edition of this book, I was cautiously optimistic thatthe government of China would fail in its attempts to censor all online content.
However the authorities there have become steadily more e↵ective at suppressingany forms of organisation and human solidarity outside of party control.
By 2006, observers noted that online discussion of local news events had ledto the emergence of ‘public opinion’ that for the ﬁrst time was not in thrall tomedia managers [1470].
 China had 137 million Internet users then, including aquarter of the population in the big cities, and ‘the Great Firewall of China’ wasalready a complex system of controls giving defence in depth against a range ofmaterial, from pornography to religious material to political dissent [1469].
 Thedefences work at three levels.
First, there are the perimeter defences.
 China’s border routers ﬁlter on IPaddresses to block access to known ‘bad’ sites like the Voice of America andthe BBC; they also use DNS cache poisoning.
 Deep packet inspection at theTCP level is used to identify emails and web pages containing forbidden wordssuch as ‘Falun Gong’; such connections are torn down.
 Ten years ago, muchof the work was done at this level.
 Nowadays, since most tra�c is encrypted,that’s not so easy.
 In 2020, the ﬁrewall started dropping TLS 1.
3 tra�c usingEncrypted Server Name Indication (ESNI) as this stops the censor telling whichsubdomain the tra�c’s going to; this amounted to over 30% of tra�c by thebeginning of July [433].
Second, there are application-level defences, which now do much of the work.
Nowadays some services are blocked and some aren’t, depending on whetherthe service provider is prepared to help the regime with both surveillance andcensorship.
Google and Facebook are largely blocked; China has promotedTencent, Alibaba and Baidu instead.
 Now that the borders that matter mostare those of ﬁrms rather than of nations, the Chinese government has alignedits industrial policy with its politics.
 This is the big change; we never believedten years ago that China would build an entire ecosystem of Chinese-ownedSecurity Engineering849Ross Anderson26.
4.
 CENSORSHIPonline service providers to keep western inﬂuence at bay.
 Language providesone barrier, but there are strong technical barriers too: the perimeter defencesnow focus on blocking Tor and VPNs that could be used by Chinese residentsto use non-approved services.
Third, there are social defences.
 There were already 30,000 online policea decade ago; now many more citizens have been engaged in the process, andrather than trying to block all dissident speech the strategy is to swamp it.
 Loyalcitizens are expected to post lots of pro-regime comments and to ﬂame anybodywho criticises authority, whether local or national.
 A social credit system givespeople positive points for such pro-social behaviour, while they can lose pointsfor anything considered antisocial.
 Online monitoring is being integrated withthe monitoring of physical space, such as by CCTV cameras with face recog-nition and emotion recognition – which is particularly aggressive in areas withrebellious minority populations, such as the Tibetans and Uighurs.
 Since 2014,a system in Sinkiang for ‘re-education’ has pioneered a fusion of techniques fromthe western ‘war on terror’ and Maoist social control, leading to the internmentof hundreds of thousands of Muslims on the basis of a scoring system whoseinputs include whether a suspect prays regularly or has a VPN on their phone.
The U.
S.
 Congress has denounced this regime for ‘crimes against humanity’:dozens of the contractor companies have been placed on the sanctions list [359].
So China appears to be winning the censorship battle, using populist butauthoritarian techniques.
Russia’s Internet is fairly open, and although thegovernment had an ally take over the main social network, and has organisedarmies of trolls to shout down its opponents, the opposition politician AlexeiNavalny has his own YouTube channel with millions of viewers, and attemptsto censor Telegram have been met with street protests.
 Putin has fought backwith a ‘digital sovereignty’ law enabling him to order ISPs to install surveillanceand censorship equipment.
The Arab Spring has also been signiﬁcant.
 This series of uprisings started inTunisia in December 2010 after a street vendor, Mohamed Bouazizi, set himselfon ﬁre after an o�cial conﬁscated his wares and humiliated him.
 Protests wereorganised using Facebook and other social media, leading to the downfall of thegovernment, and spreading to neighbouring countries too.
 The government ofEgypt also fell, along with those of Libya and the Yemen; in Egypt’s case aGoogle employee, Wael Ghonim, turned Internet activist after the police beata man to death in Alexandria on suspicion that he had video evidence of theirinvolvement in a drug deal.
 The government of Syria almost fell, but foughtback in a civil war that killed hundreds of thousands and displaced millions.
A number of other Arab countries, such as Bahrain, su↵ered signiﬁcant unrestand cracked down.
 As I write in 2020, only Tunisia has managed the transitionto democracy.
 In Egypt, one military dictator has been replaced by another;Libya is in chaos, and Yemen, like Syria, is racked by war.
 The lesson drawn bythe world’s autocrats is that, to stay in power, they’d better study the methodsused by China.
 Arab countries do censor the Internet (as do most of the less-developed countries) but their infrastructure is still fairly easily defeated usingVPNs or Tor.
 They also buy in kit for both bulk surveillance and targeted work;for a description of how the UAE hired US mercenaries to set up an equivalentof the NSA, see Bing and Schectman [247].
Security Engineering850Ross Anderson26.
4.
 CENSORSHIPTo what extent was the Arab Spring a function of technology, and to whatextent was this just marketing hype put out in 2011 by companies like Facebookand Google while things seemed to be going well? It’s unclear.
 Some of thepopulations that rose up made little use of the Internet, particularly those ofLibya and the Yemen; on the other hand, a revolt in Burma in 2007 was catalysedby the Internet, even though only 1% of the population had access [1471].
 Inthe Arab world, the Qatari TV station Al-Jazeera may have done more workthan the Internet, by showing news videos of uprisings elsewhere in the region.
26.
4.
2Filtering, hate speech and radicalisationDemocracies’ laws on hate speech vary widely.
 At one end, the USA has con-stitutional protection for free speech; so do France and Germany.
 But inter-pretations di↵er.
 France and Germany both prohibit the sale of Nazi memo-rabilia, and hate speech (‘Volksverhetzung’) has been a crime in Germany fordecades.
 In January 2018 the authorities started enforcing it against online ser-vice providers, with the threat of a ﬁne of e50m if any service provider withmore than 2m customers doesn’t take down any such material within 24 hours.
Whatever the service companies say about the cost of taking down bad stu↵,the German example shows they can do it when they have to.
 Many countriesnow ban terrorist material and extreme violence, the deﬁnition of which is neverstraightforward.
 It might seem a good thing to ban not just beheading videosbut all videos of murder, such as drug gangs shooting a customer who didn’tpay his debts.
 But it gets complex quickly.
 Platforms that enforce such a policyend up deleting evidence, both of local killings and of human-rights violationsoverseas.
Already much of the material you put online gets ﬁltered automatically tolook for material that’s forbidden by local laws, or by a platform’s terms ofservice.
 Facebook’s former CISO Alex Stamos described the tension betweenprivacy and censorship as a spectrum: people expect end-to-end encrypted chatsuch as WhatsApp to be private rather than censored, and broadcast media to becensored rather than private, with the di�cult stu↵ in the middle, like Facebookgroups.
 By now, most social media are censored.
 The platforms vary widely;Facebook is perhaps the tightest, and bans even nudity7; though it is muchmore forgiving of hate speech from President Trump than from others, and inreturn appears to receive much less attention on the antitrust front [1790].
 Au-thoritarian countries are becoming more aggressive about forcing service ﬁrmsto block content they deem to be illegal; for example, Facebook’s service wasslowed to a crawl in Vietnam in early 2020 until the company agreed to suppressdissent [1506].
Behind the AI systems that try to spot forbidden content are thousands ofcontent moderators.
 Filtering is expensive, and the costs are not just ﬁnan-cial, but human; we’ve seen an increasing number of news articles about thepsychological toll on sta↵ who have to spend all day looking at videos of gangmurders and terrorist beheadings, animal cruelty, child abuse, and other un-7Facebook bans photos of female nipples but not male ones, so dozens of naked womendemonstrated in 2019 in New York holding pictures of men’s nipples over their own; men andwomen demonstrated with pictures of female nipples [616].
Security Engineering851Ross Anderson26.
4.
 CENSORSHIPpleasantness [1438].
 Many moderators are in less developed countries; just aswe dump a lot of unpleasant refuse there, we also dump a lot of the Internet’snastiest trash [414].
 It’s also problematic to outsource censorship to large ser-vice monopolies.
 They act in a quasi-judicial manner, regulating the speechof billions of people but without the transparency and due process we expectof government decisions.
 The world sees them allowing abuse by the rich andpowerful while ignoring the weak.
 Perhaps it was inevitable that ﬁrms wouldsnuggle up to power and then try to direct political speech; this has become afactor in the backlash against the whole tech sector.
One focus of debate is section 230 of the US Communications Decency Actof 1996 (CDA) which states that ‘No provider or user of an interactive computerservice shall be treated as the publisher or speaker of any information providedby another information content provider’ so platforms cannot be held liablefor bad stu↵ provided by users; it also left platforms free to remove anything‘obscene, lewd, lascivious, ﬁlthy, excessively violent, harassing, or otherwiseobjectionable.
’ When it passed the CDA, Congress was concerned that ﬁrmsthat moderated content could be treated as publishers and held liable for all ofit (including copyright infringement and libel) while ﬁrms that didn’t would betreated as distributors and escape liability.
 How could we get a civil internetwithout killing innovation? Section 230 made ﬁrms like YouTube and Facebookpossible, but protected sites whose business model is based on revenge porn,defamation, or getting a cut of illegal gun sales [1419].
 It also enabled serviceﬁrms to acquire some of the powers of states.
Back then, the Internet had10-20m users, mostly geeks; now most human activity is online, and it’s notsustainable for a handful of American ﬁrms to act as censor, prosecutor andjudge for 200-odd countries.
 As a result the CDA, and similar laws elsewhere,are starting to be trimmed: in the USA in 2018 with laws on sex tra�cking andin Europe with a 2019 law on copyright [1598].
 The tensions can only get worse.
When making laws to restrict speech, it’s a good idea to stop and look at thehistorical context.
 Tim Wu’s ‘The attention merchants’ [2050] is a history ofpropaganda since the 1830s when the ﬁrst mass-market newspapers appeared,stu↵ed with grisly crime reports and adverts for patent medicines; this gavepoliticians their ﬁrst industrial mass-market channel.
 Radio followed, and wasused skilfully by Hitler.
 TV was next, and its nature was shaped by advertising;people invented quiz shows, soaps and much else to grab eyeballs.
 A seconduseful perspective is Yochai Benkler’s ‘Network propaganda’ which analyses the2016 US election campaign.
 He traces the history of political polarisation andargues that the root cause of the outcome wasn’t technology or Russian inter-ference so much as the asymmetric media systems of right and left that havedeveloped over the past 20 years; the left and centre-right are fact-based whilethe right is a propaganda feedback loop [227].
 A third perspective is the cri-tique of recommender systems by former Googler Tristan Harris: the platforms’algorithms learn that to maximise the time people spend on site, they shouldbe fed articles that stoke fear, anxiety and outrage.
The reactions of governments to fake news are mostly ine↵ective.
 The mostcapable may be Finland, which has been a target of Russian propaganda sinceTsarist times.
 Its government has been promoting critical thinking and me-dia literacy in schools and elsewhere since 2014, making it every citizen’s jobSecurity Engineering852Ross Anderson26.
4.
 CENSORSHIPto spot and counter information that’s designed to sow division.
In Britainwe have laws designed to please tabloid newspapers rather than to push backagainst them.
 Schoolteachers and university professors are supposed to reportstudents who seem at risk of being radicalised, and have procedures to ﬁgureout whether seminars or other talks could radicalise them; there are also lawsagainst online material that might lead them astray.
 If such an approach wereapplied consistently it might lead to banning much of the literature producedor funded by religious institutions from Saudi Arabia [1263], but action againstour largest arms export customer isn’t going to happen anytime soon.
 Whitesupremacists are at least as much of a threat, having murdered a member of theUK parliament during the Brexit campaign; but our government is much lesskeen on cracking down on them, and the people who broke the law by spend-ing too much money on that campaign (including Russian money) did not endup in jail, but at the heart of government.
 In general, Internet censorship letsthe government claim it’s doing something, but doesn’t really work well, andundermines whatever our diplomats might say about freedom of speech to theworld’s despots.
 I’d prefer to enforce existing laws on incitement to murder (andcampaign ﬁnance, leave other political material in the open, let the police mon-itor the tra�c to the worst of the sites, and train them to use the existing lawsbetter [642].
 In the longer term, the key is education, as Finland has shown.
As for targeting Muslim students, this runs directly against the criminologi-cal evidence.
 The few UK students who’ve signed up to extremist organisationshave been those who experienced lack of respect socially, perhaps being rejectedby their peers, were searching for identity but couldn’t ﬁnd it in the religion oftheir parents – then fell in with small groups of other disa↵ected youngsters.
They came under the inﬂuence of radical preachers, who o↵ered ideals, com-munity, kinship, caring and brotherhood.
 The radicalisation of white boys intowhite supremacist groups is not hugely di↵erent.
 Research by Max Abrahmsalso shows that terrorists mostly joined their movement in a search for social sol-idarity; that’s why they recruit from lonely young men rather than from amongpolitical activists.
 Their groups become institutions to which members cleave,rather than agents of change; that’s why they can respond to sensible peaceo↵ers with increased violence, and indulge in fratricidal conﬂict with similargroups [6].
 In fact, as Lydia Wilson pointed out after interviewing large num-bers of young people who’d gone to Syria to join Daesh and ended up in Kurdishjails, the process whereby young men (and occasionally women) ﬁnd their iden-tity by joining terror groups or crime gangs is no di↵erent from ﬁnding identityby joining religions, sports clubs or dance bands [2022].
 Zo¨e Quinn’s more re-cent experience of angry online mobs during the Gamergate drama, which wediscussed in section 2.
5.
1, draws much the same conclusion [1567].
 The peoplewho join extreme organisations in search of social solidarity need to think ofthemselves as the good guys; you need to undermine that, and you can’t do itby excluding them.
For all these reasons, it is unwise to model terrorist groups as rational eco-nomic actors, and just as unwise to try to prevent radicalisation on similar as-sumptions.
 The best approach is to have an environment that doesn’t excludepeople – one in which students get to know others from di↵erent backgrounds onthe staircase in their residence, in small teaching groups, and in project groups– and with hundreds of sports and student societies to choose from, so everyoneSecurity Engineering853Ross Anderson26.
5.
 FORENSICS AND RULES OF EVIDENCEcan ﬁnd a gang to belong to.
 That’s how great universities have always workedanyway.
26.
5Forensics and Rules of EvidenceOur last main policing topic is how information can be recovered from comput-ers, mobile phones and other electronic devices for use in evidence.
 This hasbeen getting more problematic over the past twenty years because of ﬁrst, thesheer volumes of data; and second, the fact that while much of it is seized fromplatforms such as mobile phones and laptops, more and more of it is held oncloud services that require paperwork and often quite substantial delays.
 Therising costs and operational di�culties lead to more selective law enforcement,with whole categories of online harms where states rarely intervene.
 As a result,many bad people, from cybercriminals to creeps, bullies and extremists, operateonline with near-total impunity.
26.
5.
1ForensicsComputer forensics has been a growing problem for the police since at least the1980s; by the early 2000s both the facilities and the sta↵ training were hopelesslybehind.
 The move of everything online during the 2010s has made matters stillworse.
 When the police raid even a small-time drug dealer nowadays, they canget half-a-dozen mobile phones, several laptops, and gadgets such as a navigatoror a Fitbit that hold his location history.
 The suspect may also have dozens ofaccounts for webmail, social-networking sites and other services.
 We have allsorts of clever ways of extracting information from the data – for example, youcan identify which camera took a picture from the pattern noise of the CCDarray [1192], and even use this to ﬁgure out which parts of a photo might havebeen tampered with.
The use of digital material in evidence depends, however, on both law andeconomics.
 Material has to be lawfully collected, whether with a search warrantor equivalent powers; and the forensic o�cer has to maintain a chain of custody,which means being able to satisfy a court that evidence wasn’t tampered withafterwards.
 That means using trustworthy tools to make evidential copies ofdata; to document everything that’s done; and to have means of dealing appro-priately with any private material that’s found (such as privileged lawyer-clientemails, or the trade secrets of a suspect’s employer).
 The traditional approachto computer forensics is described in standard textbooks such as Sammes andJenkinson [1644].
Since the world moved to smartphones and cloud services, the centre ofgravity has shifted to a handful of companies that sell mobile forensics tools topolice and intelligence agencies.
 They supply kiosks to police forces that enableunskilled o�cers to download mobile-phone contents, and to use the tokens onthem to download data from suspects’ accounts in the cloud.
 Some police forcesare working hard to get the legal issues sorted out (such as Police Scotland, whodon’t use ‘cloud forensics’ without a warrant) but many just grab and keep allthe data.
Security Engineering854Ross Anderson26.
5.
 FORENSICS AND RULES OF EVIDENCEAt the more sophisticated end of the trade, there’s an arms race betweenforensics and countermeasures.
 Police forces used to always turn PCs o↵, sothat hard disks could be copied for prosecution and defence lawyers.
 Phishinggangs exploited this by making their phishing software memory-resident, so thatthe evidence would self-destruct.
 And since laptops started to ship with decentencryption, the risk is multiplied.
 By 2013, when the FBI arrested Ross Ulbricht– the creator of the Silk Road underground drugs market – one agent’s missionwas to put his hand in the laptop to stop Ulbricht closing it, and he already hadthe right kind of power cord to plug it in [482].
In the old days, people – and small businesses – who got caught up in apolice investigation and had their computers seized could wait years to get themback, even if they were just a bystander, or if they were charged but eventuallyacquitted.
 Nowadays, people have seizure-proof o↵site backup thanks to cloudservices.
These services also make life harder for the police where suspects’material sits on servers overseas.
 The ﬁght between Facebook and GCHQ Ireferred to in Section 26.
2.
8 arose when two terrorists murdered a British soldier,Lee Rigby, near Woolwich barracks in March 2013 by running him over witha car and then stabbing him.
 While they were at the crime scene, facing o↵against the police, Facebook fed the police and security services data instantly,but once the two had been shot and were in custody in hospital, requests had togo through the UK/US mutual legal assistance treaty.
 This involves the policeﬁling forms at the US Embassy in London that are then considered at length inthe Department of Justice in Washington.
 The forms are often sent back as UKpolice sta↵ don’t understand US law and complete them incorrectly.
 Even whereeverything goes right, it can take six weeks for the FBI to serve the paperworkon Facebook in Menlo Park, California, and collect the data.
 So we found we’dgone from a world in which, after a raid, the police would have your data andyou wouldn’t, to one in which you still have your data but the police don’t –unless you cooperate, or unless you’re a serious enough bad guy to be worth thetime and attention of diplomats.
Since about 2017, there’s been a third option: cloud forensics.
 What thismeans in practice is that your phone is hacked by the police’s forensic kioskand gives up access tokens to your email, your photos, your Facebook and yourother cloud services.
 Some UK police forces think this is wonderful; they treatthe downloaded data as ‘data at rest’ as if it had been found on the phone itselfand keep it forever.
 Others consider that it can only be obtained by consent orwith a further warrant.
 The incentives to grab cloud data are strong, but themechanisms involved (phone hacking followed by impersonation of the user) arelikely to strike most citizens as unfair.
 And ever more devices are now acquiringan attached cloud service and an app.
 Will the police investigate tra�c o↵encesin future by seizing the driver’s phone and using it to download the car’s logsfrom the manufacturer’s server?This is a current policy topic in 2020: forexample, the UK privacy regulator called for a statutory code of practice tobe developed [958].
 As it happens, courts already have some rules about whatevidence can be used.
Security Engineering855Ross Anderson26.
5.
 FORENSICS AND RULES OF EVIDENCE26.
5.
2Admissibility of evidenceWhen courts were ﬁrst confronted with computer evidence in the 1960s therewere many concerns about its reliability.
 There was not just the engineeringissue of whether the data were accurate, but the legal issue of whether computer-generated data were inadmissible as hearsay.
 Di↵erent legislatures tackled thisdi↵erently.
 In the US, most of the law is found in the Federal Rules of Evidencewhere 803(6) allows computer data to be introduced as records ‘made at ornear the time by, or from information transmitted by, a person with knowledge,if kept in the course of a regularly conducted business activity.
.
.
unless thesource of information or the method or circumstances of preparation indicatelack of trustworthiness.
’ The UK is similar, and the rules of electronic evidencein the common-law countries (including Canada, Australia, South Africa andSingapore) are analysed by Stephen Mason [1236].
The deﬁnition of ‘writing’ and ‘signature’ is of interest, and varies by juris-diction.
 In Britain, courts took the view that an email is writing just as a letteris: the essence of a signature is the signer’s intent [2042, 2043].
 The US approachwas similarly pragmatic.
 In 2000, Congress enacted the Electronic Signaturesin Global and National Commerce (‘ESIGN’) Act, which gives legal force to any‘sound, symbol, or process’ by which a consumer assents to something.
 So press-ing a telephone keypad (‘press 0 to agree or 9 to terminate this transaction’),clicking a hyper-link to enter a web site, or clicking ‘continue’ on a softwareinstaller, the consumer consents to be bound to a contract [669].
 This makesclick-wrap licenses perfectly valid in America.
 Nonetheless, Docusign has builta business o↵ering digital signatures as a service for ﬁrms who want somethinga bit more showy.
In Europe the Electronic Signature Directive, which came into force in 2000,gave special force to an advanced electronic signature, which basically meansa digital signature generated with a smartcard or hardware security module.
Europe’s smartcard industry thought this would earn them lots of money, butit languished for years.
 In many countries, the risk that a paper check will beforged is borne by the relying party: if someone forges a check on my account,then it’s not my signature, and I have not given the bank my mandate to debitmy account; so if they negligently rely on a forged signature and do so, that’stheir lookout.
 However, if I ever accept an advanced electronic signature device,then I become liable to anyone in the world for any signature that appears tohave been made by this device, regardless of whether or not I actually made it!This, coupled with the facts that smartcards don’t have a trusted user inter-face and that the PCs which most people would use as an interface are easilysubverted, made such electronic signatures unattractive.
 Following further lob-bying, Europe updated the law with the eIDAS Regulation (910/2014) whichtries to improve the incentives for adoption, by requiring all organisations deliv-ering public services to accept electronic signatures since 2018.
 A number of EUcountries now insist that you use such a signature to ﬁle your taxes, rather thanpermitting it.
 There’s a hierarchy whereby a signature can be ‘advanced’ or‘qualiﬁed’ depending on the certiﬁcation of the technology used, and a qualiﬁedelectronic signature must be accepted for any purpose for which a handwrit-ten signature was previously required.
 Dozens of signature creation productswere duly certiﬁed and brought to market.
 The assurance mechanisms usedSecurity Engineering856Ross Anderson26.
5.
 FORENSICS AND RULES OF EVIDENCEto certify such products are defective in many ways, as I will discuss later insection 28.
2.
7.
2.
 The European Commission duly made a reference implementa-tion available to help governments get started with verifying all the signatures;in 2019 bugs were discovered in it that would let any citizen impersonate anyother [429].
26.
5.
3What goes wrongMany things can go wrong with police investigations, and the computerised kindare no di↵erent.
 An old pitfall is relying on evidence extracted from the sys-tems of one party to a dispute, without applying enough scepticism about itsdependability.
 Recall the Munden case described in Section 12.
4.
3.
 A man wasfalsely accused and wrongly convicted of attempted fraud after he complainedof unauthorized withdrawals from his bank account.
 On appeal, his defenceteam got an order from the court that the bank open its systems to the defenceexpert as it had done to the prosecution.
 The bank refused, the bank state-ments were ruled inadmissible and the case collapsed.
 The same has happenedmultiple times since then, including two terror cases involving curfew tags whichI discussed in section 14.
4.
The worst failure of computer evidence of which I’m aware was OperationOre.
 After the US Postal Service raided a porn site in Texas, they discoveredhundreds of thousands of credit card numbers that they thought had been usedto buy child sex abuse images, and some eight thousand of these were fromUK cardholders.
Some 3,000 homes got raided in the early 2000s, until thepolice ﬁnally realised that most of the cardholders were probably victims ofcard fraud.
 The vice squad used unskilled sta↵ in their initial analysis of theseized material, and were slow to learn – because they were ﬁxated on gettingporn convictions, because they didn’t have the forensic capacity to process allthe seized computers quickly, because they didn’t understand card fraud (theypreferred to leave that to the banks) and because of politics (Prime MinisterTony Blair himself had ordered the raids).
 So several thousand men had theirlives disrupted for months or even years, and the sad story of police bungling andcover-up is told by Duncan Campbell in [375, 376].
 For some, the revelationthat the police had screwed up came too late; over thirty men, faced withprosecution, killed themselves.
 At least one of them, Commodore David White,commander of British forces in Gibraltar, appears to have been innocent [886].
The gangsters in Indonesia and Brazil who organised and photographed thechild abuse do not seem to have been seriously pursued.
 America handled thiscase much better.
 Some 300,000 US credit card numbers were found on thesame servers, but US police forces used the data for intelligence rather thanevidence, identifying suspects of concern – such as people working with children– and quietly investigating them.
 Over a hundred convictions for actual childabuse followed.
Sometimes systems are deliberately designed to not provide evidence; anexample is the policy adopted by Microsoft after embarrassing emails came outduring their antitrust battles with the US government in the 1990s.
 The ﬁrmreacted with a policy that all emails are discarded after a ﬁxed period of timeunless someone takes positive action to save them, and many other ﬁrms followedSecurity Engineering857Ross Anderson26.
6.
 PRIVACY AND DATA PROTECTIONsuit.
 Another example is the move by service ﬁrms in the mid-2010s to adoptend-to-end encryption, so they don’t have access to customer message tra�cand don’t have to employ hundreds of lawyers to deal with requests for it.
The biggest problem with computer forensics, though, has always been sheerlack of money.
 Despite all the cool tricks that intelligence agencies can use toextract information from computer systems, a county drugs squad often won’thave the budget to do even basic computer forensics except for occasional bigcases.
 They can’t even a↵ord to send every wrap of white powder o↵ to thelab to see if it’s illegal or not.
In normal cases, they were only able to usedigital material that was easily available, such as copies of messages on thephones of cooperative witnesses, until mobile-phone forensic kiosks came alongaround 2016–8 and made masses of data available from seized handsets at lowmarginal costs.
 Hence the huge pressure to use the kiosks, even before robustlegal procedures could be developed.
 And, of course, the use of forensic toolsby regular police o�cers with no specialist training raises the risk of futuremiscarriages of justice.
 Judicial education is also an issue; few judges understandprobability theory, and indeed the UK Court of Appeal has refused to acceptanalysis of evidence based on Bayes’ theorem.
 Quite apart from the injustice of acourt system that denies mathematics, there’s the practical issue that defendantsfaced with computer evidence that’s the result of bugs, or simply misrepresented,may have no practical way to prove their innocence.
26.
6Privacy and Data ProtectionPrivacy and data protection are one subject on which the USA and Europe havetaken separate paths.
 A concentrated interest (such as business wanting to useour personal information to exploit us) usually prevails over a di↵use interest(such as the desire of individuals to keep control of our personal information),and the usual remedy is law.
 The remedy is imperfect because the concentratedinterest lobbies the lawmakers and will attempt to capture any regulator theyset up.
 And Europe, for historical reasons regulates more than America does.
The resulting gulf was highlighted powerfully in May 2014 when, in the USA, thePresidential Council of Advisers on Science and Technology (PCAST) published“Big Data: A Technological Perspective” [1546].
 This report, whose authorsincluded Google’s Eric Schmidt and Microsoft’s Craig Mundie, painted a pictureof a world full of smart objects connected to cloud servers, with an ecology inwhich sensors reported to cloud analytics which in turn provided information tousers, such as advertisers.
 PCAST warned that the spread of voice and gestureinterfaces meant that pretty soon, every inhabited space on the planet wouldhave microphones and cameras in it, whose output would be processed centrallyfor energy e�ciency.
 They argued that privacy controls could not be imposedon the sensors, as they’ll be too numerous; that they should not be imposed onthe central service aggregators; and that the controls would therefore have tofall on how the information was used.
Less than two weeks later, the European Court of Justice disagreed.
ASpanish lawyer, Mario Costeja Gonz`alez, had complained that searches for hisname brought up two ancient press reports of an auction sale of his repossessedSecurity Engineering858Ross Anderson26.
6.
 PRIVACY AND DATA PROTECTIONhouse.
 He asked the Spanish data protection authorities to order Google to stopserving these results as they were out of date and no longer relevant.
 Googleargued that it was just reporting the contents of a newspaper.
 The case wentto the ECJ, which found in Gonz`alez’ favour, creating what the media colour-fully if inaccurately called a ‘right to be forgotten’, later codiﬁed into Europe’sGeneral Data Protection Regulation from 2018.
 Google and other online ser-vice providers had to set up mechanisms whereby people could complain aboutsearch results that are ‘inadequate, irrelevant or no longer relevant, or excessivein relation to the purposes for which they were processed’ and have them re-moved.
 The mechanisms are contentious: Gonz`alez’ results are removed fromGoogle searches in Spain, but European regulators want them removed globally.
Google’s supporters claim that this would interfere with its right to free speechin the USA.
How did this rift come about?26.
6.
1European data protectionFear of technology undermining privacy isn’t a recent development.
 As earlyas 1890, Justices Warren and Brandeis warned of the threat to privacy posedby ‘recent inventions and business methods’ – speciﬁcally photography and in-vestigative journalism [1988].
 After banks, tax collectors and welfare agenciesstarted using computers in the early 1960s, people started to worry about theprivacy implications if all our transactions could be collated and analyzed.
 InEurope, business argued that only government could a↵ord enough computersto be a serious privacy threat.
 This became a human-rights issue, given livingmemory of the Gestapo in most European countries and of communist secretpolice forces in the East8.
A patchwork of data protection laws started to appear starting with the Ger-man state of Hesse in 1969.
 Because of the rate at which technology changes,the successful laws have been technology neutral.
 Their common theme was aregulator (whether at national or state level) to whom users of personal datahad to report and who could instruct them to cease and desist from inappro-priate processing.
 The practical e↵ect was usually that the general law becameexpressed through a plethora of domain-speciﬁc codes of practice.
Over time, processing by multinational businesses became an issue too, andpeople realised that purely local or national initiatives were likely to be ine↵ec-tive against them.
 Following a voluntary code of conduct promulgated by theOECD in 1980 [1476], data protection was entrenched by a Council of Europeconvention in January 1981, which entered into force in October 1985 [475].
Although strictly speaking this convention was voluntary, many states signedup to it for fear of losing access to data-processing markets.
 It required cer-tain minimum safeguards for personal information, which generally means anydata kept on an identiﬁable human being, or data subject, such as bank account8In Germany, privacy is now entrenched in the constitution, and trumps even the ‘war onterror’.
 The highest court found unconstitutional a 2001 police action to create a ﬁle on over30,000 male students or former students from Muslim-majority countries – even though no-onewas arrested as a result.
 It ruled that such exercises could be performed only in response toconcrete threats, not as a precautionary measure [344].
Security Engineering859Ross Anderson26.
6.
 PRIVACY AND DATA PROTECTIONdetails and credit card purchasing patterns.
 Data subjects have the right toinspect personal data held on them, have records changed if inaccurate, un-derstand how they’re processed, and in many cases prevent them being passedon to other organizations without their consent.
 Almost all commercial dataare covered.
 There are exemptions for national security, but they are not ascomplete as the spooks would like: there was a big row when it turned out thatdata from SWIFT, which processes interbank payment instructions, were beingcopied to the Department of Homeland Security without the knowledge of datasubjects; SWIFT eventually agreed to stop processing European data in theUSA [1485, 1486].
The quality of implementation varied widely.
 In the UK, for example, Mar-garet Thatcher unashamedly did as little as possible to comply; a data protectionbody was established but starved of funds and technical expertise, and many ex-emptions were provided for both government and industry9.
 In Germany, whichhad written a right to privacy into its post-war constitution, the data protectionbodies became proper law-enforcement agencies.
 Many other countries, such asAustralia, Canada, New Zealand and Switzerland passed comparable privacylaws in the 1980s and early 1990s: some, like Switzerland, went for the Germanmodel while others, like Iceland and Ireland, followed the British one.
By the early 1990s the di↵erence between national laws was creating barriersto trade.
Some businesses avoided controls altogether by moving their dataprocessing to the USA.
 So data protection was ﬁnally elevated to the status ofEuropean Union law in 1995 with a Data Protection Directive [647].
 This sethigher minimum standards than before, with particularly stringent controls onhighly sensitive data such as health, religion, race and political a�liation.
 Italso set out to prevent personal information being shipped to ‘data havens’ suchas the USA in the absence of comparable controls enforced by contract or treaty.
The British implementation was again minimal, falling far short of Europeanrequirements [597].
 For example, data controllers could pretend that lightly-anonymised information was no longer personal information, just so long asthey themselves did not possess the auxiliary data needed to re-identify it.
 TheInformation Commissioner’s O�ce was overwhelmed, and severely conﬂictedas a result of being simultaneously the public sector’s adviser on privacy andthe privacy enforcer; the enforcement arm was reluctant to take action againstsystems blessed by their colleagues in the advisory arm.
 Ireland’s enforcementwas even weaker – its industrial strategy for the past 50 years has been to attractUS ﬁrms’ European headquarters.
 So in addition to having low corporate taxes,the Dublin government located its data protection o�ce in Portarlington, a townof less than 10,000 people, gave it only 30 sta↵, and did not allow it to publicisethe results of investigations.
This so annoyed countries with tighter privacy laws such as France and Ger-many that they pushed for the General Data Protection Regulation (GDPR),which passed in 2016 and came into force in May 2018.
 This was the most heav-ily lobbied piece of European legislation ever, with over 3,000 amendments dis-cussed in committee in the European Parliament [82]; it was helped over the line9In one case where you’d expect there to be an exemption, there wasn’t; journalists whokept notes on their laptops or PCs which identiﬁed people were formally liable to give copiesof this information to the data subjects on demand.
Security Engineering860Ross Anderson26.
6.
 PRIVACY AND DATA PROTECTIONby the Snowden disclosures, although it had been cooking for some time beforethat10.
 GDPR took direct e↵ect in all EU member states, removing the wriggleroom for Britain or Ireland to introduce loopholes; but lobbyists got quite afew of those in the Regulation already (particularly for ‘research’, whether ofthe scientiﬁc or marketing kind).
 The main e↵ect on normal businesses is toforce them to document all their uses of personal information and write down,in advance, what the legal basis is for each of them; it’s not enough to try andﬁgure things out once challenged.
 For information-intensive businesses, the im-plications could be more signiﬁcant, and there have been fascinating disclosuresof how Facebook executives lobbied to amend the regulation – e↵ectively usingthe Irish prime minister, Enda Kenny, as their advocate in Brussels [1418].
Despite the many carve-outs inserted by the lobbyists, GDPR is still pro-viding regulators with tools to push back.
 France ﬁned Google e50m for failingto tell users enough about its data consent policies or give them enough controlover how their information is used [1534].
 The fact that consent can no longerbe coerced or presumed may become a big deal, and there are many furthercases in the pipeline.
26.
6.
2Privacy regulation in the USAIn the USA, business has mostly managed to persuade government to leaveprivacy largely to ‘self-regulation’.
 Although there’s a patchwork of state andfederal laws, they are application-speciﬁc and fragmented.
 In general, privacy infederal government records and in communications is regulated, while businessdata are largely uncontrolled.
 The few islands of regulation include the FairCredit Reporting Act of 1970, which governs disclosure of credit informationand is broadly similar to European rules; the Video Privacy Protection Actor “Bork Bill”, enacted after a Washington newspaper published Judge RobertBork’s video rental history following his nomination to the US Supreme Court;the Drivers’ Privacy Protection Act, enacted to protect privacy of DMV recordsafter the actress Rebecca Schae↵er was murdered by an obsessed fan who hireda private eye to ﬁnd her address; and the Health Insurance Portability andAccountability Act which protects medical records and which I discussed inChapter 9.
 Most states also have a breach disclosure law, which requires ﬁrmssu↵ering any security failure that compromises residents’ personal informationto inform them about it.
 Several torts also provide a basis for civil action in asurprising number of circumstances; for a survey, see Daniel Solove [1801].
The ﬁrst case that started to put privacy on CEOs’ radar came in 2006,when Choicepoint paid $10m to settle a lawsuit brought by the FTC after itfailed to vet subscribers properly and let crooks buy the personal information ofover 160,000 Americans, leading to at least 800 cases of ‘identity theft’ [671].
 In2007, it came out that the store chain TJ Maxx had had 45.
7 million customers’credit card details stolen [1159]; Albert Gonzales got 20 years in prison for thisin 2010, and it’s reckoned that the breach cost the company $800m.
 The FTCsued Facebook over deceptive changes to privacy settings and settled in 2011,just before its IPO, requiring it to get user consent for certain changes and10Snowden revealed some egregious abuses such as the large-scale collection of by GCHQof Yahoo video chats in Operation Optic Nerve, including intimate video chats [14].
Security Engineering861Ross Anderson26.
6.
 PRIVACY AND DATA PROTECTIONsubjecting it to 20 years of audits [181].
 The real shock to CEO-land camewhen Target’s CEO, Gregg Steinhafel, was ﬁred in May 2014 following a hackof more than 100m credit card numbers the previous December; the CIO wasalso replaced [702].
 The C-suite carnage has continued, both in the USA11 andelsewhere12 moving cybersecurity steadily up the corporate agenda.
In 2018, California passed a consumer privacy law, the California ConsumerPrivacy Act (CCPA).
 This followed a privacy ballot initiative which, if it hadgone to a ballot and passed, would have entrenched an even tougher privacylaw.
 The ballot in turn followed the Cambridge Analytica scandal where theFacebook data of 87 million users was harvested without their knowledge orconsent and used to target behavioural advertising during the 2016 electioncampaign.
 The big tech companies’ defence was to negotiate the new law insteadof the ballot initiative, so they could have it amended later, or even trumpedby a Federal law.
 CCPA is somewhat similar to European data-protection law:it empowers consumers to request the deletion of personal information, opt outof its sale, and access it in a format that enables its transfer to third parties.
The European right to be forgotten is a non-starter thanks to the US FirstAmendment.
 CCPA can be enforced by the state attorney general but also byprivate action.
 A really important policy question now is whether this law isprogressively copied by other states, or whether Big Tech manages to emasculateit13.
 But the USA is not the only serious player here.
26.
6.
3Fragmentation?Since 1998, European law has forbidden companies from sending personal datato organizations in countries where the law does not provide comparable pro-tection or other safeguards – in practice, that means America and India.
 Theﬁrst attempt to resolve this was the Safe Harbour Agreement whereby a dataprocessor in America or India would promise their European customer to abideby European law.
 In 2000, the European Commission adopted an executivedecision to the e↵ect that this would give ‘adequate protection’.
 However, it leftno practical recourse for EU citizens who felt their rights had been violated.
The case that killed Safe Harbour was brought by Max Schrems, an Austrianlawyer, against Facebook.
 Following the Snowden revelations, he argued thatfor Facebook in Ireland (its EU headquarters) to pass his data to the USA forprocessing was unlawful, as the law and practice of the United States o↵er noprotection against surveillance by the public authorities, speciﬁcally the NSA,which can collect it all via Prism.
 The European Court of Justice agreed andin 2015 it struck down the Safe Harbour principles.
 The USA and the EU thenagreed to replace them with a fresh arrangement, called Privacy Shield, which11Amy Pascal of Sony in 2014, Walter Stephan of FACC in 2016, Richard Smith of Equifaxin 2017; and maybe we can note Marissa Meyer of Yahoo who forfeited her bonus and stockin 2017, and perhaps even Travis Kavalnick of Uber whose successor publicised a hack thathad been covered up.
12Dido Harding of TalkTalk, UK, in 2017; Bruce Liang of Integrated Health InformationSystems, Singapore, in 2019; and maybe we can count Martin Winterkorn of VW and RupertStadler of Audi too, who presided over the company hacking its car emissions.
13Their lobbyists are already attacking it, but as I write in 2020, there’s a ballot initiativethat would entrench it in California law and put it beyond the grasp of state legislators.
Security Engineering862Ross Anderson26.
6.
 PRIVACY AND DATA PROTECTIONadds and ombudsperson to whom an EU citizen can complain if they think theNSA might have spied on them [1474]; Max too this to the European Courtof Justice, which duly struck it down in July 2020[1683].
 The defendant wasthe Irish Data Protection Commissioner, who spent almost e3M defending theposition that she had the right to look the other way as US tech ﬁrms withtheir EU headquarters in Ireland ride roughshod over privacy law.
 The courtalso ruled that privacy authorities have a duty to take action when they receivea complaint.
 It also made clear that the NSA’s right under US law to get freeaccess to the data of people who are not US persons is not consistent with USﬁrms keeping data on EU citizens under US custody and control14.
Many companies that process data in the USA had in the meantime fallenback on contract, forcing customers to agree to their personal data being sharedbefore they do business with them.
 This has a long and sordid history (it’s howmedical insurers get away with selling your data to drug companies), and theECJ allowed the continued use of standard contractual clauses (SCCs) to protectdata.
 But this isn’t straightforward.
 First, the data controller has to establishthat there’s an adequate level of protection in the country where the data willbe held, and second, you can’t simply impose such terms on consumers in theworld of the GDPR as coercive consent is speciﬁcally disallowed.
It is hardto see how US ﬁrms can establish adequacy when US law provides unfetteredaccess to foreigners’ data on US soil and the Snowden disclosures document thesystematic use (and, from the EU law viewpoint, abuse) of this access.
So this is developing into a real ﬁght, with real consequences for how andwhere the world’s server farms are located and controlled.
 Some of the better-informed ﬁrms assume that they will eventually have to process European datain Europe and under European law; Microsoft put a data centre in Germanyunder the control of a German trustee for a couple of years, but then changedits mind, while Google has done its privacy research and development for someyears in Munich.
 And public opinion in the USA isn’t that di↵erent from Europe:most Americans think their personal data is less secure now, that the risks ofsurveillance capitalism outweigh the beneﬁts, that they don’t understand what’sgoing on, that they have no control and neither companies nor government areaccountable for abuse, but that they just don’t have any alternative.
 Oh, and20% su↵ered some kind of online fraud in the last twelve months [144].
Meanwhile, data-protection law is pushing into new areas where it gives away of responding to abuses.
 For example, after the Brexit referendum, the UKInformation Commissioner ﬁned Facebook £500,00015 after they let CambridgeAnalytica harvest personal data on 87 million people worldwide, and used this totarget election ads in both the Brexit referendum and the US 2016 presidentialelection [957].
 As many modern practices in marketing and in political propa-ganda involve o↵ences under data-protection law, this gives scope for regulatory14There is also a case pending at the European Court of Human Rights, brought by BigBrother Watch against US mass surveillance [420], which has been granted an appeal to theGrand Chamber.
 If this goes the same way, the ECJ judgment will be extended to thosecountries that are members of the Council of Europe but not of the EU, such as the UK andRussia.
15The UK ﬁne was the maximum allowed under pre-GDPR data-protection law; since thenthe maximum is 4% of the defendant’s turnover, which should bring European penalties intoline with American ones.
Security Engineering863Ross Anderson26.
7.
 FREEDOM OF INFORMATIONinnovation.
 The US equivalent is the FTC’s use of truth-in-advertising law topunish ﬁrms that break their privacy policies or previous agreements about userprivacy; and Facebook was in due course ﬁned $5bn by the FTC.
 The Elec-tronic Privacy Information Center16 had been arguing arguing ever since theCambridge Analytica scandal broke that Facebook had violated the terms of its2011 settlement with the FTC.
26.
7Freedom of InformationInformation tends to ﬂow from the weak to the powerful, increasing their powerand making it harder for others to hold them to account.
 As James Madisonwrote:A popular government without popular information or the means ofacquiring it is but a prologue to a farce or a tragedy, or perhaps both.
Knowledge will forever govern ignorance: And a people who mean tobe their own Governors, must arm themselves with the power whichknowledge gives.
In the aftermath of Watergate, Congress passed the Freedom of InformationAct, and other countries followed; Britain got one in 199717.
More radicalversions have been tried: tax returns are published in Iceland and in some Swisscantons, and the practice cuts evasion, as rich men fear the loss of social statusthat a low declared income would bring.
 The most radical version is proposed byDavid Brin, in ‘The Transparent Society’ [322].
 He reasons that the falling costsof data acquisition, transmission and storage will make pervasive surveillancetechnologies available to the authorities, so the only real question is whetherthey are available to the rest of us too.
 He paints a choice between two futures– one in which the citizens live in fear of a Chinese–style policing system andone in which o�cials are held to account by public scrutiny.
 He argues thatessentially all information should be open – including, for example, all our bankaccounts.
 The cameras will exist: will they be surveillance cams or webcams?Social media often seem to be pushing us in that direction.
 In any case, Freedomof Information Acts typically let the citizen demand copies of information heldby the state unless there’s a good reason to withhold it, and help ensure thatthe ﬂow of information between the citizen and the state isn’t entirely one-way.
However, transparency leads to interesting tussles.
 Many European coun-tries have clean-slate laws whereby most criminal convictions are expunged aftera period of time that depends on the severity of the o↵ence, and in 2019 Penn-sylvania, Utah and California followed suit [607].
 But how can such laws beenforced now that web search engines exist? Do you tag the names of o↵endersin newspaper accounts of trials with an expiration date, and pass laws com-pelling search and archive services to respect them? The Google Spain casegives us the answer: someone whose conviction has expired has a right to haveit suppressed in searches, although it may remain in the newspaper archive forthose who know where to look.
16Full disclosure: I’m a member of their advisory board.
17Tony Blair later described it as his biggest mistake.
Security Engineering864Ross Anderson26.
8.
 SUMMARYThat’s one example of the shifting boundary between data protection andfreedom of information.
 Another has been the monitoring of former child sex of-fenders, with laws in some states requiring that registers of o↵enders be publiclyavailable, and riots in the UK following the naming of some former o↵enders bya Sunday newspaper and at least one innocent person being lynched.
 A thirdis the release of crime statistics: home owners object to their neighbourhoodbeing stigmatised, and if the data are too granular there may be some risk ofindividual victims being identiﬁed.
 For further examples, see Section 11.
1 oninference security.
26.
8SummaryPublic policy is increasingly entangled with the work of the security engineer.
The largest single concern of governments, if we measure it in dollar terms, isintelligence; a typical government spends a hundred times more money collectinginformation on its enemies, real and potential, than it does on ﬁghting cyber-crime.
Intelligence collection is also in conﬂict with both defensive securityand with privacy, both of which have historically come second.
 However, sincethe Snowden revelations made clear the scale of US data collection worldwide,and of Five Eyes operations against allied countries, the balance has started toshift, and the e↵ects have propagated through privacy and data protection law,albeit slowly and with so far little e↵ect on the agencies themselves.
 Perhapswhen the analysis is done, Snowden’s e↵ect on the agencies’ capabilities will belargely technical (through getting people to use cryptography more, and moreintelligently) while the policy e↵ect may be to curb some of the excesses of‘surveillance capitalism’ by making privacy more salient to more people.
 Thestrains between the US and European ways of dealing with privacy are becomingmore signiﬁcant and in the medium term we may see more localisation – whereUS companies have to keep data on EU citizens on servers in Europe and perhapseven under the control of European trustees.
 Other countries are starting tofollow suit.
Censorship is a real issue; some countries, like China, ban many of the largeUS service ﬁrms outright, while more and more are demanding that they takedown not just abusive material but also material that o↵ends local politicalsensitivities.
 The Internet still makes it harder for countries that won’t go asfar as China to censor subversive content, but much of the optimism we had tenyears ago has dissipated with the failure of the Arab Spring.
 Even the developedcountries push the large service ﬁrms to moderate and ﬁlter user-generatedcontent at scale, and despite the cost and complexity, it’s becoming universalexcept on end-to-end encrypted services.
 It’s now 25 years since AOL barredusers from living in Scunthorpe, and large-scale ﬁltering still raises a host ofpolicy issues whether we’re talking about copyright, radicalisation, harassmentor fake news.
The security-industrial complex, whose growth was fuelled by the climate offear whipped up after the 9/11 attacks, has got a second wind from China andthe Arab Spring, as the world’s authoritarians buy surveillance systems to keeptrack of their populations.
 This has led to the proliferation of computer andSecurity Engineering865Ross Anderson26.
8.
 SUMMARYnetwork exploitation tools that erode our security, our liberty, and our qualityof life.
 This proliferation is aided and abetted by Western governments whoshould know better, and is bound to be extended as social media ﬁrms andothers are co-opted into ever more content screening as a condition of doingbusiness.
 Understanding and pushing back on the surveillance ecosystem whilemitigating online harms is the highest priority for security engineers who havethe ability to get involved in public life – whether directly, or via our writingand teaching.
And research also helps.
Individual academics can’t hope tocompete with national leaders in the mass media, but the careful accumulationof data and knowledge over the years can and will undermine their excuses.
 Idon’t mean just knowledge about why extreme airport screening measures are awaste of money; we also must disseminate knowledge about the economics andpsychology that underlie maladaptive government behaviour, and its terribleconsequences in terms of spending money on security theatre that should havebeen spent on pandemic preparedness.
Research ProblemsTechnology policy involves a complex interplay between science, engineering,psychology, law and economics.
 There is still too little serious cross-disciplinaryresearch, and initiatives which speed up this process are almost certainly agood thing.
 Since 2002 I’ve worked to build up the security-economics researchcommunity; and since 2008 we’ve run an annual workshop on security and hu-man behaviour to engage psychologists, anthropologists and philosophers too.
But we need much, much more.
 Where are the historians, the sociologists andthe political scientists? (And perhaps if there’s a fourth edition, we’ll add thephilosophers.
)Further ReadingIt’s extraordinarily easy for technology policy arguments to get detached fromreality, and many of the scares conjured up to get attention and money (suchas ‘cyberterrorism’) are the modern equivalent of the monsters that appearedon medieval maps to cover up the cartographer’s ignorance.
 An engineer shouldlook for primary sources – from material written by experienced insiders suchas R.
V.
 Jones [992] to the thousands of documents leaked by Ed Snowden.
 Asfor the use of information warfare techniques in the Brexit referendum and the2016 US election, Carole Cadwalladr’s movie ‘The Great Hack’ is unmissable.
There’s a good book on the history of wiretapping and crypto policy byWhit Di�e and Susan Landau, who had a long involvement in the policy pro-cess [558], and an NRC study on cryptography policy was also inﬂuential [1411].
There’s a video on my website of the history of the crypto wars from a Europeanperspective.
The history of export control is tied up with Soviet attempts to buy UScomputer, semiconductor and energy technology during the 1970s and 80s, andthe US and French intelligence community’s work to block them and feed themSecurity Engineering866Ross Anderson26.
8.
 SUMMARYmisleading information: see the memoir on Gus Weiss, a CIA maverick involvedin this work [723].
Resources on online censorship include Reporters without Borders, who pub-lish a ‘Handbook for bloggers and cyber-dissidents’ on how to circumvent cen-sorship, with a number of case histories of how blogging has helped open up themedia in less liberal countries [1594].
The standard work on computer forensics is by Tony Sammes and BrianJenkinson [1644], while Privacy International has a survey of mobile phoneforensics [1555] and the Department of Justice’s “Guidelines for Searching andSeizing Computers” also bear some attention [550].
 For early computer crimecase histories, see Peter Neumann [1429] and Dorothy Denning [539].
 The stan-dard work on computer evidence in the common law countries is by StephenMason [1236].
On the topic of privacy versus data protection, there is a huge literaturebut no concise recent guide that I know of.
 Recent material can be found onthe web sites of organizations such as EPIC [631], EFF [618], FIPR [708] andEDRi [643], and of Max Schrems [1683].
As for the policy problems around the ﬁltering of inﬂammatory content andpropaganda, the two most thought-provoking books for me are those by TimWu [2050] and Yochai Benkler [227], while Facebook’s former CISO Alex Stamosnow discusses the tech companies’ view of ﬁltering political ads [999].
Finally, the deﬁnitive story of the Cambridge Analytica scandal is told in thebook by the whistleblower Chris Wylie [2052], and in the journalism by CaroleCadwalladr based on information that he and others supplied [363].
Security Engineering867Ross Anderson