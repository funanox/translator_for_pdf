Chapter 8EconomicsThe great fortunes of the information age lie in the hands ofcompanies that have established proprietaryarchitectures that are used by alarge installed base oflocked-in customers.
– CARL SHAPIRO AND HAL VARIANThere are two things I am sure of after all these years: there isa growing societal need for high assurance software, andmarket forces are never going to provide it.
– EARL BOEBERTThe law locks up the man or womanWho steals the goose from o↵ the commonBut leaves the greater villain looseWho steals the common from the goose.
– TRADITIONAL, 17th CENTURY8.
1IntroductionRound about 2000, we started to realise that many security failures weren’t dueto technical errors so much as to wrong incentives: if the people who guard asystem are not the people who su↵er when it fails, then you can expect trouble.
In fact, security mechanisms are often designed deliberately to shift liability,which can lead to even worse trouble.
Economics has always been important to engineering, at the raw level ofcost accounting; a good engineer was one who could build a bridge safely with athousand tons of concrete when everyone else used two thousand tons.
 But theperverse incentives that arise in complex systems with multiple owners make eco-nomic questions both more important and more subtle for the security engineer.
Truly global-scale systems like the Internet arise from the actions of millions ofindependent principals with divergent interests; we hope that reasonable global2638.
2.
 CLASSICAL ECONOMICSoutcomes will result from selﬁsh local actions.
 The outcome we get is typically amarket equilibrium, and often a surprisingly stable one.
 Attempts to make largecomplex systems more secure, or safer, will usually fail if this isn’t understood.
At the macro level, cybercrime patterns have been remarkably stable throughthe 2010s even though technology changed completely, with phones replacinglaptops, with society moving to social networks and servers moving to the cloud.
Network insecurity is somewhat like air pollution or congestion, in that peoplewho connect insecure machines to the Internet do not bear the full consequencesof their actions while people who try to do things right su↵er the side-e↵ects ofothers’ carelessness.
In general, people won’t change their behaviour unless they have an incentiveto.
 If their actions take place in some kind of market, then the equilibrium willbe where the forces pushing and pulling in di↵erent directions balance eachother out.
 But markets can fail; the computer industry has been dogged bymonopolies since its earliest days.
 The reasons for this are now understood, andtheir interaction with security is starting to be.
Security economics has developed rapidly as a discipline since the early 2000s.
It provides valuable insights not just into ‘security’ topics such as privacy, bugs,spam, and phishing, but into more general areas of system dependability.
 Forexample, what’s the optimal balance of e↵ort by programmers and testers? (Forthe answer, see section 8.
6.
3 below.
) It also enables us to analyse many impor-tant policy problems – such as the costs of cybercrime and the most e↵ectiveresponses to it.
 And when protection mechanisms are used to limit what some-one can do with their possessions or their data, questions of competition policyand consumer rights follow – which we need economics to analyse.
 There arealso questions of the balance between public and private action: how much ofthe protection e↵ort should be left to individuals, and how much should beborne by vendors, regulators or the police? Everybody tries to pass the buck.
In this chapter I ﬁrst describe how we analyse monopolies in the classicaleconomic model, how information goods and services markets are di↵erent, andhow network e↵ects and technical lock-in make monopoly more likely.
 I thenlook at asymmetric information, another source of market power.
 Next is gametheory, which enables us to analyse whether people will cooperate or compete;and auction theory, which lets us understand the working of the ad marketsthat drive much of the Internet – and how they fail.
These basics then letus analyse key components of the information security ecosystem, such as thesoftware patching cycle.
 We also get to understand why systems are less reliablethan they should be: why there are too many vulnerabilities and why too fewcyber-crooks get caught.
8.
2Classical economicsModern economics is an enormous ﬁeld covering many di↵erent aspects of humanbehaviour.
 The parts of it that have found application in security so far arelargely drawn from microeconomics, game theory and behavioral economics.
 Inthis section, I’ll start with a helicopter tour of the most relevant ideas frommicroeconomics.
 My objective is not to provide a tutorial on economics, but toSecurity Engineering264Ross Anderson8.
2.
 CLASSICAL ECONOMICSget across the basic language and ideas, so we can move on to discuss securityeconomics.
The modern subject started in the 18th century when growing trade changedthe world, leading to the industrial revolution, and people wanted to under-stand what was going on.
 In 1776, Adam Smith’s classic ‘The Wealth of Na-tions’ [1788] provided a ﬁrst draft: he explained how rational self-interest ina free market leads to progress.
 Specialisation leads to productivity gains, aspeople try to produce something others value to survive in a competitive mar-ket.
 In his famous phrase, “It is not from the benevolence of the butcher, thebrewer, or the baker, that we can expect our dinner, but from their regard totheir own interest.
” The same mechanisms scale up from a farmers’ market orsmall factory to international trade.
These ideas were reﬁned by nineteenth-century economists; David Ricardoclariﬁed and strengthened Smith’s arguments in favour of free trade, while Stan-ley Jevons, L´eon Walras and Carl Menger built detailed models of supply anddemand.
 One of the insights from Jevons and Menger is that the price of agood, at equilibrium in a competitive market, is the marginal cost of produc-tion.
 When coal cost nine shillings a ton in 1870, that didn’t mean that everymine dug coal at this price, merely that the marginal producers – those whowere only just managing to stay in business – could sell at that price.
 If theprice went down, these mines would close; if it went up, even more marginalmines would open.
 That’s how supply responded to changes in demand.
 (Italso gives us an insight into why so many online services nowadays are free; asthe marginal cost of duplicating information is about zero, lots of online busi-nesses can’t sell it and have to make their money in other ways, such as fromadvertising.
 But we’re getting ahead of ourselves.
)By the end of the century Alfred Marshall had combined models of supplyand demand in markets for goods, labour and capital into an overarching ‘clas-sical’ model in which, at equilibrium, all the excess proﬁts would be competedaway and the economy would be functioning e�ciently.
 By 1948, Kenneth Ar-row and G´erard Debreu had put this on a rigorous mathematical foundationby proving that markets give e�cient outcomes, subject to certain conditions,including that the buyers and sellers have full property rights, that they havecomplete information, that they are rational and that the costs of doing trans-actions can be neglected.
Much of the interest in economics comes from the circumstances in whichone or more of these conditions aren’t met.
 For example, suppose that trans-actions have side-e↵ects that are not captured by the available property rights.
Economists call these externalities, and they can be either positive or negative.
An example of a positive externality is scientiﬁc research, from which every-one can beneﬁt once it’s published.
 As a result, the researcher doesn’t capturethe full beneﬁt of their work, and we get less research than would be ideal(economists reckon we do only a quarter of the ideal amount of research).
 Anexample of a negative externality is environmental pollution; if I burn a coal ﬁre,I get the positive e↵ect of heating my house but my neighbour gets the negativee↵ect of smell and ash, while everyone shares the negative e↵ect of increasedCO2 emissions.
Security Engineering265Ross Anderson8.
2.
 CLASSICAL ECONOMICSExternalities, and other causes of market failure, are of real importance to thecomputer industry, and to security folks in particular, as they shape many of theproblems we wrestle with, from industry monopolies to insecure software.
 Whereone player has enough power to charge more than the market clearing price, ornobody has the power to ﬁx a common problem, then markets alone may not beable to sort things out.
 Strategy is about acquiring power, or preventing otherpeople having power over you; so the most basic business strategy is to acquiremarket power in order to extract extra proﬁts, while distributing the costs ofyour activity on others to the greatest extent possible.
 Let’s explore that nowin more detail.
8.
2.
1MonopolyAs an introduction, let’s consider a textbook case of monopoly.
 Suppose we havea market for apartments in a university town, and the students have di↵erentincomes.
 We might have one rich student able to pay $4000 a month, maybe 300people willing to pay at least $2000 a month, and (to give us round numbers) atleast 1000 prepared to pay at least $1000 a month.
 That gives us the demandcurve shown in Figure 8.
1 below.
Figure 8.
1: the market for apartmentsSo if there are 1000 apartments being let by many competing landlords, themarket-clearing price will be at the intersection of the demand curve with thevertical supply curve, namely $1000.
 But suppose the market is rigged – say thelandlords have set up a cartel, or the university makes its students rent througha tied agency.
 A monopolist landlord examines the demand curve, and noticesthat if he rents out only 800 apartments, he can get $1400 per month for eachof them.
 Now 800 times $1400 is $1,120,000 per month, which is more than themillion dollars a month he’ll make from the market price at $1000.
 (EconomistsSecurity Engineering266Ross Anderson8.
2.
 CLASSICAL ECONOMICSwould say that his ‘revenue box’ is the box CBFO rather than EDGO in ﬁgure8.
1.
) So he sets an artiﬁcially high price, and 200 apartments remain empty.
This is clearly ine�cient, and the Italian economist Vilfredo Pareto inventeda neat way to formalise this.
 A Pareto improvement is any change that wouldmake some people better o↵ without making anyone else worse o↵, and an allo-cation is Pareto e�cient if there isn’t any Pareto improvement available.
 Here,the allocation is not e�cient, as the monopolist could rent out one empty apart-ment to anyone at a lower price, making both him and them better o↵.
 NowPareto e�ciency is a rather weak criterion; both perfect communism (every-one gets the same income) and perfect dictatorship (the king gets the lot) arePareto-e�cient.
 In neither case can you make anyone better o↵ without makingsomeone else worse o↵! Yet the simple monopoly described here is not e�cienteven in this very weak sense.
So what can the monopolist do? There is one possibility – if he can chargeeveryone a di↵erent price, then he can set each student’s rent at exactly whatthey are prepared to pay.
 We call such a landlord a price-discriminating monop-olist; he charges the rich student exactly $4000, and so on down to the 1000thstudent whom he charges exactly $1000.
 The same students get apartmentsas before, yet almost all of them are worse o↵.
 The rich student loses $3000,money that he was prepared to pay but previously didn’t have to; economistsrefer to this money he saved as surplus.
 The discriminating monopolist managesto extract all the consumer surplus.
Merchants have tried to price-discriminate since antiquity.
 The carpet sellerin Istanbul who expects you to haggle down his price is playing this game, as is anairline selling ﬁrst, business and cattle class seats.
 The extent to which ﬁrms cancharge people di↵erent prices depends on a number of factors, principally theirmarket power and their information asymmetry.
 Market power is a measure ofhow close a merchant is to being a monopolist; under monopoly the merchantis a price setter, while under perfect competition he is a price taker who has toaccept whatever price the market establishes.
 Merchants naturally try to avoidthis.
 Information asymmetry can help them in several ways.
 A carpet seller hasmuch more information about local carpet prices than a tourist who’s passingthrough, and who won’t have the time to haggle in ten di↵erent shops.
 So themerchant may prefer to haggle rather than display ﬁxed prices.
 An airline isslightly di↵erent.
 Thanks to price-comparison sites, its passengers have goodinformation on base prices, but if it does discount to ﬁll seats, it may be able totarget its o↵ers using information from the advertising ecosystem.
 It can alsocreate its own loyalty ecosystem by o↵ering occasional upgrades.
 Technologytends to make ﬁrms more like airlines and less like small carpet shops; theinformation asymmetry isn’t so much whether you know about average prices,as what the system knows about you and how it locks you in.
Monopoly can be complex.
 The classic monopolist, like the landlord or cartelin our example, may simply push up prices for everyone, resulting in a clear lossof consumer surplus.
Competition law in the USA looks for welfare loss ofthis kind, which often happens where a cartel operates price discrimination.
During the late 19th century, railroad operators charged di↵erent freight ratesto di↵erent customers, depending on how proﬁtable they were, how perishabletheir goods were and other factors – basically, shaking them all down accordingSecurity Engineering267Ross Anderson8.
3.
 INFORMATION ECONOMICSto their ability to pay.
 This led to massive resentment and to railway regulation.
In the same way, telcos used to price-discriminate like crazy; SMSes used to costa lot more than voice, and voice a lot more than data, especially over distance.
This led to services like Skype and WhatsApp which use data services to providecheaper calls and messaging, and also to net neutrality regulation in a numberof countries.
 This is still a tussle space, with President Trump’s appointee atthe FCC reversing many previous net neutrality rulings.
However, many ﬁrms with real market power like Google and Facebook givetheir products away free to most of their users, while others, like Amazon (andWalmart), cut prices for their customers.
 This challenges the traditional basisthat economists and lawyers used to think about monopoly, in the USA atleast.
 Yet there’s no doubt about monopoly power in tech.
 We may have gonefrom one dominant player in the 1970s (IBM) to two in the 1990s (Microsoftand Intel) and a handful now (Google, Facebook, Amazon, Microsoft, maybeNetﬂix) but each dominates its ﬁeld; although Arm managed to compete withIntel, there has been no new search startup since Bing in 2009 (whose marketshare is slipping), and no big social network since Instagram in 2011 (now ownedby Facebook).
 So there’s been a negative e↵ect on innovation, and the questionwhat we do about it is becoming a hot political topic.
 The EU has ﬁned techmajors multiple times for competition o↵ences.
To understand what’s going on, we need to dive more deeply into how infor-mation monopolies work.
8.
3Information economicsThe information and communications industries are di↵erent from traditionalmanufacturing in a number of ways, and among the most striking is that thesemarkets have been very concentrated for generations.
 Even before computerscame along, newspapers tended to be monopolies, except in the biggest cities.
Much the same happened with railways, and before that with canals.
 Whenelectrical tabulating equipment came along in the late 19th century, it wasdominated by NCR, until a spin-o↵ from NCR’s Manhattan sales o�ce calledIBM took over.
 IBM dominated the computer industry in the 1960s and 70s,then Microsoft came along and took pole position in the 90s.
 Since then, Googleand Facebook have come to dominate advertising, Apple and Google sell phoneoperating systems, ARM and Intel do CPUs, while many other ﬁrms dominatetheir own particular speciality.
 Why should this be so?8.
3.
1Why information markets are di↵erentRecall that in a competitive equilibrium, the price of a good should be itsmarginal cost of production.
 But for information that’s almost zero! That’swhy there is so much free stu↵ online; zero is its fair price.
 If two or moresuppliers compete to o↵er an operating system, or a map, or an encyclopedia,that they can duplicate for no cost, then they will keep on cutting their priceswithout limit.
Take for example encyclopedias; the Britannica used to cost$1,600 for 32 volumes; then Microsoft brought out Encarta for $49.
95, forcingSecurity Engineering268Ross Anderson8.
3.
 INFORMATION ECONOMICSBritannica to produce a cheap CD edition; and now we have Wikipedia forfree [1718].
 One ﬁrm after another has had to move to a business model inwhich the goods are given away free, and the money comes from advertising orin some parallel market.
 And it can be hard to compete with services that arefree, or are so cheap it’s hard to recoup the capital investment you need to getstarted.
 So other industries with high ﬁxed costs and low marginal costs tendto be concentrated – such as newspapers, airlines and hotels.
Second, there are often network externalities, whereby the value of a networkgrows more than linearly in the number of users.
 Networks such as the telephoneand email took some time to get going because at the start there were only a fewother enthusiasts to talk to, but once they passed a certain threshold in eachsocial group, everyone needed to join and the network rapidly became main-stream.
 The same thing happened again with social media from the mid-2000s;initially there were 40–50 startups doing social networks, but once Facebookstarted to pull ahead, suddenly all young people had to be there, as that waswhere all your friends were, and if you weren’t there then you missed out onthe party invitations.
 This positive feedback is one of the mechanisms by whichnetwork e↵ects can get established.
 It can also operate in a two-sided marketwhich brings together two types of user.
 For example, when local newspapersgot going in the nineteenth century, businesses wanted to advertise in the paperswith lots of readers, and readers wanted papers with lots of small ads so theycould ﬁnd stu↵.
 So once a paper got going, it often grew to be a local monopoly;it was hard for a competitor to break in.
 The same thing happened when therailways allowed the industrialisation of agriculture; powerful ﬁrms like Cargilland Armour owned the grain elevators and meat-packers, dealing with smallfarmers on one side and the retail industry on the other.
 We saw the same pat-tern in the 1960s when IBM mainframes dominated computing: ﬁrms used todevelop software for IBM as they’d have access to more users, while many usersbought IBM because there was more software for it.
 When PCs came along,Microsoft beat Apple for the same reason; and now that phones are replacinglaptops, we see a similar pattern with Android and iPhone.
 Another winnerwas eBay in the late 1990s: most people wanting to auction stu↵ will want touse the largest auction, as it will attract more bidders.
 Network e↵ects canalso be negative; once a website such as Myspace starts losing custom, negativefeedback can turn the loss into a rout.
Third, there are various supply-side scale economies enjoyed by leading in-formation services ﬁrms, ranging from access to unmatchable quantities of userdata to the ability to run large numbers of A/B tests to understand user pref-erences and optimise system performance.
 These enable early movers to create,and incumbents to defend, competitive advantage in service provision.
Fourth, there’s often lock-in stemming from interoperability, or a lack thereof.
Once a software ﬁrm commits to using a platform such as Windows or Oraclefor its product, it can be expensive to change.
 This has both technical andhuman components, and the latter are often dominant; it’s cheaper to replacetools than to retrain programmers.
 The same holds for customers, too: it canbe hard to close a sale if they not only have to buy new software and convertﬁles, but retrain their sta↵ too.
 These switching costs deter migration.
 Earlierplatforms where interoperability mattered included the telephone system, theSecurity Engineering269Ross Anderson8.
3.
 INFORMATION ECONOMICStelegraph, mains electricity and even the railways.
These four features separately – low marginal costs, network externalities,supply-side scale economies and technical lock-in – can lead to industries withdominant ﬁrms; in combination, they are even more likely to.
 If users want tobe compatible with other users (and with vendors of complementary productssuch as software) then they will logically buy from the vendor they expect towin the biggest market share.
8.
3.
2The value of lock-inThere is an interesting result, due to Carl Shapiro and Hal Varian: that the valueof a software company is the total lock-in (due to both technical and networke↵ects) of all its customers [1718].
 To see how this might work, consider a ﬁrmwith 100 sta↵ each using O�ce, for which it has paid $150 per copy.
 It couldsave this $15,000 by moving to a free program such as LibreO�ce, so if thecosts of installing this product, retraining its sta↵, converting ﬁles and so on– in other words the total switching costs – were less than $15,000, it wouldswitch.
 But if the costs of switching were more than $15,000, then Microsoftwould put up its prices.
As an example of the link between lock-in, pricing and value, consider howprices changed over a decade.
 In the second edition of this book, this examplehad the cost of O�ce as $500; since then, cloud-based services that worked justlike O�ce, such as Google Docs, cut the costs of switching – so Microsoft had toslash its prices.
 As I started writing this edition in 2019, I saw standalone O�cefor sale at prices ranging between $59.
99 and £164.
 Microsoft’s response since2013 has been trying to move its customers to an online subscription service(O�ce365) which costs universities a few tens of pounds per seat depending onwhat options they choose and how good they are at negotiating, while Google isalso trying to move organisations away from their free services to paid G Suiteversions that cost about the same.
 Charging $30 a year for an online service isbetter business than charging $60 for a program that the customer might usefor ﬁve years or even seven.
 When I revised this chapter in 2020, I saw I cannow get a ‘lifetime key’ for about double the cost of a standalone product lastyear.
 There’s a new form of lock-in, namely that the cloud provider now looksafter all your data.
Lock-in explains why so much e↵ort gets expended in standards wars andantitrust suits.
 It also helps explain the move to the cloud (though cost cuttingis a bigger driver).
 It’s also why so many security mechanisms aim at controllingcompatibility.
 In such cases, the likely attackers are not malicious outsiders, butthe owners of the equipment, or new ﬁrms trying to challenge the incumbentby making compatible products.
 This doesn’t just damage competition, butinnovation too.
 Locking things down too hard can also be bad for business,as innovation is often incremental, and products succeed when new ﬁrms ﬁndkiller applications for them [903].
 The PC, for example, was designed by IBMas a machine to run spreadsheets; if they had locked it down to this applicationalone, then a massive opportunity would have been lost.
 Indeed, the fact thatthe IBM PC was more open than the Apple Mac was a factor in its becomingthe dominant desktop platform.
 (That Microsoft and Intel later stole IBM’sSecurity Engineering270Ross Anderson8.
3.
 INFORMATION ECONOMICSlunch is a separate issue.
)So the law in many countries gives companies a right to reverse-engineertheir competitors’ products for compatibility [1647].
 Incumbents try to buildecosystems in which their o↵erings work better together than with their com-petitors’.
 They lock down their products using digital components such as cloudservices and cryptography so that even if competitors have the legal right to tryto reverse engineer these products, they are not always going to succeed in prac-tice.
 Incumbents also use their ecosystems to learn a lot about their customers,the better to lock them in; while a variety of digital mechanisms are to con-trol aftermarkets and enforce planned obsolescence.
 I will discuss these morecomplex ecosystem strategies in more detail below in section 8.
6.
4.
8.
3.
3Asymmetric informationAnother way markets can fail, beyond monopoly and public goods, is whensome principals know more than others, or know it slightly earlier, or can ﬁndit out more cheaply.
 We discussed how an old-fashioned carpet trader has aninformation advantage over tourists buying in his store; but the formal study ofasymmetric information was kicked o↵ by a famous paper in 1970 on the ‘marketfor lemons’ [34], for which George Akerlof won a Nobel prize.
 It presents thefollowing simple yet profound insight: suppose that there are 100 used carsfor sale in a town: 50 well-maintained cars worth $2000 each, and 50 ‘lemons’worth $1000.
 The sellers know which is which, but the buyers don’t.
 What isthe market price of a used car?You might think $1500; but at that price, no good cars will be o↵ered forsale.
 So the market price will be close to $1000.
 This is why, if you buy a newcar, maybe 20% falls o↵ the price the second you drive it out of the dealer’slot.
 Asymmetric information is also why poor security products dominate somemarkets.
When users can’t tell good from bad, they might as well buy thecheapest.
 When the market for antivirus software took o↵ in the 1990s, peoplewould buy the $10 product rather than the $20 one.
 (Nowadays there’s much lessreason to buy AV, as the malware writers test their code against all availableproducts before releasing it – you should focus on patching systems instead.
That people still buy lots of AV is another example of asymmetric information.
)A further distinction can be drawn between hidden information and hiddenaction.
 For example, Volvo has a reputation for building safe cars that helptheir occupants survive accidents, yet Volvo drivers have more accidents.
 Is thisbecause people who know they’re bad drivers buy Volvos so they’re less likelyto get killed, or because people in Volvos believe they’re safer and drive faster?The ﬁrst is the hidden-information case, also known as adverse selection, andthe second is the hidden-action case, also known as moral hazard.
 Both e↵ectsare important in security, and both may combine in speciﬁc cases.
 (In the case ofdrivers, people adjust their driving behaviour to keep their risk exposure at thelevel with which they’re comfortable.
 This also explains why mandatory seat-belt laws tend not to save lives overall, merely to move fatalities from vehicleoccupants to pedestrians and cyclists [19].
)Asymmetric information explains many market failures in the real world,Security Engineering271Ross Anderson8.
3.
 INFORMATION ECONOMICSfrom low prices in used-car markets to the high price of cyber-risks insurance(ﬁrms who know they cut corners may buy more of it, making it expensive forthe careful).
 In the world of information security, it’s made worse by the factthat most stakeholders are not motivated to tell the truth; police and intelligenceagencies, as well as security vendors, try to talk up the threats while softwarevendors, e-commerce sites and banks downplay them [111].
8.
3.
4Public goodsAn interesting case of positive externalities is when everyone gets the samequantity of some good, whether they want it or not.
 Classic examples are airquality, national defense and scientiﬁc research.
 Economists call these publicgoods, and the formal deﬁnition is that such goods are non-rivalrous (my usingthem doesn’t mean there’s less for you) and non-excludable (there’s no practicalway to stop people consuming them).
Uncoordinated markets are generallyunable to provide public goods in socially optimal quantities.
Public goods may be supplied by governments directly, as with nationaldefense, or by using indirect mechanisms such as laws on patents and copyrightsto encourage people to produce inventions, books and music by giving thema temporary monopoly.
 Very often, public goods are provided by some mixof public and private action; scientiﬁc research is done in universities that getsome public subsidy, earn some income from student fees, and get some researchcontracts from industry (which may get patents on the useful inventions).
Many aspects of security are public goods.
 I do not have an anti-aircraftgun on the roof of my house; air-defense threats come from a small numberof actors, and are most e�ciently dealt with by government action.
 So whatabout Internet security? Certainly there are strong externalities; people whoconnect insecure machines to the Internet end up dumping costs on others, asthey enable bad actors to build botnets.
 Self-protection has some aspects of apublic good, while insurance is more of a private good.
 So what should we doabout it?The answer may depend on whether the bad actors we’re concerned withare concentrated or dispersed.
 In our quick survey of cybercrime in section 2.
3we noted that many threats have consolidated as malware writers, spammersand others have become commercial.
 By 2007, the number of serious spammershad dropped to a handful, and by 2019, the same had become true of denial-of-service (DoS) attacks: there seems to be one dominant DoS-for-hire provider.
This suggests a more centralised defence strategy, namely, ﬁnding the bad guysand throwing them in jail.
Some have imagined a gentler government response, with rewards paid toresearchers who discover vulnerabilities, paid for by ﬁnes imposed on the ﬁrmswhose software contained them.
 To some extent this happens already via bugbounty programs and vulnerability markets, without government intervention.
But a cynic will point out that in real life what happens is that vulnerabilitiesare sold to cyber-arms manufacturers who sell them to governments who thenstockpile them – and industry pays for the collateral damage, as with NotPetya.
So is air pollution the right analogy – or air defense? This brings us to gameSecurity Engineering272Ross Anderson8.
4.
 GAME THEORYtheory.
8.
4Game theoryGame theory has some of the most fundamental insights of modern economics.
It’s about when we cooperate, and when we ﬁght.
There are really just two ways to get something you want if you can’t ﬁndor make it yourself.
 You either make something useful and trade it; or youtake what you need, by force, by the ballot box or whatever.
 Choices betweencooperation and conﬂict are made every day at all sorts of levels, by both humansand animals.
The main tool we can use to study and analyse them is game theory – thestudy of problems of cooperation and conﬂict among independent decision mak-ers.
 Game theory provides a common language used by economists, biologistsand political scientists as well as computer scientists, and is a useful tool forbuilding collaboration across disciplines.
 We’re interested in games of strategy,and we try to get to the core of a decision by abstracting away much of the de-tail.
 For example, consider the school playground game of ‘matching pennies’:Alice and Bob toss coins and reveal them simultaneously, upon which Alice getsBob’s penny if they’re di↵erent and Bob gets Alice’s penny if they’re the same.
I’ll write this as in Figure 7.
2:BobAliceHTH-1,11,-1T1,-1-1,1Figure 7.
2 – matching penniesEach entry in the table shows ﬁrst Alice’s outcome and then Bob’s.
 Thusif the coins fall (H,H) Alice loses a penny and Bob gains a penny.
 This is anexample of a zero-sum game: Alice’s gain is Bob’s loss.
Often we can solve a game quickly by writing out a payo↵ matrix like this.
Here’s an example (Figure 7.
3):BobAliceLeftRightTop1,20,1Bottom2,11,0Figure 7.
3 – dominant strategy equilibriumIn game theory, a strategy is just an algorithm that takes a game state andSecurity Engineering273Ross Anderson8.
4.
 GAME THEORYoutputs a move1.
 In this game, no matter what Bob plays, Alice is better o↵playing ‘Bottom’; and no matter what Alice plays, Bob is better o↵ playing‘Left’.
 Each player has a dominant strategy – an optimal choice regardless ofwhat the other does.
 So Alice’s strategy should be a constant ‘Bottom’ andBob’s a constant ‘Left’.
 We call this a dominant strategy equilibrium.
Another example is shown in Figure 7.
4:BobAliceLeftRightTop2,10,0Bottom0,01,2Figure 7.
4 – Nash equilibriumHere each player’s optimal strategy depends on what they think the otherplayer will do.
 We say that two strategies are in Nash equilibrium when Alice’schoice is optimal given Bob’s, and vice versa.
 Here there are two symmetricNash equilibria, at top left and bottom right.
 You can think of them as beinglike local optima while a dominant strategy equilibrium is a global optimum.
8.
4.
1The prisoners’ dilemmaWe’re now ready to look at a famous problem that applies to many situationsfrom international trade negotiations through cooperation between hunting an-imals to whether the autonomous systems that make up the Internet cooperatee↵ectively to protect its infrastructure.
 It was ﬁrst studied by scientists at theRand corporation in 1950 in the context of US and USSR defense spending;Rand was paid to think about possible strategies in nuclear war.
But theypresented it using the following simple example.
Two prisoners are arrested on suspicion of planning a bank robbery.
 The po-lice interview them separately and tell each of them: “If neither of you confessesyou’ll each get a year for carrying a concealed ﬁrearm without a permit.
 If onlyone of you confesses, he’ll go free and the other will get 6 years for conspiracyto rob.
 If both of you confess, you will each get three years.
”What should the prisoners do? Here’s their payo↵ matrix:BenjyAlﬁeConfessDenyConfess-3,-30,-6Deny-6,0-1,-1Figure 7.
5 – the prisoners’ dilemmaWhen Alﬁe looks at this table, he will reason as follows: “If Benjy’s going toconfess then I should too as then I get 3 years rather than 6; and if he’s going to1In business and politics, a strategy a means of acquiring power, such as monopoly poweror military advantage, by a sequence of moves; the game-theoretic meaning is a somewhatsimpliﬁed version, to make problems more tractable.
Security Engineering274Ross Anderson8.
4.
 GAME THEORYdeny then I should still confess as I’ll walk rather than doing a year”.
 Benjy willreason similarly.
 The two of them confess, and get three years each.
 This is notjust a Nash equilibrium; it’s a dominant strategy equilibrium.
 Each prisonershould confess regardless of what the other does.
But hang on, you say, if they had agreed to keep quiet then they’ll get ayear each, which is a better outcome for them! In fact the strategy (deny,deny)is Pareto e�cient, while the dominant strategy equilibrium is not.
 (That’s onereason it’s useful to have concepts like ‘Pareto e�cient’ and ‘dominant strategyequilibrium’ rather than just arguing over ‘best’.
)So what’s the solution? Well, so long as the game is going to be played onceonly, and this is the only game in town, there isn’t a solution.
 Both prisonerswill confess and get three years.
You may think this is fair enough, as it serves them right.
 However, thePrisoners’ Dilemma can be used to model all sorts of interactions where wedecide whether or not to cooperate: international trade, nuclear arms control,ﬁsheries protection, the reduction of CO2 emissions, and the civility of politicaldiscourse.
 Even matters of self-control such as obesity and addiction can beseen as failures of cooperation with our future selves.
 In these applications, wereally want cooperation so we can get good outcomes, but the way a single-shotgame is structured can make them really hard to achieve.
 We can only changethis if somehow we can change the game itself.
There are many possibilities: there can be laws of various kinds from in-ternational treaties on trade to the gangster’s omert`a.
 In practice, a prisoner’sdilemma game is changed by altering the rules or the context so as to turn itinto another game where the equilibrium is more e�cient.
8.
4.
2Repeated and evolutionary gamesSuppose the game is played repeatedly – say Alﬁe and Benjy are career criminalswho expect to be dealing with each other again and again.
 Then of course therecan be an incentive for them to cooperate.
There are at least two ways ofmodelling this.
In the 1970s, Bob Axelrod started thinking about how people might playmany rounds of prisoners’ dilemma.
 He set up a series of competitions to whichpeople could submit programs, and these programs played each other repeatedlyin tournaments.
 He found that one of the best strategies overall was tit-for-tat,which is simply that you cooperate in round one, and at each subsequent roundyou do to your opponent what he or she did in the previous round [147].
 Itbegan to be realised that strategy evolution could explain a lot.
 For example, inthe presence of noise, players tend to get locked into (defect, defect) wheneverone player’s cooperative behaviour is misread by the other as defection.
 So inthis case it helps to ‘forgive’ the other player from time to time.
A parallel approach was opened up by John Maynard Smith and GeorgePrice [1251].
 They considered what would happen if you had a mixed populationof aggressive and docile individuals, ‘hawks’ and ‘doves’, with the behaviour thatdoves cooperate; hawks take food from doves; and hawks ﬁght, with a risk ofSecurity Engineering275Ross Anderson8.
4.
 GAME THEORYdeath.
 Suppose the value of the food at each interaction is v and the risk ofdeath in a hawk ﬁght is c per encounter.
 Then the payo↵ matrix looks likeFigure 7.
6:HawkDoveHawkv�c2 , v�c2v,0Dove0, vv2, v2Figure 7.
6 – the hawk-dove gameHere, if v > c, the whole population will become hawk, as that’s the domi-nant strategy, but if c > v (ﬁghting is too expensive) then there is an equilibriumwhere the probability p that a bird is a hawk sets the hawk payo↵ and the dovepayo↵ equal, that ispv � c2+ (1 � p)v = (1 � p)v2which is solved by p = v/c.
 In other words, you can have aggressive anddocile individuals coexisting in a population, and the proportion of aggressiveindividuals will be a function of the costs of aggression; the more dangerous aﬁght is, the fewer combative individuals there will be.
 Of course, the costs canchange over time, and diversity can a good thing in evolutionary terms as asociety with some hard men may be at an advantage when war breaks out.
 Butit takes generations for a society to move to equilibrium.
 Perhaps our currenthigh incidence of aggression reﬂects conditions in pre-state societies.
 Indeed,anthropologists believe that tribal warfare used to be endemic in such societies;the archaeological record shows that until states came along, about a quarterto a third of men and boys died of homicide [1132].
 We just haven’t lived longenough in civilised societies for evolution to catch up.
Such insights, along with Bob Axelrod’s simulation methodology, got manypeople from moral philosophers to students of animal behaviour interested inevolutionary game theory.
They o↵er further insights into how cooperationevolved.
 It turns out that many primates have an inbuilt sense of fairness andpunish individuals who are seen to be cheating – the instinct for vengeanceis one mechanism to enforce sociality.
Fairness can operate in a number ofdi↵erent ways at di↵erent levels.
 For example, doves can get a better resultagainst hawks if they can recognise each other and interact preferentially, givinga model for how some social movements and maybe even some religions establishthemselves [1784].
 Online reputation systems, as pioneered by eBay and nowused by ﬁrms like Uber and AirBnB, perform a similar function: they help dovesavoid hawks by making interactions into iterated games.
Of course, the basic idea behind tit-for-tat goes back a long way.
 The OldTestament has ‘An eye for an eye’ and the New Testament ‘Do unto others asyou’d have them do unto you’ – the latter formulation being the more fault-tolerant – and versions of it can be found in Aristotle, in Confucius and else-where.
 More recently, Thomas Hobbes used similar arguments in the seven-teenth century to argue that a state did not need the Divine Right of Kings toSecurity Engineering276Ross Anderson8.
5.
 AUCTION THEORYexist, paving the way for revolutions, republics and constitutions in the eigh-teenth.
Since 9/11, people have used hawk-dove games to model the ability of funda-mentalists to take over discourse in religions at a time of stress.
 Colleagues andI have used evolutionary games to model how insurgents organise themselvesinto cells [1373].
 Evolutionary games also explain why cartel-like behaviour canappear in industries even where there are no secret deals.
For example, Internet service in the UK involves a regulated monopoly thatprovides the local loop, and competing retail companies that sell Internet serviceto households.
 If the local loop costs the ISPs £6 a month, how come the ISPsall charge about £35?Well, if one were to undercut the others, they’d allretaliate by cutting their own prices, punishing the defector.
 It’s exactly thesame behavior you see if there are three airlines operating a proﬁtable route,and one lowers its prices to compete for volume; the others will often respond bycutting prices even more sharply to punish it and make the route unproﬁtable.
And just as airlines o↵er all sorts of deals, air miles and so on to confuse thecustomer, so also the telecomms providers o↵er their own confusion pricing.
Similar structures lead to similar behaviour.
 Tacit collusion can happen in bothindustries without the company executives actually sitting down and agreeing toﬁx prices (which would be illegal).
 As pricing becomes more algorithmic, bothlawyers and economists may need to understand more computer science; andcomputer scientists need to understand economic analysis tools such as gametheory and auction theory.
8.
5Auction TheoryAuction theory is vital for understanding how Internet services work, and whatcan go wrong.
 Much online activity is funded by the ad auctions run by ﬁrmslike Google and Facebook, and many e-commerce sites run as auctions.
Auctions have been around for millennia, and are the standard way of sellinglivestock, ﬁne art, mineral rights, bonds and much else; many other transactionsfrom corporate takeovers to house sales are also really auctions.
 They are thefundamental way of discovering prices for unique goods.
 There are many issuesof game play, asymmetric information, cheating – and some solid theory to guideus.
Consider the following ﬁve traditional types of auction.
1.
 In the English, or ascending-bid, auction, the auctioneer starts at a reserveprice and then raises the price until only one bidder is left.
 This is usedto sell art and antiques.
2.
 In the Dutch, or descending-bid, auction, the auctioneer starts out at ahigh price and cuts it gradually until someone bids.
 This is used to sellﬂowers.
3.
 In the ﬁrst-price sealed-bid auction, each bidder is allowed to make onebid.
 After bidding closes, all the bids are opened and the highest bid wins.
Security Engineering277Ross Anderson8.
5.
 AUCTION THEORYThis has been used to auction TV rights; it’s also used for governmentcontracts, where it’s the lowest bid that wins.
4.
 In the second-price sealed-bid auction, or Vickrey auction, we also getsealed bids and the highest bid wins, but that bidder pays the price in thesecond-highest bid.
 This is familiar from eBay, and is also how online adauctions work; it evolved to sell rare postage stamps, though the earliestknown use was by the poet Goethe to sell a manuscript to a publisher inthe 18th century.
5.
 In the all-pay auction, every bidder pays at every round, until all but onedrop out.
 This is a model of war, litigation, or a winner-take-all marketrace between several tech startups.
 It’s also used for charity fundraising.
The ﬁrst key concept is strategic equivalence.
 The Dutch auction and theﬁrst-price sealed-bid auction give the same result, in that the highest bidder getsthe goods at his reservation price – the maximum he’s prepared to bid.
 Similarly,the English auction and the Vickrey auction give the same result (modulo thebid increment).
 However the two pairs are not strategically equivalent.
 In aDutch auction, you should bid low if you believe your valuation is a lot higherthan anybody else’s, while in a second-price auction it’s best to bid truthfully.
The second key concept is revenue equivalence.
 This is a weaker concept; it’snot about who will win, but how much money the auction is expected to raise.
The interesting result here is the revenue equivalence theorem, which says thatyou get the same revenue from any well-behaved auction under ideal conditions.
These conditions include risk-neutral bidders, no collusion, Pareto e�ciency(the highest bidder gets the goods) and independent valuations (no externalitiesbetween bidders).
 In such circumstances, the bidders adjust their strategies andthe English, Dutch and all-pay auctions all yield the same.
 So when you designan auction, you have to focus on the ways in which the conditions aren’t ideal.
For details and examples, see Paul Klemperer’s book [1057].
And there are many things that can go wrong.
 There may be bidding rings,where all the buyers collude to lowball the auction; here, a ﬁrst-price auction isbest as it takes only one defector to break ranks, rather than two.
 Second, there’sentry detection: in one UK auction of TV rights, bidders had to submit extensiveprogramming schedules, which involved talking to production companies, soeveryone in the industry knew who was bidding and the franchises with only onebidder went for peanuts.
 Third, there’s entry deterrence: bidders in corporatetakeovers often declare that they will top any other bid.
 Fourth, there’s riskaversion: if you prefer a certain proﬁt of $1 to a 50% chance of $2, you’llbid higher at a ﬁrst-price auction.
Fifth, there are signaling games; in USspectrum auctions, some bidders broke anonymity by putting zip codes in theleast signiﬁcant digits of their bids, to signal what combinations of areas theywere prepared to ﬁght for, and to deter competitors from starting a biddingwar there.
 And then there are budget constraints: if bidders are cash-limited,all-pay auctions are more proﬁtable.
Advertisement auctions are big business, with Google, Facebook and Ama-zon making about $50bn, $30bn and $10bn respectively in 2019, while the restof the industry gets about $40bn.
The ad auction mechanism pioneered bySecurity Engineering278Ross Anderson8.
6.
 THE ECONOMICS OF SECURITY AND DEPENDABILITYGoogle is a second-price auction tweaked to optimise revenue.
 Bidders o↵er topay prices bi, the platform estimates their ad quality as ei, based on the ad’srelevance and clickthrough rate.
 It then calculates ‘ad rank’ as ai = biei.
 Theidea is that if my ad is ﬁve times as likely to be clicked on as yours, then mybid of 10c is just as good as your bid of 50c.
 This is therefore a second-priceauction, but based on ranking ai rather than bi.
 Thus if I have ﬁve times yourad quality, I bid 10c and you bid 40c, then I get the ad and pay 8c.
 It can beshown that under reasonable assumptions, this maximises platform revenue.
There’s one catch, though.
 Once media become social, then ad quality caneasily segue into virality.
 If your ads are good clickbait and people click on them,you pay less.
 One outcome was that in the 2016 US Presidential Election, HilaryClinton paid a lot more per ad than Donald Trump did [1234].
 Both auctiontheory and empirical data show how the drive to optimise platform revenue maylead to ever more extreme content: in addition to virality e↵ects at the auctionstep, Facebook’s delivery algorithms put ads in front of the people most likelyto click on them, strengthening the e↵ect of ﬁlter bubbles, and that this is notall due to user actions [40].
 Some people feel this ‘delivery optimisation’ shouldbe prohibited by electoral law; certainly it’s one more example of mechanismswith structural tension between e�ciency and fairness.
In fact, in the UK,election ads aren’t permitted on TV, along with some other categories such astobacco.
 Maybe the cleanest solution in such jurisdictions is to ban them onlinetoo, just like tobacco.
 And ad pricing is not the only way social media promoteextreme content; as former Googler Tristan Harris has explained, the platforms’recommender algorithms are also optimised to maximise the time people spendon site, which means not just scrolling feeds and followers, but a bias towardsanxiety and outrage.
 What’s more, ad delivery can be skewed by factors suchas gender and race by market e↵ects, as advertisers compete for more ‘valuable’demographics, and by content e↵ects because of the appeal of ad headlines orimages; this can be deliberate or accidental, and can a↵ect a broad range of adsincluding employment and housing [39].
 This all raises thorny political issuesat the boundary between economics and psychology, but economic tools such asauction theory can often be used to unpick them.
8.
6The economics of security and dependabilityEconomists used to see a simple interaction between economics and security:richer nations could a↵ord bigger armies.
 But after 1945, nuclear weapons werethought to decouple national survival from economic power, and the ﬁelds ofeconomics and strategic studies drifted apart [1238].
It has been left to theinformation security world to re-establish the connection.
Round about 2000, a number of us noticed persistent security failures thatappeared at ﬁrst sight to be irrational, but which we started to understand oncewe looked more carefully at the incentives facing the various actors.
 I observedodd patterns of investment by banks in information security measures [54, 55].
Hal Varian looked into why people were not spending as much money on anti-virus software as the vendors hoped [1943].
 When the two of us got to discussingthese cases in 2001, we suddenly realised that there was an interesting and im-Security Engineering279Ross Anderson8.
6.
 THE ECONOMICS OF SECURITY AND DEPENDABILITYportant research topic here, so we contacted other people with similar interestsand organised a workshop for the following year.
 I was writing the ﬁrst editionof this book at the time, and found that describing many of the problems asincentive problems made the explanations much more compelling; so I distilledwhat I learned from the book’s ﬁnal edit into a paper ‘Why Information Securityis Hard – An Economic Perspective”.
 This paper, plus the ﬁrst edition of thisbook, got people talking [72].
 By the time they came out, the 9/11 attacks hadtaken place and people were searching for new perspectives on security.
We rapidly found many other examples of security failure associated withinstitutional incentives, such as hospital systems bought by medical directorsand administrators that support their interests but don’t protect patient privacy.
(Later, we found that patient safety failures often had similar roots.
) Jean Camphad been writing about markets for vulnerabilities, and two startups had set upearly vulnerability markets.
 Networking researchers were starting to use auctiontheory to design strategy-proof routing protocols.
 The Department of Defensehad been mulling over its failure to get vendors to sell them secure systems,as you can see in the second quote at the head of this chapter.
 Microsoft wasthinking about the economics of standards.
 All these ideas came together at theWorkshop on the Economics of Information Security at Berkeley in June 2002,which launched security economics as a new ﬁeld of study.
 The picture thatstarted to emerge was of system security failing because the people guarding asystem were not the people who su↵ered the costs of failure.
 Sometimes, securitymechanisms are used to dump risks on others, and if you are one of those othersyou’d be better o↵ with an insecure system.
 Put di↵erently, security is often apower relationship; the principals who control what it means in a given systemoften use it to advance their own interests.
This was the initial insight, and the story of the birth of security economicsis told in [78].
 But once we started studying the subject seriously, we found thatthere’s a lot more to it than that.
8.
6.
1Why is Windows so insecure?The hot topic in 2002, when security economics got going, was this.
Whyis Windows so insecure, despite Microsoft’s dominant market position?It’spossible to write much better software, and there are ﬁelds such as defense andhealthcare where a serious e↵ort is made to produce dependable systems.
 Whydo we not see a comparable e↵ort made with commodity platforms, especiallysince Microsoft has no real competitors?By then, we understood the basics of information economics: the combina-tion of high ﬁxed and low marginal costs, network e↵ects and technical lock-inmakes platform markets particularly likely to be dominated by single vendors,who stand to gain vast fortunes if they can win the race to dominate the mar-ket.
 In such a race, the Microsoft philosophy of the 1990s – ‘ship it Tuesdayand get it right by version 3’ – is perfectly rational behaviour.
 In such a race,the platform vendor must appeal not just to users but also to complementers– to the software companies who decide whether to write applications for itsplatform or for someone else’s.
 Security gets in the way of applications, andit tends to be a lemons market anyway.
 So the rational vendor engaged in aSecurity Engineering280Ross Anderson8.
6.
 THE ECONOMICS OF SECURITY AND DEPENDABILITYrace for platform dominance will enable all applications to run as root on hisplatform2, until his position is secure.
 Then he may add more security – butwill be tempted to engineer it in such a way as to maximise customer lock-in,or to appeal to complementers in new markets such as digital media.
The same pattern was also seen in other platform products, from the old IBMmainframe operating systems through telephone exchange switches to the earlySymbian operating system for mobile phones.
 Products are insecure at ﬁrst,and although they improve over time, many of the new security features are forthe vendor’s beneﬁt as much as the user’s.
 And this is exactly what we sawwith Microsoft’s product lines.
 DOS had no protection at all and kick-startedthe malware market; Windows 3 and Windows 95 were dreadful; Windows 98was only slightly better; and security problems eventually so annoyed Microsoft’scustomers that ﬁnally in 2003 Bill Gates decided to halt development until all itsengineers had been on a secure coding course.
 This was followed by investmentin better testing, static analysis tools, and regular patching.
 The number andlifetime of exploitable vulnerabilities continued to fall through later releases ofWindows.
 But the attackers got better too, and the protection in Windows isn’tall for the user’s beneﬁt.
 As Peter Gutmann points out, much more e↵ort wentinto protecting premium video content than into protecting users’ credit cardnumbers [842].
From the viewpoint of the consumer, markets with lock-in are often ‘bargainsthen rip-o↵s’.
 You buy a nice new printer for $39.
95, then ﬁnd to your disgustafter just a few months that you need two new printer cartridges for $19.
95each.
 You wonder whether you’d not be better o↵ just buying a new printer.
From the viewpoint of the application developer, markets with standards racesbased on lock-in look a bit like this.
 At ﬁrst it’s really easy to write code forthem; later on, once you’re committed, there are many more hoops to jumpthrough.
 From the viewpoint of the poor consumer, they could be described as‘poor security, then security for someone else’.
The same pattern can be seen with externalities from security managementcosts to infrastructure decisions that the industry takes collectively.
 When rac-ing to establish a dominant position, vendors are tempted to engineer productsso that most of the cost of managing security is dumped on the user.
 A clas-sic example is SSL/TLS encryption.
This was adopted in the mid-1990s asMicrosoft and Netscape battled for dominance of the browser market.
 As wediscussed in Chapter 5, SSL leaves it up to the user to assess the certiﬁcateo↵ered by a web site and decide whether to trust it; and this led to all kinds ofphishing and other attacks.
 Yet dumping the compliance costs on the user madeperfect sense at the time; competing protocols such as SET would have saddledbanks with the cost of issuing certiﬁcates to every customer who wanted to buystu↵ online, and that would just have cost too much [524].
 The world endedup with an insecure system of credit card payments on the Internet, and withmost of the stakeholders trying to dump liability on others in ways that blockprogress towards a better system.
There are also network e↵ects for bads, and well as for goods.
 Most malwarewriters targeted Windows rather than Mac or Linux through the 2000s and2To make coding easier, and enable app developers to steal the user’s other data for salein secondary markets.
Security Engineering281Ross Anderson8.
6.
 THE ECONOMICS OF SECURITY AND DEPENDABILITY2010s as there are simply more Windows machines to infect – leading to an oddequilibrium in which people who were prepared to pay more for their laptopcould have a more secure one, albeit one that didn’t run as much software.
 Thismodel replicated itself when smartphones took over the world in the 2010s; sinceAndroid took over from Windows as the world’s most popular operating system,we’re starting to see a lot of bad apps for Android, while people who pay morefor an iPhone get better security but less choice.
 (There, the more stringentpolicies of Apple’s app store are more important now than market share.
)8.
6.
2Managing the patching cycleThe second big debate in security economics was about how to manage thepatching cycle.
 If you discover a vulnerability, should you just publish it, whichmay force the vendor to patch it but may leave people exposed for months untilthey do so? Or should you report it privately to the vendor – and risk gettinga lawyer’s letter threatening an expensive lawsuit if you tell anyone else, afterwhich the vendor just doesn’t bother to patch it?This debate goes back a long way; as we noted in the preface, the Victo-rians agonised over whether it was socially responsible to publish books aboutlockpicking, and eventually concluded that it was [1895].
 People have worriedmore recently about whether the online availability of the US Army ImprovisedMunitions Handbook [1924] helps terrorists; in some countries it’s a crime topossess a copy.
Security economics provides both a theoretical and a quantitative frameworkfor discussing some issues of this kind.
 We started in 2002 with simple models inwhich bugs were independent, identically distributed and discovered at random;these have nice statistical properties, as attackers and defenders are on an equalfooting, and the dependability of a system is a function only of the initial codequality and the total amount of time spent testing it [74].
 But is the real worldactually like that? Or is it skewed by correlated bugs, or by the vendor’s insideknowledge? This led to a big policy debate.
 Eric Rescorla argued that softwareis close enough to the ideal that removing one bug makes little di↵erence to thelikelihood of an attacker ﬁnding another one later, so frequent disclosure andpatching were an unnecessary expense unless the same vulnerabilities were likelyto be rediscovered [1596].
 Ashish Arora and others responded with data showingthat public disclosure made vendors ﬁx bugs more quickly; attacks increased tobegin with, but reported vulnerabilities declined over time [133].
 In 2006, AndyOzment and Stuart Schechter found that the rate at which unique vulnerabilitieswere disclosed for the core OpenBSD operating system decreased over a six-yearperiod [1488].
 In short, in the right circumstances, software can be more likewine than like milk – it improves with age.
 (Sustainability is a holy grail, andI discuss it in more detail in Part 3.
)Several further institutional factors helped settle the debate in favour of re-sponsible disclosure, also known as coordinated disclosure, whereby people reportbugs to vendors or to third parties that keep them conﬁdential for a period untilpatches are available, then let the reporters get credit for their discoveries.
 Onewas the political settlement at the end of Crypto War I whereby bugs wouldbe reported to CERT which would share them with the NSA during the bug-Security Engineering282Ross Anderson8.
6.
 THE ECONOMICS OF SECURITY AND DEPENDABILITYﬁxing process, as I will discuss later in section 26.
2.
7.
3.
 This got governmentson board.
 The second was the emergence of commercial vulnerability marketssuch as those set up by iDefense and TippingPoint, where security researcherscould sell bugs; these ﬁrms would then disclose each bug responsibly to thevendor, and also work out indicators of compromise that could be sold to ﬁrmsoperating ﬁrewall or intrusion-detection services.
 Third, smart software ﬁrmsstarted their own bug-bounty programs, so that security researchers could selltheir bugs directly, cutting out middlemen such as CERT and iDefense.
This marketplace sharpened considerably after Stuxnet drove governmentsto stockpile vulnerabilities.
 We’ve seen the emergence of ﬁrms like Zerodiumthat buy bugs and sell them to state actors, and to cyberweapons suppliers thatalso sell to states; zero-day exploits for platforms such as the iPhone can nowsell for a million dollars or more.
 This had knock-on e↵ects on the supply chain.
For example, in 2012 we came across the ﬁrst case of a volunteer deliberatelycontributing vulnerable code to an open-source project3, no doubt in the hope ofa six-ﬁgure payo↵ if it had found its way into widely-used platforms.
 Already in2010, Sam Ransbotham had shown that although open-source and proprietarysoftware are equally secure in an ideal model, bugs get turned into exploits fasterin the open source world, so attackers target it more [1579].
 In 2014, AbdullahAlgarni and Yashwant Malaiya surveyed vulnerability markets and interviewedsome of the more proliﬁc researchers; a combination of curiosity and economicincentives draw in many able young men, many from less developed countries,some disclose responsibly, some use vulnerability markets to get both moneyand recognition, while others sell for more money to the black hats; some willo↵er bugs to the vendor, but if not treated properly will o↵er them to the badguys instead.
 Vendors have responded with comparable o↵ers: at Black Hat2019, Apple announced a bug bounty schedule that goes up to $1m for exploitsthat allow zero-click remote command execution on iOS.
 Oh, and many of thebug hunters retire after a few years [38].
Like it or not, volunteers runningopen-source projects now ﬁnd themselves some capable motivated opponents iftheir projects get anywhere, and even if they can’t match Apple’s pocket, it’s agood idea to keep as many of the researchers onside as possible.
The lifecycle of a vulnerability now involves not just its discovery, but per-haps some covert use by an intelligence agency or other black-hat actor; thenits rediscovery, perhaps by other black hats but eventually by a white hat; theshipment of a patch; and then further exploitation against users who didn’t ap-ply the patch.
 There are tensions between vendors and their customers over thefrequency and timing of patch release, as well as with complementers and sec-ondary users over trust.
 A vulnerability in Linux doesn’t just a↵ect the serverin your lab and your kid’s Raspberry Pi.
 Linux is embedded everywhere: inyour air-conditioner, your smart TV and even your car.
 This is why responsibledisclosure is being rebranded as coordinated disclosure.
 There may be simplytoo many ﬁrms using a platform for the core developers to trust them all about aforthcoming patch release.
 There are also thousands of vulnerabilities, of whichdozens appear each year in the exploit kits used by criminals (and some nodoubt used only once against high-value targets, so they never become knownto defense systems).
 We have to study multiple overlapping ecosystems – of the3Webkit, which is used in mobile phone browsersSecurity Engineering283Ross Anderson8.
6.
 THE ECONOMICS OF SECURITY AND DEPENDABILITYvulnerabilities indexed by their CVE numbers; of the Indicators of Compromise(IoCs) that get fed to intrusion detection systems; of disclosure to vendors di-rectly, via markets, via CERTs and via ISACs; of the various botnets, crimegangs and state actors; and of the various recorded crime patterns.
 We havepartial correlations between these ecosystems, but the data are generally noisy.
I’ll come back to all this in Part III.
8.
6.
3Structural models of attack and defenceThe late Jack Hirshleifer, the founder of conﬂict theory, told the story of Anar-chia, an island whose ﬂood defences were constructed by individual families eachof whom maintained a section of the ﬂood wall.
 The island’s ﬂood defence thusdepended on the weakest link, that is, the laziest family.
 He compared this witha city whose defences against missile attack depend on the single best defen-sive shot [906].
 Another example of best-shot is medieval warfare, where therecould be a single combat between the two armies’ champions.
 This can lead todi↵erent political systems.
 Medieval Venice, the best example of weakest-linkdefence because of the risk of ﬂooding, had strong central government, with themerchant families electing a Doge with near-dictatorial powers over ﬂood de-fence.
 In much of the rest of late medieval Europe, kings or chieftains led theirown armies to kill enemies and seize land; the strongest king built the biggestempire, and this led to a feudal system that optimised the number of men atarms.
Hal Varian extended this model to the dependability of information systems– where performance can depend on the weakest link, the best e↵ort, or thesum-of-e↵orts [1945].
 This last case, the sum-of-e↵orts, is the modern model forwarfare: we pay our taxes and the government hires soldiers.
 It’s more e�cientthan best-shot (where most people will free-ride behind the heroes), which inturn is more e�cient than weakest-link (where everyone will be vulnerable viathe laziest).
 Information security is an interesting mix of all three modes.
 Pro-gram correctness can depend on the weakest link (the most careless programmerintroducing a vulnerability) while software vulnerability testing may depend onthe sum of everyone’s e↵orts.
 Security may also depend on the best e↵ort – theactions taken by an individual champion such as a security architect.
 As moreagents are added, systems become more reliable in the sum-of-e↵orts case butless reliable in the weakest-link case.
 So as software companies get bigger, theyend up hiring more testers and fewer (but more competent) programmers; Mi-crosoft found by the early 2000s that they had more test engineers than softwareengineers.
Other models of attack and defence include epidemic models of malwarespread, which were important back when computer viruses spread from machineto machine via ﬂoppy disks, but are of less interest now that we see relativelyfew wormable exploits; and models of security games that hinge on timing,notably the game of FlipIt by Ron Rivest and colleagues [559]; indeed, there’s awhole conference (Gamesec) devoted to game theory and information security.
There are also models of social networks.
 For example, most social networks owetheir connectivity to a relatively small number of nodes that have a relativelyhigh number of links to other nodes [1994].
Knocking out these nodes canSecurity Engineering284Ross Anderson8.
6.
 THE ECONOMICS OF SECURITY AND DEPENDABILITYrapidly disconnect things; William the Conqueror consolidated England after1066 by killing the Anglo-Saxon nobility and replacing them with Normans,while Stalin killed the richer peasants.
 US and British forces similarly targetedhighly-connected people in counterinsurgency operations during the Iraq war(and the resulting social breakdown in Sunni areas helped the emergence ofISIS).
 Such models also suggest that for insurgents to form into cells is thenatural and most e↵ective response to repeated decapitation attacks [1373].
George Danezis and I also showed that where solidarity is needed for defence,smaller and more homogeneous groups will be more e↵ective [511].
RainerB¨ohme and Tyler Moore studied what happens where it isn’t – if people usedefense mechanisms that bring only private beneﬁt, then the weakest-link modelbecomes one of low-hanging fruit.
 Examples include spammers who simply guessenough weak passwords to replenish their stock of compromised email accounts,and card-not-present fraud against e-commerce websites [276].
In short, the technology of conﬂict in any age can have deep and subtle e↵ectson politics, as it conditions the kind of institutions that can survive and thrive.
These institutions in turn shape the security landscape.
 Tyler Moore, AllanFriedman and Ariel Procaccia studied whether a national agency such as theNSA with both defensive and o↵ensive missions would disclose vulnerabilities sothey could be ﬁxed, or stockpile them; they concluded that if it could ignore thesocial costs that fall on others, it would stockpile [1338].
 However the biggestinstitutions in the security ecosystem are probably not government agencies butthe dominant ﬁrms.
8.
6.
4The economics of lock-in, tying and DRMTechnical lock-in is one of the factors that lead to dominant-ﬁrm markets, andsoftware ﬁrms have spent billions over more than thirty years on mechanismsthat make it hard for their customers to leave but easy for their competitors todefect.
 The 1980s saw ﬁle format wars where companies tried to stop anyoneelse accessing the word-processing ﬁles or spreadsheets their software generated.
By the 1990s, the ﬁght had shifted to network compatibility as Microsoft triedto exclude other operating systems from LANs, until SAMBA created inter-operability with Apple; in the wake of a 1993 anti-trust suit, Microsoft heldback from using the Windows contract to block it.
 Adversarial interoperabilityemerged as a kind of judo to ﬁght network e↵ects [570].
 Similar mechanisms areused to control markets in neighbouring or complementary goods and services,examples being tying ink cartridges to printers, and digital rights management(DRM) systems that lock music and videos to a speciﬁc machine or family ofmachines, by preventing users from simply copying them as ﬁles.
 In an earlysecurity-economics paper, Hal Varian pointed out in 2002 that their unfettereduse could damage competition [1944].
In 2003, Microsoft, Intel and others launched a ‘Trusted Computing’ ini-tiative that extended rights management to other types of ﬁle, and WindowsServer 2003 o↵ered ‘Information Rights Management’ (IRM) whereby I couldemail you a Word document that you could only read on screen, not print, andonly till the end of the month.
 There was obvious potential for competitiveabuse; by transferring control of user data from the owner of the machine onSecurity Engineering285Ross Anderson8.
6.
 THE ECONOMICS OF SECURITY AND DEPENDABILITYwhich it is stored to the creator of the ﬁle in which it is stored, the potential forlock-in is hugely increased [73].
 Think of the example in section 8.
3.
2 above, inwhich a ﬁrm has 100 sta↵, each with a PC on which they install O�ce for $150.
The $15,000 they pay Microsoft is roughly equal to the total costs of switchingto (say) LibreO�ce, including training, converting ﬁles and so on.
 However, ifcontrol of the ﬁles moves to its thousands of customers, and the ﬁrm now hasto contact each customer and request a digital certiﬁcate in order to migratethe ﬁle, then clearly the switching costs have increased – so you could expectthe cost of O�ce to increase too.
Now IRM failed to take o↵ at the time:corporate America quickly understood that it was a lock-in play, European gov-ernments objected to the fact that the Trusted Computing initiative excludedsmall ﬁrms, and Microsoft couldn’t get the mechanisms to work properly withVista.
 However, now that email has moved to the cloud, both Microsoft andGoogle are o↵ering restricted email services of just the type that was proposed,and objected to, back in 2003.
Another aspect concerns DRM and music.
 In the late 1990s and early 2000s,Hollywood and the music industry lobbied hard for mandatory DRM in con-sumer electronics equipment, and we still pay the costs of that in various ways;for example, when you switch your presentation from a VGA adapter to HDMIand you lose the audio.
 Hollywood’s claim that unlicensed peer-to-peer ﬁle-sharing would destroy the creative industries was always shaky; a 2004 studyshowed that downloads didn’t harm music industry revenues overall [1457] whilea later one suggested that downloaders actually bought more CDs [50].
 How-ever the real issue was explained in 2005 by Google’s chief economist [1946]:that a stronger link between the tech industry and music would help tech ﬁrmsmore than the music industry, because tech was more concentrated (with onlythree serious music platforms then – Microsoft, Sony and Apple).
 The contentindustry sco↵ed, but by the end of that year music publishers were protestingthat Apple was getting too large a share of the cash from online music sales.
Power in the supply chain moved from the music majors to the platforms, sothe platforms (now Apple, Google, Amazon and Spotify) got most of the moneyand the residual power in the music industry shifted from the majors to the in-dependents – just as airline deregulation favoured aircraft makers and low-costairlines.
 This is a striking demonstration of the predictive power of economicanalysis.
 By ﬁghting a non-existent threat, the record industry helped the com-puter industry eat its lunch.
 I discuss this in more detail in section 24.
5.
DRM had become much less of an issue by 2020; the move from removablemedia to streaming services means that few people copy music or movies anymore; the question is whether you pay a subscription to avoid the ads.
 Similarly,the move to cloud-based services means that few people steal software.
 As aresult, crimes involving copyright infringement have dropped sharply [91].
However, the move to the cloud is making lock-in a more complex matter,operating at the level of ecosystems as well as of individual products.
 We dis-cussed above how competition from Google Docs cut the price of O�ce, and soMicrosoft responded with a move to O�ce365; and how the total cost of owner-ship of either that service or G-suite is greater than a standalone productivityproduct.
 So where is the lock-in? Well, if you opt for the Google ecosystem,you’ll probably be using not just Gmail and Google Docs but a Google calendar,Security Engineering286Ross Anderson8.
6.
 THE ECONOMICS OF SECURITY AND DEPENDABILITYmaps and much else.
 Although you can always download all your data, rein-stalling it on a di↵erent platform (such as Microsoft’s or Apple’s) will be a lotof bother, so you’ll probably just grit your teeth and pay for more storage whenthe free quota runs out.
 Similarly, if you start using tools like Slack or Splunkin an IT company, you’ll end up customising them in all sorts of ways that makeit di�cult to migrate.
 Again, this is nothing new; my own university’s dreadfulaccounting system has been a heavily customised version of Oracle Financials forabout 20 years.
 Now everyone’s playing the lock-in game by inducing customersto buy or build complementary assets, or even to outsource whole functions.
Salesforce has taken over many companies’ sales admin, Palantir has locked inmany US police forces, and the big academic publishers are usurping the func-tions of university libraries.
 Where there’s no viable competition – as in thesecond of these cases – there’s a real policy issue.
 The depth of Microsoft lockinon public-sector IT is illustrated by the brave attempts made by the city of Mu-nich to break away and use Linux in public administration: this was eventuallyreverted after 15 years, several visits of Bill Gates, and a new mayor [759].
The control of whole ecosystems by cartels is nothing new; Joshua Spechttells the history of how the big food companies like Cargill and Armour grabbedcontrol of the two-sided markets opened up by the railroads, consolidated theirpower by buying infrastructure such as grain elevators, dumped climate risk onsmall farmers, ran union organisers out of town and even got the politicians topass ‘ag-gag’ laws that deﬁne animal-rights activism as terrorism [1808].
 Thereare interesting echoes of this in the way the big IT service ﬁrms have built outtheir market power, controlling everything from the ad ecosystem through op-erating systems to datacentres.
 In fact, the whole global economy has becomemore monopolistic over the past couple of decades, and IT appears to accountfor much of the growth in industry concentration[234].
 It isn’t the only factor– other industries (such as defence contracting) have their own dynamic, whilethe regulators of natural monopolies such as utilities tend to be captured overtime by lobbying.
 There is a growing literature on moats – structural barri-ers to competition, of which network e↵ects and technical lock-in are merelytwo examples; others range from patents and regulatory capture to customerinsight derived from control of data [1431].
 The dynamics of the informationindustries compound many of these existing problems and can make e↵ectivecompetition even harder.
 Competition law scholars, led by Lina Khan of Har-vard, have been arguing for several years that American law needs to take abroader view of competition abuse than just consumer surplus (as is already thecase in Europe) [1044], while Chicago-school economists such as Carl Shapirodenounce antitrust populism and argue that remedies should be targeted at spe-ciﬁc harms, as antitrust law is ill-suited to tackle the political power that largecorporations wield [1716].
 Carl does however concede that US antitrust law hasbeen excessively narrowed by the Supreme Court in the last 40 years; that theconsumer-welfare test is inadequate; that dominant ﬁrms’ exclusionary conductand labour-market practices both need to be tackled, and that the USA needsto control horizontal mergers better [1717].
European competition law has for many years forbidden ﬁrms from using adominant position in one market to establish one in another, and we’ve seen awhole series of judgements against the big tech ﬁrms.
 As for the likely futuredirection, a 2019 report for the European Commission’s Directorate-GeneralSecurity Engineering287Ross Anderson8.
6.
 THE ECONOMICS OF SECURITY AND DEPENDABILITYof Competition by Jacques Cr´emer, Yves-Alexandre de Montjoye and HeikeSchweizter highlights not just the tech majors’ network externalities and extremereturns to scale, but also the fact that they control more and more of the datathanks to the move to online services and cloud computing [497].
 As a result theyhave economies of scope: succeeding in one business makes it easier to succeedin another.
 It concludes that the EU’s competition-law framework is basicallysound but needs some tuning: regulators need to protect both competition forthe market and competition in the market, such as on dominant platforms, whichhave a responsibility not to distort competition there.
In this environment,regulators must pay attention to multihoming, switching, interoperability, dataportability and the e↵ect on aftermarkets.
Tying spare parts is also regulated in Europe, with speciﬁc laws in somesectors requiring vendors to let other ﬁrms make compatible spare parts, andin others requiring that they make spares available for a certain period of time.
Some some very speciﬁc policy issues can arise if you use security mechanismsto tie products to each other.
 This links in with laws on planned obsolesence,which is reinforced for goods with digital components when the vendors limitthe time period for which software updates are made available.
 The rules haverecently been upgraded in the European Union by a new Sales of Goods Directive(2019/771) that from January 2022 requires ﬁrms selling goods with digitalcomponents – whether embedded software, cloud services or associated phoneapps – to maintain this software for at least two years after the good are sold,and for longer if this is the reasonable expectation of the customer (for cars andwhite goods it’s likely to mean ten years).
 Such regulations will become moreof an issue now we have software in durable goods such as cars and medicaldevices; I’ll discuss sustainability in the last chapter of this book.
8.
6.
5Perversely motivated guards“There’s nane sae blind as them that will na see”, goes an old Scots proverb,and security engineering throws up lots of examples.
• There’s very little police action against cybercrime, as they found it sim-pler to deter people from reporting it.
 As we noted in section 2.
3, thisenabled them to claim that crime was falling for many years even thoughit was just moving online like everything else.
• Governments have imposed a duty on banks to spot money laundering,especially since 9/11.
 However no banker really wants to know that oneof his customers is a Maﬁoso.
 So banks lobby for risk reduction to beformalised as due diligence; they press for detailed regulations that specifythe forms of ID they need for new account opening, and the processing tobe done to identify suspicious transactions.
• When it comes to fraud, spotting a rare bank fraud pattern means apayment service provider should now carry the loss rather than just tellingthe customer she must be mistaken or lying.
 So they’re tempted to waitand learn about new fraud types from industry or from academics, ratherthan doing serious research of their own.
Security Engineering288Ross Anderson8.
6.
 THE ECONOMICS OF SECURITY AND DEPENDABILITY• Click fraud is similar.
 Spotting a pattern of ‘inorganic clicks’ from a botnetmeans you can’t charge the advertisers for those clicks any more.
 You haveto do some work to mitigate the worst of it, but if you have a dominantmarket position then the harder you work at ﬁghting click fraud, the lessrevenue you earn.
• Finding bugs in your own code is another example.
 Of course you haveto tweak the obvious bugs that stop it working, but what about the moresubtle bugs that can be exploited by attackers? The more time you spendlooking for them, the more time you have to spend ﬁxing them.
 You canalways go and buy static analysis tools, but then you’ll ﬁnd thousandsmore bugs and your ship date will slip by months.
 So ﬁrms tend to dothat only if their customers demand it, and it’s only cheap if you do itfrom the start of a project (but in that case you could just as well writethe code in Rust rather than in C).
There are more subtle examples, such as when it’s not politically acceptableto tell the truth about threats.
 In the old days, it was hard to talk to a boardof directors about the insider threat, as directors mostly preferred to believe thebest about their company; so a typical security manager would make chillingpresentations about ‘evil hackers’ in order to get the budget to build internalcontrols.
Nowadays, the security-policy space in many companies has beencaptured by the big four accountancy ﬁrms, whose consensus on internal controlsis tied to their thought leadership on governance, which a cynic might say isoptimised for the welfare not of their ostensible client, the shareholders, but fortheir real client, the CEO.
 Executive frauds are rarely spotted unless they bringthe company down; the e↵ort goes instead into the annoying and irrelevant, suchas changing passwords every month and insisting on original paper receipts.
 Idiscuss all this in detail in section 12.
2.
2.
Or consider the 2009 parliamentary expenses scandal in the UK describedin section 2.
3.
6.
 Perhaps the o�cers of the Houses of Parliament didn’t defendthe expenses system more vigorously because they have to think of MPs andpeers as ‘honourable members’ in the context of a government that was pushingharsh surveillance legislation with a slogan of ‘If you’ve nothing to hide you havenothing to fear’.
 The author of that slogan, then Home Secretary Jacqui Smith,may have had nothing to hide, but her husband did: he was watching porn andcharging it to her parliamentary expenses.
 Jacqui lost her job, and her seat inParliament too.
 Had o�cers known that the information on the expenses servercould cost a cabinet minister her job, they probably ought to have classiﬁed itTop Secret and kept it in a vault.
 But how could the extra costs have beenjustiﬁed to the Treasury? On that cheerful note, let’s go on to privacy.
8.
6.
6Economics of privacyThe privacy paradox is that people say that they value privacy, yet act otherwise.
If you stop people in the street and ask them their views, about a third say theyare privacy fundamentalists and will never hand over their personal informationto marketers or anyone else; about a third say they don’t care; and about a thirdare in the middle, saying they’d take a pragmatic view of the risks and beneﬁtsSecurity Engineering289Ross Anderson8.
6.
 THE ECONOMICS OF SECURITY AND DEPENDABILITYof any disclosure.
 However, their shopping behavior – both online and o✏ine –is quite di↵erent; the great majority of people pay little heed to privacy, and willgive away the most sensitive information for little beneﬁt.
 Privacy-enhancingtechnologies have been o↵ered for sale by various ﬁrms, yet most have failed inthe marketplace.
 Why should this be?Privacy is one aspect of information security that interested economists be-fore 2000.
 In 1978, Richard Posner deﬁned privacy in terms of secrecy [1536],and the following year extended it to seclusion [1537].
 In 1980, Jack Hirshleiferpublished a seminal paper in which he argued that rather than being aboutwithdrawing from society, privacy was a means of organising society, arisingfrom evolved territorial behavior; internalised respect for property supports au-tonomy.
 In 1996, Hal Varian analysed privacy in terms of information mar-kets [1940].
 Consumers want to not be annoyed by irrelevant marketing callswhile marketers do not want to waste e↵ort; yet both are frustrated, because ofsearch costs, externalities and other factors.
 Varian suggested giving consumersrights in information about themselves, and letting contracts sort it out.
However, as we’ve seen, the information industries are prone to marketfailures leading to monopoly, and the proliferation of dominant, information-intensive business models demands a di↵erent approach.
 Andrew Odlyzko ar-gued in 2003 that these monopolies simultaneously increase both the incentivesand the opportunities for price discrimination [1462].
 Companies mine onlineinteractions for data revealing individuals’ willingness to pay, and while the dif-ferential pricing we see in many markets from airline yield-management systemsto telecommunications prices may be economically e�cient, it is increasinglyresented.
 Peter Swire argued that we should measure the externalities of pri-vacy intrusion [1852].
 If a telesales operator calls 100 prospects, sells three ofthem insurance, and annoys 80, then the conventional economic analysis con-siders only the beneﬁt to the three and to the insurer.
 But persistent annoyancecauses millions of people to go ex-directory, screen calls through an answeringmachine, or just not have a landline at all.
 The long-run societal costs of robo-calls can be considerable.
 Empirical studies of people’s privacy valuations havesupported this.
The privacy paradox has generated a signiﬁcant literature, and is com-pounded by at least three factors.
 First, there are many di↵erent types of pri-vacy harm, from discrimination in employment, credit and insurance, throughthe kind of cybercrime that presents as payment fraud, to personal crimes suchas stalking and non-consensual intimate imagery.
Second, the behavioral factors we discussed in section 3.
2.
5 play a largerole.
 Leslie John and colleagues demonstrated the power of context with a neatexperiment.
 She devised a ‘privacy meter’ in the form of a list of embarrassingquestions; the score was how many questions a subject would answer beforethey balked.
She tried this on three groups of students: a control group ina neutral university setting, a privacy treatment group who were given strongassurances that their data would be encrypted, their IP addresses not stored,and so on; and a gamer treatment group that was taken to an external website(howbadareyou.
com with a logo of a smiling devil).
 You might think that theprivacy treatment group would disclose more, but in fact they disclosed less – asprivacy had been made salient to them.
 As for the gamer group, they happilySecurity Engineering290Ross Anderson8.
6.
 THE ECONOMICS OF SECURITY AND DEPENDABILITYdisclosed twice as much as the control group [987].
Third, the industry understands this, and goes out of its way to make privacyrisks less salient.
 Privacy policies are usually not on the front page, but are easilyﬁndable by concerned users; policies typically start with anodyne text and leavethe unpleasant stu↵ to the end, so they don’t alarm the casual viewer, but thevigilant minority can quickly ﬁnd a reason not to use the site, so they also don’tstop the other users clicking on the ads.
The cookie warnings mandated inEurope are mostly anodyne, though some ﬁrms give users ﬁne-grained control;as noted in section 3.
2.
5, the illusion of control is enough to reassure many.
So what’s the overall e↵ect? In the 2000s and early 2010s there was evidencethat the public were gradually learning what we engineers already understoodabout the risks; we could see this for example in the steadily rising proportionof Facebook users who opt to use privacy controls to narrow that system’s veryopen defaults.
In 2015, almost two years after the Snowden revelations, two surveys con-ducted by Pew Research disclosed a growing sense of learned helplessness amongthe US public.
 93% of adults said that being in control of who can get infor-mation about them is important, and 90% that controlling what information iscollected about them is important; 88% said it’s important that no-one watchor listen to them without their permission.
 Yet just 6% of adults said they were‘very conﬁdent’ that government agencies could keep their records private andsecure, while another 25% said they were ‘somewhat conﬁdent.
’ The ﬁguresfor phone companies and credit card companies were similar while those foradvertisers, social media and search engines were signiﬁcantly worse.
 Yet fewrespondents had done anything signiﬁcant, beyond occasionally clearing theirbrowser history or refusing particularly inappropriate demands for personal in-formation [1204].
These tensions have been growing since the 1960s, and have led to complexprivacy regulation that di↵ers signiﬁcantly between the US and Europe.
 I’lldiscuss this in much more detail in section 26.
6.
8.
6.
7Organisations and human behaviourOrganisations often act in apparently irrational ways.
 We frequently see ﬁrmsand even governments becoming so complacent that they’re unable to react to athreat until it’s a crisis, when they panic.
 The erosion of health service resilienceand pandemic preparedness in Europe and North America in the century sincethe 1918–19 Spanish ﬂu is merely the most salient of many examples.
 As anotherexample, it seems that there’s always one phone company, and one bank, thatthe bad guys are picking on.
 A low rate of fraud makes people complacent, untilthe bad guys notice.
 The rising tide of abuse is ignored, or blamed on customers,for as long as possible.
 Then it gets in the news and executives panic.
 Loads ofmoney get spent for a year or two, stu↵ gets ﬁxed, and the bad guys move onto the next victim.
So the security engineer needs to anticipate the ways in which human frailtiesexpress themselves through organizational behaviour.
Security Engineering291Ross Anderson8.
6.
 THE ECONOMICS OF SECURITY AND DEPENDABILITYThere’s a substantial literature on institutional economics going back toThorstein Veblen.
 One distinguished practitioner, Herb Simon, was also a com-puting pioneer and founded computer science at CMU.
 In a classic book onadministrative behaviour, he explained that the decisions taken by managersare not just about e�ciency but also organisational loyalty and authority, andthe interaction between the organisation’s goals and the incentives facing in-dividual employees; there are messy hierarchies of purpose, while values andfacts are mixed up [1754].
 A more modern analysis of these problems typicallysees them as principal-agency issues in the framework of microeconomics; thisis a typical approach of professors of accountancy.
 We will discuss the failuresof the actual practice of accountancy later, in section 12.
2.
 Another approachis public-choice economics, which applies microeconomic methods to study thebehaviour of politicians, civil servants and people in public-sector organsationsgenerally.
 I summarise public choice in section 26.
3.
3; the principles are illus-trated well in the TV sitcom “Yes Minister’ which explores the behaviour ofBritish civil servants.
 Cynics note that bureaucracies seem to evolve in such away as to minimise the likelihood of blame.
My own observation, having worked in banks, tech companies big and smalland in the university sector too, is that competition is more important thanwhether an enterprise is publicly or privately owned.
 University professors com-pete hard with each other; our customer isn’t our Vice-Chancellor but the NobelPrize committee or equivalent.
 But as university administrators work in a hier-archy with the VC at the top, they face the same incentives as civil servants anddisplay many of the same strengths and weaknesses.
 Meanwhile, some privateﬁrms have such market power that internally they behave just like government(though with much better pay at the top).
8.
6.
8Economics of cybercrimeIf you’re going to protect systems from attack, it’s a good idea to know who theattackers are, how many they are, where they come from, how they learn theirjobs and how they’re motivated.
 This brings us to the economics of cybercrime.
In section 2.
3 we gave an overview of the cybercrime ecosystem, and there aremany tools we can use to study it in more detail.
 At the Cambridge CybercrimeCentre we collect and curate the data needed to do this, and make it availableto over a hundred researchers worldwide.
As in other economic disciplines,there’s an iterative process of working out what the interesting questions areand collecting the data to answer them.
The people with the questions arenot just economists but engineers, psychologists, lawyers, law enforcement and,increasingly, criminologists.
One approach to crime is that of Chicago-school economists such as GaryBecker, who in 1968 analysed crime in terms of rewards and punishments [200].
This approach gives many valuable insights but isn’t the whole story.
 Why iscrime clustered in bad neighbourhoods? Why do some kids from these neigh-bourhoods become proliﬁc and persistent o↵enders? Traditional criminologistsstudy questions like these, and ﬁnd explanations of value in crime prevention:the worst o↵enders often su↵er multiple deprivation, with poor parenting, withsubstance and alcohol abuse, and get drawn into cycles of o↵ending.
 The earlierSecurity Engineering292Ross Anderson8.
6.
 THE ECONOMICS OF SECURITY AND DEPENDABILITYthey start in their teens, the longer they’ll persist before they give up.
 Criticalcriminologists point out that laws are made by the powerful, who maintain theirpower by oppressing the poor, and that bad neighbourhoods are more likely tobe over-policed and stigmatised than the nice suburbs where the rich whitepeople live.
Drilling down further, we can look at the bad neighbourhoods, the psychol-ogy of o↵enders, and the pathways they take into crime.
 Since the 1960s therehas been a substantial amount of research into using environmental design tosuppress crime, initially in low-cost housing and then everywhere.
 For exam-ple, courtyards are better than parks, as residents are more likely to identifyand challenge intruders; many of these ideas for situational crime prevention goacross from criminology into systems design.
 In section 13.
2.
2 we’ll discuss thisin more detail.
Second, psychologically normal people don’t like harming others; people whodo so tend to have low empathy, perhaps because of childhood abuse, or (moreoften) to have minimisation strategies to justify their actions.
 Bank robberssee bankers as the real exploiters; soldiers dehumanise the enemy as ‘gooks’ or‘terrs’; and most common murderers see their crimes as a matter of honour.
“She cheated on me” and “He disrespected me” are typical triggers; we discussedthe mechanisms in section 3.
2.
4.
These mechanisms go across to the worldof online and electronic fraud.
 Hackers on the wrong side of the law tend tofeel their actions are justiﬁed anyway: hacktivists are political activists afterall, while cyber-crooks use a variety of minimisation strategies to avoid feelingguilty.
 Some Russian cybercrooks take the view that the USA screwed Russianover after 1989, so they’re just getting their own back (and they’re supportedin this by their own government’s attitudes and policies).
 As for bankers whodump fraud risks on customers, they talk internally about ‘the avalanche offraudulent risks of fraud’ they’d face if they owned up to security holes.
Third, it’s important to understand the pathways to crime, the organisationof criminal gangs, and the di↵usion of skills.
 Steve Levitt studied the organi-sation and ﬁnances of Chicago crime gangs, ﬁnding that the street-level dealerswere earning less than minimum wage [1151].
 They were prepared to stand inthe rain and be shot at for a chance to make it to the next level up, where theneighbourhood boss drove around in a BMW with three girls.
 Arresting theboss won’t make any di↵erence as there are dozens of youngsters who’ll ﬁght toreplace him.
 To get a result, the police should target the choke point, such asthe importer’s system administrator.
 These ideas also go across.
 Many cyber-criminals start o↵ as gamers, then cheat on games, then deal in game cheats,then learn how to code game cheats, and within a few years the more talentedhave become malware devs.
 So one policy intervention is to try to stop kidscrossing the line between legal and illegal game cheating.
 As I mentioned insection 3.
2.
4, the UK National Crime Agency bought Google ads which warnedpeople in Britain searching for DDoS-for-hire services that the use of such ser-vices was illegal.
 Ben Collier and colleagues used our Cybercrime Centre datato show that this halted the growth of DDoS attacks in the UK, compared withthe USA where they continued to grow [454].
We discussed the overall costs of cybercrime in section 2.
3, noting that theecosystem has been remarkably stable over the past decade, despite the fact thatSecurity Engineering293Ross Anderson8.
7.
 SUMMARYthe technology has changed; we now go online from phones more than laptops,use social networks, and keep everything in the cloud.
 Most acquisitive crimeis now online; in 2019 we expect that about a million UK households su↵ereda burglary or car theft, while over two million su↵ered a fraud or scam, almostalways online.
 (In 2020 the di↵erence will be even more pronounced; burglaryhas fallen still further with people staying at home through the lockdown.
) Yetpolicy responses lag almost everywhere.
 Studies of speciﬁc crimes are reportedat various places in this book.
The e↵ects of cybercrime are also studied via the e↵ects of breach disclosures.
Alessandro Acquisti and colleagues have studied the e↵ects on the stock price ofcompanies of reporting a security or privacy breach [15]; a single breach tendsto cause a small dip that dissipates after a week or so, but a double breach canimpair investor conﬁdence over the longer term.
 Breach disclosure laws havemade breaches into insurable events; if TJX loses 47m records and has to pay$5 to mail each customer, that’s a claim; we’ll discuss cyber-insurance later insection 28.
2.
9.
Overall, though, measurement is tricky.
 Most of the relevant publicationscome from organisations with an incentive to talk up the losses, from policeagencies to anti-virus vendors; our preferred methodology is to count the lossesby modus operandi and by sector, as presented in section 2.
3.
8.
7SummaryMany systems fail because the incentives are wrong, rather than because of sometechnical design mistake.
 As a result, the security engineer needs to understandbasic economics as well as the basics of crypto, protocols, access controls andpsychology.
 Security economics has grown rapidly to explain many of the thingsthat we used to consider just ‘bad weather’.
 It constantly throws up fascinatingnew insights into all sorts of questions from how to optimise the patching cyclethrough whether people really care about privacy.
Research problemsSo far, three areas of economics have been explored for their relevance to se-curity, namely microeconomics, game theory and behavioural economics.
 Buteconomics is a vast subject.
 What other ideas might it give us?In the history paper I wrote on the origins of security economics, I suggesteda new research student might follow the following heuristics to select a researchtopic.
 First, think of security and X for other subﬁelds X of economics.
 Second,think about the security economics of Y for di↵erent applications Y ; there havealready been some papers on topics like payments, pornography, gaming, andcensorship, but these aren’t the only things computers are used for.
Third,where you ﬁnd gold, keep digging (e.
g.
 behavioral privacy) [78].
 Since then Iwould add the following.
Fourth, there is a lot of scope for data-driven research now that we’re startingSecurity Engineering294Ross Anderson8.
7.
 SUMMARYto make large datasets available to academics (via the Cambridge CybercrimeCentre) and many students are keen to develop skills in data science.
 A relatedproblem is how to gather more data that might be useful in exploring other ﬁelds,from the productivity of individual security sta↵ to how security works withininstitutions, particularly large complex institutions such as governments andhealthcare systems.
 Is there any good way of measuring the quality of a securityculture? Fifth, now we’re starting to put software and online connectivity indurable safety-critical things like cars and medical devices, we need to know alot more about the interaction between security and safety, and about how wecan keep such systems patched and running for decades.
 This opens up all sortsof new topics in dependability and sustainability.
The current research in security economics is published mostly at the Work-shop on the Economics of Information Security (WEIS), which has been heldannually since 2002 [76].
 There are liveblogs of all but one of the workshops,consisting of a summary of each paper and a link to it, which you can get onmy blog or linked directly from my Economics and Security Resource Page athttp://www.
cl.
cam.
ac.
uk/~rja14/econsec.
html.
Further readingThe classic introduction to information economics is Shapiro and Varian’s ‘In-formation Rules’ which remains remarkably fresh for a book written twentyyears ago [1718].
 This is still on our student reading list.
 The most up-to-datesummary is probably Jacques Cr´emer, Yves-Alexandre de Montjoye and HeikeSchweizter’s 2019 report for the European Commission’s Directorate-General ofCompetition, which analyses what goes wrong with markets in which informa-tion plays a signiﬁcant role [497]; I would read also Carl Shapiro’s 2019 reviewof the state of competition policy in the USA[1717].
Tim Wu’s “The Master Switch” discusses monopoly in telecomms and theinformation industries generally from the viewpoint of ten years ago [2049].
 Ifyou plan to do research in the subject and your degree wasn’t in economics,you might work through a standard textbook such as Varian [1941] or the CoreEconomics website.
 Adam Smith’s classic ‘An inquiry into the nature and causesof the wealth of nations’ is still worth a look, while Dick Thaler’s ‘Misbehaving’tells the story of behavioural economics.
The early story of security economics is told in [78]; there’s an early (2007)survey of the ﬁeld that I wrote with Tyler Moore at [110], and a more com-prehensive 2011 survey, also with Tyler, at [111].
 For privacy economics, seeAlessandro Acquisti’s online bibliography, and the survey paper he wrote withGeorge Loewenstein and Laura Brandimarte [16]; there’s also a survey of theliterature on the privacy paradox by Spiros Kokolakis [1076].
 Then, to dive intothe research literature, I’d suggest the WEIS conference papers and liveblogs.
A number of economists study related areas.
 I mentioned Jack Hirshleifer’sconﬂict theory [907]; another important strand is the economics of crime, whichwas kick-started by Gary Becker [200], and has been popularised by Steve Levittand Stephen Dubner’s “Freakonomics” [1151].
 Diego Gambetta is probably theSecurity Engineering295Ross Anderson8.
7.
 SUMMARYleading scholar of organised crime; his ‘Codes of the Underworld: How CriminalsCommunicate’ is a classic [742].
 Finally, there is a growing research communityand literature on cyber-criminology, for which the website of our CambridgeCybercrime Centre might be a reasonable starting point.
Security Engineering296Ross Anderson