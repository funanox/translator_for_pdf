Chapter 24Copyright and DRMBe very glad that your PC is insecure – it means that after you buyit, you can break into it and install whatever software you want.
What YOU want, not what Sony or Warner or AOL wants.
– JOHN GILMORE24.
1IntroductionCopyright has been among the highly contentious issues of the digital age, anddrove the development of digital rights management (DRM).
 The big ﬁght wasbetween Hollywood and the tech industry in the 1990s and 2000s; by 2010 ithad essentially been resolved.
 We won; power in the music and ﬁlm industrypassed from ﬁrms like EMI and Universal to ﬁrms like Apple, Spotify, Amazonand Netﬂix, while Amazon cornered the market in books – ﬁrst physically andthen with e-books.
 Technically, the world moved from enjoying music and videofrom local media such as CDs and DVDs (which many people used to share)and satellite broadcast TV (which some people used to hack), to broadbandstreaming services where subscription management is fairly straightforward.
 Ithought seriously about dropping this chapter from the third edition and justreferring you to the second edition chapter online, as there’s not a lot more tosay technically.
 On reﬂection I decided to edit it to give the context as seenfrom 2020.
 Just as the multilevel secure systems I describe in Chapter 9 arelargely obsolete but drove the development of military computer security andinﬂuenced today’s security landscape in many subtle ways, so also the copyrightwars left their mark.
 DRM is still used: in ebooks, in the Fairplay system onyour iPhone to make it harder to copy songs, and in HTML5 in your browser tomake it harder for you to copy Netﬂix videos.
 Very similar techniques are usedin gaming platforms to make it harder for players to use aimbots, in protectinguser data on cloud platforms, and in mobile phone security where RuntimeApplication Self-Protection (RASP) is used to defend banking and other appsagainst malware that roots the phone.
 Accessory-control mechanisms that ourindustry adopted to protect game cartridges now use cryptography to supportbusiness models in dozens of business sectors.
 My ﬁnal reason to spare this73724.
1.
 INTRODUCTIONchapter is that the copyright wars became part of our shared security culture,and even if you’re too young to have taken part, you may occasionally ﬁnd ithelpful to understand what we greybeards are blethering on about.
At the political level, the control of information has been near the centreof government concerns since before William Tyndale (one of the founders ofthe Cambridge University Press) was burned at the stake for printing the Biblein English.
The sensitivity continued through the establishment of moderncopyright law starting with the Statute of Anne in 1709, through eighteenth-century battles over press censorship, to the Enlightenment and the framing ofthe US Constitution.
 The link between copyright and censorship is obscuredby technology from time to time, but has a habit of reappearing.
 Copyrightmechanisms exist to keep information out of the hands of people who haven’tpaid for it, while censors keep information out of the hands of people who aren’ttrusted with it.
 Where ISPs are compelled to install ﬁlters that prevent theircustomers from downloading copyrighted material, these ﬁlters can often beused to block seditious material too.
Over the twentieth century, the great wealth accruing to the owners of lit-erary copyright, ﬁlms and music created a powerful interest in control.
 As theInternet took o↵, the music and ﬁlm industries feared losing sales to digitalcopying, and lobbied for sweetheart laws – the DMCA in America in 1998, anda series of IP Directives in Europe – that give special legal protection to mech-anisms that enforce copyright.
 These laws have since been used and abusedfor all sorts of other purposes, from taking down phishing websites to stoppingpeople from reﬁlling printer cartridges and even from repairing broken devices.
The ostensible target of these laws was the DRM used from the 1990s inproducts such as Windows Media Player, and since 2017 in browsers compliantwith HTML5, to control the copying of music and videos.
 The basic idea in DRMis to make a ﬁle uncopiable by encrypting it, and then providing separately a‘license’ which is the key to the media ﬁle encrypted using a key unique to theuser, plus some statements in a ‘rights management language’ about what theuser can do with the content.
 The app that renders the media content is trustedto abide by these.
 I’ll also give a quick tour of the history and describe someinteresting variants such as satellite TV encryption systems, copyright markingand traitor tracing.
 DRM is less relevant now than in 2008 when the secondedition of this book came out, but there are still some applications, which I’lldescribe later.
Some serious policy issues are mixed up in all this.
 It’s hard to make DRMcompatible with open-source software unless you have either trustworthy hard-ware such as enclaves or TPMs, or closed-source sandboxes that are patched assoon as they are reverse engineered.
 The computer industry resisted DRM butHollywood and the music industry forced us to introduce it, saying that withoutit they’d be ruined.
 We warned them that DRM would ruin them, and theydidn’t listen.
 Music is no longer run by ﬁrms like Universal and EMI but byﬁrms like Apple and Amazon – and the move to streaming let new ﬁrms likeSpotify join the party.
 DRM introduced serious privacy issues, though, whichhave not gone away with streaming.
 Instead of a license management server inMicrosoft knowing every music track you’ve ever listened to, and every movieyou’ve ever watched, it’s now streaming servers at Apple or Spotify or Netﬂix.
Security Engineering738Ross Anderson24.
2.
 COPYRIGHT24.
2CopyrightThe protection of copyright has for years been an obsession of the ﬁlm, musicand book publishing industries.
 There were long and acrimonious disputes inmany countries about whether blank audiocasettes, and then videocassettes,should be subjected to a tax whose proceeds would be distributed to copyrightowners.
 Going back to the nineteenth century, there was alarm that the inven-tion of photography would destroy the book publishing trade; the eighteenthsaw book publishers trying to close down public lending libraries, until they re-alised they were creating mass literacy and driving sales; while in the sixteenth,the invention of movable type printing was considered subversive by most of thepowers of the day, from princes and bishops to craft guilds.
We’ll come back to these historical examples later.
 But I’m going to startby looking at software protection – as most of the copyright issues that led toDRM played out in the PC and games software markets from the 1980s.
24.
2.
1SoftwareSoftware for early computers was given away free by the hardware vendors orby users who’d written it.
 IBM even set up a scheme in the 1960s whereby itsusers could share programs they’d written.
 (Most business programs were toospecialised, too poorly documented, or just too hard to adapt.
 But softwareused in research was widely shared.
) So protecting software copyright was notan issue.
 Almost all organizations that owned computers were large and re-spectable; their software tended to require skilled maintenance.
 There were alsocomputer bureau services – the forerunner of today’s cloud computing – wherethe owner of a mainframe who used it to work out their own payroll would o↵erthis as a service to other ﬁrms.
 There, you bought the service, not the software.
The hardware costs were the dominant factor.
When minicomputers arrived in the 1960s, software costs became signiﬁcant.
Hardware vendors started to charge extra for their operating system, and third-party system houses sprang up.
 To begin with, they mostly sold you a completebespoke system – hardware, software and maintenance – so piracy was still notmuch of an issue.
 By the mid-1970s, some of them had turned bespoke systemsinto packages: software originally written for one bakery would be parametrisedand sold to many bakeries.
 The most common copyright dispute in those dayswas when a programmer left your company to join a competitor, and their codesuddenly acquired a number of your features; the question then was whetherhe’d taken code with him, or reimplemented it.
One way to resolve such a problem is to look at software birthmarks – fea-tures of how a particular implementation was done.
 For example, litigation overwhether people had copied software from the ROM of the early IBM PCs turnedon the order in which registers are pushed and popped, as the software had beenwritten in assembler.
 This merged with the ﬁeld of stylometry in which human-ities scholars try to attribute authorship by analysis of writing styles1.
 More1The cryptanalyst William Friedman and his wife Elizebeth were hired by an eccen-tric millionaire to ﬁgure out whether Bacon wrote Shakespeare.
They concluded that heSecurity Engineering739Ross Anderson24.
2.
 COPYRIGHTrecently, the natural-language processing community has written plagiarism de-tection tools, which typically recognise a passage of text by indexing it accordingto the least common words that appear in it [879]; by the 1990s this had led totools that try to identify malware authors from their coding style [1099].
 Codestylometry is still an active area of research [370].
With time, people invented lots of useful things to do with software.
 So aﬁrm that had bought a minicomputer for stock control (or contracted for timeon a bureau service) might be tempted to run a statistical program as well toprepare management reports.
 Meanwhile, the installed base of machines gotlarge enough for software sharing to happen more than just occasionally.
 Sosome system houses started to design enforcement mechanisms.
 A common onewas to check the processor serial number; another was the time bomb.
 When Iworked in 1981 for a company selling retail stock control systems, we caused amessage to come up every few months saying something like “Fault no.
 WXYZ– please call technical support”.
 WXYZ was an encrypted version of the licenseserial number, and if the caller claimed to be from that customer we’d give thema password to re-enable the system for the next few months.
 (If not, we’d sendround a sales person.
) This mechanism could have been defeated easily if the‘customer’ understood it, but in practice it worked ﬁne: most of the time it wasa low-level clerk who got the fault message and called our o�ce.
Software copyright infringement really started to become an issue when thearrival of microcomputers in the late 1970s and early 80s created a mass market,and software houses started to ship products that didn’t need technical supportto install and run.
 Initial responses varied.
 There was a famous open letter fromBill Gates in 1976, a year after Microsoft was founded, in which he complainedthat less than 10% of all microcomputer users had paid them for BASIC [722].
“Who cares if the people who worked on it get paid?” he asked.
 “Is this fair?”His letter concluded: “Nothing would please me more than being able to hireten programmers and deluge the hobby market with good software.
”Appeals to fair play only got so far, and the industry next tackled the maindi↵erence between minis and the early micros – the latter had no processor serialnumbers.
 There were three general approaches tried: to add uniqueness on tothe machine, to create uniqueness in it, or to use whatever uniqueness happenedto exist already by chance.
1.
 The standard way to add hardware uniqueness was a dongle – a deviceattached to the PC which could be interrogated by the software.
Thesimplest just had a serial number; the most common executed a sim-ple challenge-response protocol; while some top-end devices actually per-formed some critical part of the computation.
2.
 A very common strategy in the early days was for the software to installitself on a PC’s hard disk in a way that resisted naive copying.
 For exam-ple, a sector of the hard disk would be marked as bad, and a critical partof the code or data written there.
 Now if the product were copied from thehard disk using the standard utilities, the bad sector wouldn’t be copiedand the copy wouldn’t work.
 A variant on the same theme was to requirehadn’t.
 [1001].
Security Engineering740Ross Anderson24.
2.
 COPYRIGHTthe presence of a master diskette which had been customized in some way,such as by formatting it in a strange way or even burning holes in it witha laser.
 In general, though, a distinction should be drawn between pro-tecting the copy and protecting the master; it’s often a requirement thatpeople should be able to make copies for backup if they wish, but not tomake copies of the copies (this is called copy generation control).
3.
 1988 saw the arrival of the license server, basically a machine programmedto act as a dongle shared by all the machines on a company network, whichsupported more complex business models such as enabling a company tobuy the right to run a program on up to 20 machines at once, and enablingmultiple software companies to license their products via the same licenseserver.
4.
 A product I worked on in 1989 ﬁngerprinted the PC – what extensioncards were present, how much memory, what type of printer – and if thisconﬁguration changed too radically, it would ask the user to phone thehelpline.
 It’s quite surprising how many unique identiﬁers there are in theaverage PC; ethernet addresses and serial numbers of disk controllers areonly the more obvious ones.
 So you can tie software to a given machineﬁngerprint; ad trackers use similar techniques to this day.
A generic attack that works against most of these defenses is to go throughthe software with a debugger and remove all the calls made to the copy protec-tion routines.
 Many hobbyists did this for sport, and competed to put unpro-tected versions of software products online as soon as possible after their launch.
Even people with licensed copies of the software often got hold of unprotectedversions as they were easier to back up and often more reliable generally.
 Youcan stop this by having critical code somewhere uncopiable (such as in a dongle,a license server, or nowadays in the cloud) but this arms race taught everyonethat if you don’t do something like that then kids with debuggers will alwaysbreak your scheme eventually.
 It’s one reason why closed platforms, like gamesconsoles and the iPhone, only run signed code.
The vendors also used psychological techniques.
• The installation routine for many business programs would embed theregistered user’s name and company on the screen, for example, in thetoolbar.
 This wouldn’t stop a pirate distributing copies registered in afalse name, but it will discourage legitimate users from giving casual copiesto colleagues.
 To this day, when I download papers from many academicjournals, my university’s name and a serial number are visible in the pdf.
These are examples of copyright marking which I’ll discuss in more detaillater.
• Industry people delighted in telling tales of organizations that had comeunstuck when they failed to get a critical upgrade they hadn’t paid for.
• If early Microsoft software (Multiplan, Word or Chart) thought you wererunning it under a debugger, it would put up the message ‘The tree ofevil bears bitter fruit.
 Now trashing program disk.
’ It would then seek totrack zero on the ﬂoppy disk and go ‘rrnt, rrnt, rrnt’.
Security Engineering741Ross Anderson24.
2.
 COPYRIGHTIn the late-1980s, the market split.
 The games market moved to hardwareprotection, and ended up dominated by consoles with closed architectures whosesoftware was sold in proprietary cartridges.
 As consumers are more sensitiveabout the sticker price of a product than about its total cost of ownership, itmakes sense to subsidise the console out of later sales of software.
 This led toaccessory control in which hardware protection is used to control aftermarkets;it was adopted by ﬁrms selling printers and much else.
 We’ll discuss it in detailin section 24.
6.
Business software vendors moved from dongles to license servers for high-value products such as the CAD software used to design everything from chipsto ships.
 Technical support is often critical for such products, so they may besold as a bundle of software and service.
 But vendors generally stopped tryingto protect mass-market products using technical means, for several reasons.
• Unless you’re prepared to spend money on dongle hardware to executesome of your critical code, the mechanisms in mass-market software will bedefeated by people for whom it’s an intellectual challenge, and unprotectedcode will be published anonymously.
• Protection was a nuisance.
 Multiple dongles get in the way or interferewith each other.
 Software protection techniques get in the way of backupand recovery; they also cause software from di↵erent vendors to be incom-patible and in some cases unable to reside on the same machine.
 (Thedi�culty of doing this right is one reason why so many of the ﬁrms whouse license management use Flexlm.
)• Many vendors preferred not to have to worry about whether the soft-ware was licensed to the user (in which case he could migrate it to a newmachine) or to the machine (in which case he could sell the computersecond-hand with the software installed).
 As both practices were com-mon, mechanisms that made one or the other very much harder causedproblems.
 Mechanisms that could deal with both (such as dongles andlicense servers) tended to be expensive.
• The arrival of computer viruses forced corporate customers to invest insoftware hygiene, so casual copying couldn’t be condoned so easily.
 Withina few years, antivirus programs made life much harder for copy protectionmechanisms in any case, as non-standard operating system usage tendedto set o↵ alarms.
• There was not much money to be made out of harassing personal users asthey often made only casual use of the product and would throw it awayrather than pay.
• A certain level of sharing was good for business.
 People who got a piratecopy of a tool and liked it would often buy a regular copy, or persuadetheir employer to buy one.
 In 1998 Bill Gates even said, “Although aboutthree million computers get sold every year in China, people don’t pay forthe software.
 Someday they will, though.
 And as long as they’re going tosteal it, we want them to steal ours.
 They’ll get sort of addicted, and thenwe’ll somehow ﬁgure out how to collect sometime in the next decade”[755].
Security Engineering742Ross Anderson24.
2.
 COPYRIGHT• Competition led to falling costs which made piracy less attractive.
 In thecase of tools, for example, Borland shook up the industry with its launch ofTurbo Pascal in 1983.
 Before then a typical language compiler cost about$500 and came with such poor documentation that you had to spend afurther $50 on a book to tell you how to use it.
 Borland’s product cost$49.
95, was technically superior to Microsoft’s, and came with a manualthat was just as good as a third party product.
(So, like many otherpeople, once I’d heard of it, borrowed a copy from a friend, tried it andliked it, I went out and bought it.
) ‘Pile it high and sell it cheap’ simplyproved to be a more proﬁtable business model.
The industry then turned to the law.
 Software is mostly protected by copy-right law; when you write software (or a book, or a tune) copyright comesinto existence automatically nowadays and you have the right to sue peoplefor damages if they make copies without your permission.
 The details vary bycountry but copyright infringement tends to be a crime only if done at commer-cial scale.
 So copyright owners can send unpleasant letters to individuals andsmall businesses, but actually suing them for a few dollars or pounds or euros inthe small claims court is uneconomic.
 Against large-scale users, though, copy-right enforcement can be worthwhile.
 In fact, when IBM separated its hardwareand software businesses in 1969 – following a lawsuit from the US governmentwhich claimed that bundling software with hardware entrenched their marketdominance – they took a strategic decision not to use any technical copyright en-forcement mechanisms as they would be onerous to customers and not e↵ectiveagainst clever thieves, so they’d rely on the law instead [1793].
In 1988, Microsoft led the industry in IBM’s footsteps, and established tradeorganizations (such as the Business Software Alliance in the USA) that broughthigh-proﬁle prosecutions of large companies that had been condoning widespreaduse of unlicensed software.
 This was followed up by harassing medium and evensmall businesses with threatening letters demanding details of the company’spolicy on enforcing copyright – basically demanding they sign up for an approvedsoftware audit schemes or risk a raid by an enforcement squad.
The industry discovered that the law not only provides tools for enforce-ment, but sets limits too.
 In 1993, a software company director in Scunthorpe,England, received a criminal conviction under Britain’s Computer Misuse Actfor ‘making an unauthorized modiﬁcation’ to a system.
 Their customers had toenter unlock codes regularly into his software or it froze, denying access to data.
But when he used this mechanism to enforce payment of a disputed invoice, thecourt decided he’d gone too far, and he ended up with a criminal record [455].
Thanks to the ubiquity of O�ce, Microsoft had by then become a tax on thecorporate sector, making most of its revenue from customers with over 25,000licenses.
In addition to O�ce, it was selling many high-value products fornetwork management and other tasks, so like the CAD ﬁrms it turned to licenseservers.
 Although these could still be defeated by disassembling the applicationcode, this got harder as code became larger, and was unattractive to large ﬁrmsafter a few of them had been sued.
 Then the very idea of running on unlicensedsoftware became crazy when Patch Tuesday arrived in 2003.
With personalsoftware, the emphasis shifted to online registration: you’d design your productSecurity Engineering743Ross Anderson24.
2.
 COPYRIGHTto get customers to interact with your web site – whether to download the tunes,latest exchange rates or security updates.
 Large-scale commercial counterfeitingcan then be detected by monitoring product serial numbers registered online2.
I wrote in the second edition of this book in 2008: “software-as-a-service maybe the ultimate copyright protection or DRM for software (or any other contentthat can live online): you can’t buy it, freeze the version you’re running, or useit o✏ine.
 You may also get to control all your customers’ data too, giving youimpressive lockin”.
 That is precisely the model to which the software industryhas converged since the early 2010s.
 Putting some or all of the functionality inthe cloud can give real advantages of cost and reliability, which I will discussin section 27.
5.
5.
 Software is then sold by subscription and the issue of copyprotection goes away.
24.
2.
2Free software, free culture?In the old days, software was shared and this continued to be the case among aca-demics and other research scientists, who evolved many communities of practicewithin which software was shared freely and adapted by successive contributors.
This continued to support the dominant platforms of the time, which initiallymeant IBM.
 During the 1970s, for example, the UK government pushed Britishacademics to buy ICL computers; ICL was Britain’s champion, having been setup in the 1960s when the government nationalised the computer industry to‘save’ it from IBM.
 However, we academics wanted IBM mainframes as otheracademics worldwide had written software that ran on their hardware, and evenalthough most was written in high-level languages like FORTRAN, porting itwas a hassle.
 The arrival of home computers in the 1970s and the PC in 1981developed ever wider communities of software enthusiasts who shared our work,whether by physically passing diskettes around friends or in clubs, or via earlybulletin-board systems and other dial-up networks.
In 1983 IBM stopped supplying the source code for its products, introducinga policy of ‘object code only’, and other vendors followed.
This made it alot harder to understand the platforms and tools on which we relied and led topushback on a number of fronts.
 Two years later, Richard Stallman, an engineerat MIT, was annoyed when he could not integrate a new Xerox printer with thelocal maintenance arrangements as Xerox would not supply source code for theprinter driver.
 He announced the GNU project to build a free operating system,and helped found the Free Software Foundation (FSF), which promoted theidea of free software.
 Free software means that users should be able to run it forany purpose, study how it works and change it, and redistribute it – includingimproved or modiﬁed versions.
 One slogan was ‘free as in free speech, not asin free beer’, but free software comes in many ﬂavours.
 The FSF promotedthe GNU General Public License (GPL) which has the property that anyoneadapting GPL licensed software and making it available must make the source2Once they got product registration sorted out, Microsoft found that a third of the copiesof O�ce sold in Germany were counterfeit, and traced them to a small factory a few miles upthe road from us in Cambridge.
 Almost all the factory’s sta↵ were unaware of the scam – theybelieved the company was a bona ﬁde Microsoft supplier.
 They were proud of their productand their sales sta↵ used it to try to get CD duplication business from other software houses.
Security Engineering744Ross Anderson24.
2.
 COPYRIGHTcode of their adaptation publicly available, under the same license – a viralproperty also known as ‘copyleft’.
 In 1988, the University of California releasedthe Berkeley distribution of Unix under the less restrictive BSD license thatsimply allows anyone to use the software for any purpose.
Such licensing arrangements are necessary because otherwise an operatingsystem that had been written by 500 di↵erent people over 20 years would containcode that was their copyright, and so any of them could go to court to exercisetheir right to prevent some third party from using it.
Proprietary softwarevendors can get the copyright in code written by engineers they employ3, butwhat about projects maintained by volunteers? Open licenses help avoid thicketsof conﬂicting claims.
There was much argument through the 1990s about their respective merits,but both approaches are in wide use.
 Linux was ﬁrst released in 1991 underthe GPL, while Berkeley Unix spawned FreeBSD and other variants which areavailable under the BSD license.
 As we noted in the chapter on Access Controls,Linux was the platform on which Android was built, while FreeBSD evolved intoOSX and iOS.
 Other free software licenses were developed for Apache and inother communities, and public licenses spread quickly from software to othercreative activities: for example, a variant of BSD was adapted for Wikipedia.
Software and culture both involve the adaptive and cumulative contributionsof many individuals.
 Traditional musicians sometimes compose new tunes butmore often change existing ones; even new compositions draw on phrases fromthe existing vocabulary.
 DJs rip tracks from others and mash them togetherinto new compositions.
 Novelists reuse old storylines and character stereotypes,while comedians recycle old jokes.
 The law doesn’t always deal with this verywell as it tends to be written for large corporate interests rather than for com-munities.
 So music companies would press musicians to write entirely new tuneswith clean copyrights rather than following tradition and adapting the best tunesof the older players.
Academia is also a place where we build on each others’ work, and has thefurther twist that we get our recognition from the number of people who use ourwork rather than the number of people who pay for it.
 Mathematicians becomefamous if lots of other mathematicians use their theorems in other results, andcomputer scientists get recognition if lots of people use our software.
 This createsreal tensions with publishers.
 Indeed, starting in the 1970s, many computerscientists made both our code and our publications available freely online, usingFTP servers and later, once they were invented, web pages.
We tended toignore the copyright agreements we had to sign with academic journals to getour papers published – or if we were careful we crossed out the ‘exclusive’ clausein the agreements, which back then were paper forms that the publishers neverbothered to check.
1994 saw a couple of publications with real impact.
 Andrew Odlyzko calcu-lated that the U.
S.
 government spent about $100M a year doing mathematics3The law varies from one country to another.
 In some countries, such as the USA, youown copyright in a program written by an employee, while in others you have to make it aterm in an employment contract; and contractors are another matter altogether.
 And sincethe pandemic lockdown, half my team are working from home in di↵erent countries.
 It reallyis prudent to have a written agreement.
Security Engineering745Ross Anderson24.
2.
 COPYRIGHT(by paying professors’ salaries and the stipends of grad students) and a fur-ther $100M a year marketing mathematics (being the money that was spent injournals and conferences, plus the unpaid labour that mathematicians put inso journal publishers could make their proﬁts) [1459].
 If publication went fullyonline and all papers were available for all to read, perhaps the amount spenton actual mathematics could be increased.
 A quarter of a century and manytussles later, most government and charitable funders insist that the researchthey pay for is made available to all (though the journals have survived verycomfortably by imposing page charges on authors, and also demanding thatuniversity libraries buy subscriptions for online access to their back catalogue).
The second, and better-known, was a paper by EFF founder John PerryBarlow, who was also a lyricist for the Grateful Dead.
 He pointed out that asthe marginal cost of copying is zero with digital technology, ‘information wantsto be free’ (which he ascribed to Stewart Brand).
 Both the physical containers ofideas (books, CDs) were vanishing, as was jurisdiction, as the Internet enabledpeople to swap ﬁles across national boundaries.
 He warned against corporatelegal departments trying to protect by force what could no longer be protectedby practical e�ciency or general social consent, and about the USA writingcopyright compliance into trade treaties: “Ideally, laws ratify already developedsocial consensus.
” He called for ﬁrms to develop business models that wouldwork with the grain of the information age.
 His band, the Grateful Dead, letpeople tape their songs from the 1970s, and became one of the biggest stadiumdraws.
 He suggested that other industries explore models of live performanceand service rather than selling bundles of bits [170].
There was vigorous debate and innovation on the copyright front during thedotcom boom of the later 1990s.
 Quite apart from arguments about books, jour-nals, music and ﬁlms – to which we will return shortly – there was a growingrealisation of the need for shared infrastructure and tools.
 Many common com-ponents of the communications infrastructure, such as BGP, DNS and SMTP,had been ﬁrst implemented at taxpayer expense and published, and ﬁrms oftenfound they needed to add still more code to the commons.
 For example, afterNetscape made available the ﬁrst popular web browser in 1994, Microsoft killedthem by giving away its own browser, Internet Explorer, free with Windows, andtried to create a monopoly at the server side with a product then called InternetInformation Server which it launched in 1995.
 Other ﬁrms who were racing toestablish a presence in the growing e-commerce industry were so alarmed at theprospect of Microsoft extracting all the value that they set up Apache, whichbecame the leading web server the following year.
 This may have been one ofthe most important pieces of software ever written, as it meant that Microsoftcould not control both ends of the link in the early days of the web, so they couldnot turn it into something proprietary from which they could extract rent.
 As aresult, the web remained open for many years, and it was possible for companiessuch as Google and Facebook to get going.
 (We may now have a policy strugglewith them instead, but a lot of innovation happened meantime.
)Moving from the policy to the mechanics, when software engineers – or bookauthors or musicians – place works in the public domain, we have a wide rangeof conditions we may want to attach.
 Some writers are happy for their workto be used by anyone, so opt for a BSD-style license; others want their work toSecurity Engineering746Ross Anderson24.
2.
 COPYRIGHTremain in the commons rather than being incorporated into closed proprietaryproducts, so prefer the GPL; academics generally want our stu↵ to be usedprovided we’re acknowledged as the creators.
 In 2001 Larry Lessig founded theCreative Commons (CC) to bring some order to this; it makes available a set oflicenses which parametrise this and enable you to specify how your work maybe used.
 For example, you can specify whether a user can share your work withothers; whether commercial uses are allowed; whether they must give you properattribution; whether they can adapt and build on it, and if so whether they haveto distribute their contributions under the same license as the original.
 Theselicenses are now used widely outside of software.
 In fact, most of my academicpapers are available under CC licenses, and my agreement with the publishersof this book speciﬁes that I may make all the chapters available freely online42 months after the manuscript is sent for publication.
 I appreciate it if youpay for the book, but I want it to be available to everybody – even if the latestversions go online after a delay.
A critical development came in 1996 with section 230 of the US Communi-cations Decency Act (CDA).
 This let the online service providers o↵ the hookon copyright law by stating that ‘No provider or user of an interactive computerservice shall be treated as the publisher or speaker of any information providedby another information content provider’ – making ﬁrms like Google and Face-book possible, and leaving the corporate lawyers to chase individual ﬁle sharers.
The service ﬁrms are supposed to take down infringing content when they’re no-tiﬁed of it; in practice, the boundaries are hard to police, and the incentives areperverse (section 230 shelters them when they run ads for counterfeiters [1830]).
We’ll return to this later, in this chapter and in Chapter 26.
So there are many alternative business models, both for software and forother products of human creativity.
 One is freemium: you give away a basicversion of the product, and sell a premium version.
 (Even once this book is freeonline as PDF ﬁles, you’ll have to pay money for a printed book.
) Another is togive your software away free, and make your money from selling services, fromadvertising, or by acting as spyware and selling data about the user.
 You cancombine them: get customers addicted to your free product, and then sell themmore storage or an ad-free experience.
 The success of these models in software –with the Linux industry living from consulting and Google from ads – suggesteda similar approach to other online businesses.
In the second edition of this book in 2008, I suggested then that“the solutionfor Hollywood’s problem lies in a change of business model.
” As this third editionwent to press in August 2020, the New York Times was lamenting the death ofHollywood [1791].
 The studio that led Hollywood, Warner, had its executivesﬁred, without the usual golden parachutes; no longer masters of the universe,they had become the employees of the video production arm of a phone company.
The ﬁlm industry had changed from a wholesale business which did deals withdistributors over a handshake by the pool into a retail one where maximisingsubscription revenue is the core skill.
 The only studio to remain in recognisableform is Disney, which managed the transition to subscription early – helpedperhaps by having Steve Jobs as its largest shareholder and as a main boarddirector.
I will return to copyright policy later in section 24.
5, but let’s now take aSecurity Engineering747Ross Anderson24.
2.
 COPYRIGHTquick historical tour at the world of protecting media content.
24.
2.
3Books and musicIn 1800, there were only 80,000 frequent readers in England; most of the booksup till then were serious philosophical or theological tomes.
 After the inventionof the novel, a mass market appeared for books, and circulating libraries sprangup to service it.
 The educated classes were appalled, and printers were frightenedthat the libraries would deprive them of sales.
But the libraries so whettedpeople’s appetite for books that the number of readers grew to 5,000,000 by1850.
 Sales of books soared as people bought books they’d ﬁrst borrowed froma library.
 The library movement turned out to have been the printers’ greatestally and helped create a whole new market for mass-market books [1718].
People have been copying music much longer than software.
 Paganini wasso worried that people would copy his violin concertos that he distributed thescores himself to the orchestra just before rehearsals and performances, andcollected them again afterwards.
 (As a result, many of his works were lost toposterity.
)Copyright collecting societies were established from the mid-19th century,starting in Paris; composers who were members would charge venues or bandsa fee for performing their compositions.
 In many countries these have becomemonopolies backed by law; to perform at our university’s concert hall, you haveto pay the Performing Rights Society a levy.
 You can submit them a playlist,and if you play all your own compositions then some of the money may ﬁndits way back to you eventually.
Many tunes are orphan works in that theircomposers’ heirs are unknown, so the societies can either keep the money orshare it among their known composers.
 The free culture movement and thepirate parties advocate restricting or abolishing copyright in order to erase suchinjustices; but while they’ve won a few parliamentary seats in some Europeancountries, they always seem to be outgunned by the copyright lobbyists on theworld stage (an issue to which I’ll return later in section 24.
5.
1).
When the cassette recorder came along in the 1960s, the record industrylobbied for (and in some countries got) a tax on audiocassettes, to be distributedto copyright holders.
 Technical measures were also tried.
 The Beatles’ recordSergeant Pepper contained a 20KHz spoiler tone that should in theory havecombined with the 21KHz bias frequency of the tape to produce a 1KHz whistlethat would spoil the sound.
 In practice it didn’t work, as many record playersdidn’t have the bandwidth to pick up the spoiler tone.
 But in practice thisdidn’t matter.
 Cassettes turned out not to be a huge problem because soundquality is noticeably poorer on home equipment; people mostly used them torecord music to listen to in their cars.
 Then, in the 1980s, the arrival of theSony Walkman made cassettes into big business, and although there was somecopying, there were huge sales of pre-recorded cassettes and the music industrycleaned up.
Audio copying became a headline concern again in the 1990s, thanks to theMP3 format for compressing audio.
 Previously, digital audio was protected byits size: a CD of uncompressed music can take 650Mb.
 However, MP3 enablesSecurity Engineering748Ross Anderson24.
2.
 COPYRIGHTpeople to squeeze an audio track into a few megabytes, and broadband enablesﬁles of this size to be shared easily.
 By 1998, some 40% of the network tra�cat MIT was MP3 tra�c.
The industry response was to push for technical ﬁxes.
 This led to the growthof the rights-management industry.
 It had its origins in work on digital pub-lishing and in the mechanisms used to protect pay-TV and DVDs, so let’s takea quick look at those ﬁrst.
24.
2.
4Video and pay-TVThe early history of videocassettes was a replay of the history of audio cas-settes.
 At ﬁrst Hollywood was terriﬁed, and refused to release movies for homeviewing.
 Crude technical measures were taken to prevent copying – such asthe Macrovision system which added spurious synchronization pulses to confusethe recording circuitry of domestic VCRs – which again turned out to be easyto defeat.
 Then Hollywood became paranoid about video rental stores, just asbook publishers had been about libraries.
 Once more, libraries turned out tobe the publisher’s friend, as being able to rent videos got people to buy VCRsand whetted their desire to own their favorite movies.
 VCRs and videocassettesbecame mass-market products rather than rock stars’ toys, and by 2000 salesof prerecorded cassettes made up most of the income of ﬁrms like Disney.
 Thebusiness model changed so that the cinema release was really just advertisingfor the sales of the video.
By then, many of the world’s pre-teens demanded that their parents buildthem a collection of Disney cassettes, just like their friends had, so a videocas-sette pirate had to make the packaging look original.
 This reduced the problemto an industrial counterfeiting one.
 As with mass-market software before theonset of online registration, or with perfumes and Swiss watches today, enforce-ment involves sending out ﬁeld agents to buy products, look for forgeries, tracethe supply chain and bring prosecutions.
More interesting technical protection mechanisms were built into broadcastpay-TV equipment.
The advent of pay-TV, whether delivered by cable or satellite, created aneed for conditional access mechanisms which would allow a station operator torestrict reception of a channel in various ways.
 If the operator had only boughtthe rights to screen a movie in Poland, they’d have to block German or Russianviewers within the satellite footprint from watching.
 Porn channel operatorsneeded to prevent reception in countries like Ireland with strict censorship laws.
Most operators also wanted to be able to charge extra for speciﬁc events suchas boxing matches.
24.
2.
4.
1Typical system architectureThe evolution of early systems was determined largely by the hardware cost ofdeciphering video (for a history of set-top boxes, see [425]).
 The ﬁrst generationof systems, available since the 1970s, were crude analog devices which usedtricks such as inverting the video signal from time to time, interfering withSecurity Engineering749Ross Anderson24.
2.
 COPYRIGHTthe synchronization, and inserting spikes to confuse the TV’s automatic gaincontrol.
 They were easy enough to implement, but also easy to defeat; breakingthem didn’t involve cryptanalysis, just an oscilloscope and persistence.
The second generation of systems appeared in the late 1980s and employeda hybrid of analog and digital technologies: the broadcast was analog, but thesubscriber control was digital.
 These included systems such as Videocrypt andNagravision, and typically had three components:• a subscription management service at the station enciphers the outgoingvideo, embeds various entitlement management messages (EMMs) andentitlement control messages (ECMs) in it, and issues access tokens suchas smartcards to subscribers;• a set-top box converts the cable or satellite signal into one the TV can dealwith.
 This includes descrambling it;• the subscriber smartcard personalises the device and controls what pro-grammes the set-top box is allowed to descramble.
 It does this by inter-preting the ECMs and providing keys to the descrambling circuit in theset-top box.
This architecture means that the complex, expensive processes such as bulkvideo scrambling could be done in a mass-produced custom chip with a longproduct life, while key-management functions that may need to be changedafter a hack can be sold to the customer in a low-cost token that is easy toreplace.
 If the set-top box itself had to be replaced every time the system washacked, the economics would be much less attractive4.
The basic mechanism is that the set-top box decodes the ECMs from theinput datastream and passes them to the card.
 The card deciphers the ECMs toget both control messages (such as “smartcard number 123356, your subscriberhasn’t paid, stop working until further notice”) and keys, known as controlwords, that are passed to the set-top box.
 The set-top box then uses the controlwords to descramble the video and audio streams.
 There’s a detailed descriptionin [456].
24.
2.
4.
2Video scrambling techniquesBecause of the limitations on the chips available at low cost in the early 1990s,hybrid systems typically scrambled video by applying a transposition cipherto picture elements.
 A typical scheme was the cut-and-rotate algorithm usedin Videocrypt.
This scrambles one line of video at a time by cutting it ata point determined by a control byte and swapping the left and right halves(Figure 24.
1):This involved analog-to-digital conversion of the video signal, storage in abu↵er, and digital-to-analog conversion after rotation – a process which couldjust about be shoehorned into a low-cost custom VLSI chip by 1990.
 However,4Now that set-top boxes cost a few dollars, and the shipping costs dominate, the smartcardis often just soldered to the motherboard and the whole box is replaced if there’s a hack.
Security Engineering750Ross Anderson24.
2.
 COPYRIGHTPlain�Cut point�t�Cipher�t�Figure 24.
1: – cut-and-rotate scramblinga systemic vulnerability of such systems is that video is highly redundant, soit may be possible to reconstruct the image using ‘oscilloscope and persistence’techniques, enhanced by simple signal processing.
 This was ﬁrst done by MarkusKuhn in 1995 and required the use of a university supercomputer to do in realtime.
 Figure 24.
2 shows a frame of enciphered video, and Figure 24.
3 the sameframe after processing.
 By 2000, it was possible to do this on a PC [1824].
 Ifthis attack had been feasible earlier, it would have given a complete break of thesystem, as regardless of how well the smartcard managed the keys, the videosignal could be retrieved without them.
 Hybrid systems are still used by somestations in less developed countries, together with frequent key changes to makelife inconvenient for the pirates – whose problem is to distribute the keys totheir customers as they crack them.
The major developed-world operators moved to digital systems in the early2000s.
 These digital systems work on the same principle – a set-top box withthe crypto hardware and a smartcard to hold the personal keys that in turndecipher the content keys from ECMs.
 However the crypto now typically uses ablock cipher to protect the entire digital video stream.
 I’ll describe the currentdigital video broadcast systems in the next section.
The hybrid scrambling techniques lasted (just) long enough.
 However, theyhave some interesting lessons to teach, as they were subjected to quite deter-mined attack in the decade after 1995, so I’ll go brieﬂy through what wentwrong.
Figure 24.
2 – scrambled video frameFigure 24.
3 – processed video frameSecurity Engineering751Ross Anderson24.
2.
 COPYRIGHT24.
2.
4.
3Attacks on hybrid scrambling systemsGiven a population of set-top boxes that can use a stream of control words tounscramble broadcast video, the next problem was to ensure that only payingcustomers could get the control words.
In general, this could be done withallow and deny messages.
But the bandwidth available was typically of theorder of ten ECMs per second.
 So sending an allow message to each of ﬁvemillion subscribers would take over a week, and deny messages were mostlyused instead.
The customer smartcard interprets the ECMs.
 If the current programme isone the subscriber is allowed to watch, then a keyed hash – essentially a messageauthentication code (MAC) – is computed on a series of ECMs using a masterkey held in the card and supplied to the set-top box as the control word:CW = MAC(K; ECM1, ECM2, ECM3, ECM4)So if a subscriber stops paying their subscription, their card can be inacti-vated by sending an ECM ordering it to stop issuing control words; and it needsaccess to the ECM stream in order to compute control words at all.
 Providedthe cards can be made tamper-resistant, only compliant devices should haveaccess to the master key K, and they should commit suicide on demand.
 Sowhat could go wrong?The ﬁrst attacks were on the protocol.
 Since the control word sent from thesmartcard is the same for every set-top box currently unscrambling the program,one person can record the stream of control words, by placing a PC between thesmartcard and the set-top box, and post them online.
 Other people can video-record the scrambled program, and unscramble it later [1255].
 Servers sprungup for this key-log attack, but were only a minor nuisance to the industry; notmany viewers were prepared to buy or build a special adapter to connect theirPC to their set-top box.
 Hobbyists with such equipment found other attacksincluding blockers, programs that would prevent ECMs addressed to your cardfrom being delivered to it; this way, you could cancel your subscription withoutthe operator being able to cancel your service [1255].
Cryptanalysis also gave some opportunities.
Every half-second or so thesmartcard supplies the set-top box with a new control word, and this is loadedinto a keystream generator which works as follows.
 There are two linear feedbackshift registers, of lengths 31 and 29 in the Eurocrypt system, which generatelong linear sequences.
 Some of the bits of register 1 are used as address lines toa multiplexer, which selects a bit from register 2; this bit becomes the next bitof the keystream sequence.
 Each successive byte of output becomes a controlbyte for the scrambler (Figure 24.
4).
Linear feedback shift register 1###(address)Multiplexer�! output(select)"""""Security Engineering752Ross Anderson24.
2.
 COPYRIGHTLinear feedback shift register 2Figure 24.
4 – the multiplexer generatorThe designers intended that breaking this cipher should involve guessing thekey, and as this is 60 bits long a guess would take on average 259 trials which isuneconomic – as it has to be done about twice a second.
 But it turns out thatthe cipher has a shortcut attack.
 The trick is to guess the contents of register 1,use this address information to place bits of the observed keystream in register2, and if this causes a clash, reject the current guess for register 1.
 (I discoveredthis attack in 1985 and it’s what got me interested in cryptography.
) The high-order four bits or so of each control word are easy to deduce from inter-linecorrelations – it’s the least signiﬁcant bits you really have to work hard for.
 Soyou can reconstruct the latter using cryptanalysis.
 But this computation is stillof interest to hobbyists rather than the mass market.
Perhaps the most powerful of the ‘amateur’ attacks exploited a master-keyleakage: someone who bought a second-hand PC, looked at the hard disk outof curiosity, and managed to undelete a complete subscriber management sys-tem for one pay-TV operator, including embedded master keys.
 This enabledenthusiasts to write software to emulate a subscriber smartcard completely – infact, it could even be ‘improved’ so it would not turn itself o↵ when ordered todo so by an ECM.
Anyway, the commercial pirates turned to reverse engineering smartcardsusing microprobing techniques, and in section 18.
5 I described the arms racethat followed.
But hardware ﬁxes were limited to new card issues, and theoperators didn’t want to issue a new card more than once a year as it costseveral dollars per subscriber, and the subscriptions were usually less than $20a month.
 So other defensive techniques were tried too.
Litigation was one route, but it took time.
 A lawsuit was lost against a piratein Ireland, which for a while became a haven from which pirates sold cards bymail order all over Europe.
 The industry’s lobbying muscle was deployed tobring in European law to override Dublin, but this took years.
 By the middle of1995, the main UK satellite TV station (Sky-TV) was losing 5% of its revenueto pirate cards, mostly sold by mail order from Dublin.
So all through the mid 1990s, pirates and the operators engaged in a war oftechnical countermeasures and counter-countermeasures.
 The operators wouldship a new card, and within months the pirates would have reversed it andbe o↵ering clones for sale.
 The operators would buy some, analyze them, anddevelop tricks to cause them to fail.
 The problem faced by the operators wasthis: when all the secrets in your system can be compromised within months,how can you still ﬁght back against the pirates without having to reissue all thecards?The operators came up with all sorts of cunning tricks.
 One of their moree↵ective ones was an ECM whose packet contents were executed as code bythe smartcard; in this way, the existing card base could be upgraded on theﬂy and implementation di↵erences between the genuine and pirate cards couldbe exploited.
 Any computation that would give a di↵erent answer on the twoplatforms – even if only as a result of an unintentional timing condition – couldSecurity Engineering753Ross Anderson24.
2.
 COPYRIGHTKMKG12KG11KG21KG22KGn1k1k2• • •�• • •�• • •�• • •�Figure 24.
5: – binary revocation treebe fed into the MAC algorithm to make the pirate cards deliver invalid controlwords.
One of the systems (Eurocrypt) had an e�cient revocation scheme designedin from the start, and it’s worth looking at brieﬂy.
 Each of the subscriber smart-cards contains a subscriber key ki, and there is a binary tree of intermediategroup keys KGij linking the subscriber keys to the currently active master keyKM.
 Each operational card knows all the group keys in the path between itand the master key, as in Figure 24.
5.
In this scheme, if (say) key k2 appears in pirate cards and has to be revoked,then the operator will send out a stream of packets that let all the other sub-scriber cards compute a new master key KM.
 The ﬁrst packet will be {K0M}KG12which will let half the subscribers compute K0M at once; then there will be aK0M encrypted under an updated version of KG11: {K0M}KG011; then this newgroup key KG011 encrypted under GK22; and so on.
 The e↵ect is that evenwith ten million customers the operator has to transmit less than ﬁfty ECMsin order to do a complete key change.
 Of course, this isn’t a complete solution:one also needs to think about how to deal with pirate cards that contain severalsubscriber keys, and how leaked keys can by identiﬁed without having to go tothe trouble of breaking into pirate cards.
 But it’s a useful tool in the box.
Psychological measures were also used.
 For example, one cable TV stationbroadcast a special o↵er for a free T-shirt, and stopped legitimate viewers fromseeing the 0800 number to call; this got them a list of the pirates’ customers.
Economic factors also matter here, as everywhere.
 Pay-TV pirates depend fortheir success on time-to-market as much as conventional software ﬁrms: a piratewho could produce a 99% correct forgery in three weeks would wipe out acompetitor who produced a 99.
9% forgery after three months.
 So pirates raceSecurity Engineering754Ross Anderson24.
2.
 COPYRIGHTto market just like legitimate vendors, and pirate cards have bugs too.
Anunderstanding of economics teaches that it’s best to let a pirate build up asubstantial user base before you pull the plug on him, as this gives him time towipe out his competitors, and also as switching o↵ his cards once he’s establishedwill destroy his credibility with more potential customers than an immediateresponse would.
 But if you leave him too long, he may acquire the ﬁnancial andtechnical resources to become a persistent problem.
The pay-TV industry learned to plan in advance for security recovery, and tohide features in their products that weren’t used initially but could be activatedlater5.
Eventually, the smartcards were made much harder to forge by includingproprietary encryption algorithms in the processor hardware.
 As the attackercouldn’t simply read out the algorithm with a probing station but had to reverseengineer thousands of gates in the chip, they reduced to a handful the numberof laboratories with the technical capability to do attacks.
 Many of these labo-ratories were drawn into the industry’s orbit by consultancy deals or other kindsof sponsorship.
 Those who remained outside the tent were watched.
 Vigorouslegal enforcement provided the last link in the chain.
 The industry hunted downthe main commercial pirates and put them out of business, whether by havingthem jailed or by drowning them in litigation.
In the last big pay-TV piracy case in the 20th century, British pirate ChrisCary was convicted of forging Sky-TV smartcards whose design he had hadreverse engineered by a company in Canada for $105,000.
He sold forgeriesthrough a front company in Ireland, where counterfeit cards were not illegalyet [1368].
 So Sky TV’s security consultants inﬁltrated a spy into his Dublinsales o�ce, and she quietly photocopied enough documents to prove that theoperation was really being run from the UK [956].
 The British authorities didn’twant to prosecute, so Sky brought a private prosecution and had him convicted.
When the authorities put him in an open prison and he absconded, Sky’s privatedetectives relentlessly hunted him down and caught him in New Zealand, wherehe’d ﬂed using a passport in a dead person’s name [847].
 He then ended up ina proper jail.
 Sky-TV’s relentless unpleasantness served as a warning to others.
24.
2.
4.
4DVBDigital video broadcasting (DVB) largely operates using a set of standards thathave evolved over the years since 1996 and that are controlled by the DVBConsortium, an industry group of over 250 members.
 The standards are manyand complex, relating to IPTV and digital terrestrial TV as well as satelliteTV, and to free-to-air services as well as pay-TV.
 DVB has been replacinganalog/hybrid systems, starting with the UK and Germany in 2003.
 The lateststandards, DVB-T2, were promulgated by ETSI in 2009.
The protection mechanisms are complex, and some of them are covered bynondisclosure agreements, but here is a telegraphic summary.
 The conditionalaccess mechanisms for DVB are similar to the hybrid system: the content en-5We discussed in section 16.
3.
1 how banknote printers learned years ago to include a wholeseries of security printing features that could be disclosed one at a time as needed.
Security Engineering755Ross Anderson24.
2.
 COPYRIGHTcryption is digital, but the keys are generated by subscriber smartcards oper-ating on EMMs and ECMs as before.
 The encryption uses the DVB CommonScrambling Algorithm, which was available only under NDA, but leaked in 2002.
In 2011, an attack was found by Erik Tews, Julian W¨alde and Michael Weiner,which was then barely practical as it requires an 8TB rainbow table [1872].
 Thesmartcards are not standardised (except at the interface level) so each broad-caster can use his favorite crypto tricks and suppliers; the piracy to date seemsto have involved smartcard cloning, and there have been various lawsuits wherepay-TV operators have accused each other of hacking.
Pay-TV, whether cable or satellite, peaked in 2008 with 75% of US house-holds.
 What dislodged it was Netﬂix, and more generally the move to onlinesubscription services based on broadband.
24.
2.
5DVDThe history of DVD was both a warning of trouble to come between Holly-wood and the computer industry, and an object lesson on how not to do copyprotection.
The consumer electronics industry introduced the digital video disk (DVD),later renamed the digital versatile disk, in 1996.
 As usual, Hollywood took frightand said that unless DVD had a decent copy protection mechanism, ﬁrst-classmovies wouldn’t be released for it.
 So a mechanism called the content scramblingsystem (CSS) was built in at the last minute; arguments over this held up thelaunch of DVD and it was designed in a rush.
 (The story of how the DVDstandards evolved is told in Jim Taylor’s standard reference [1865], which alsodescribes most of them.
)DVD had region coding: disks were supposed to run only on players fromsome designated list of regions, to support the traditional practice of releasinga movie in the USA ﬁrst, then in Europe and so on, in order to minimise thecost of producing physical ﬁlm prints, and the ﬁnancial loss if the ﬁlm bombs.
But users preferred to buy DVD players in which region coding could be turnedo↵.
 So every DVD vendor wanted to have the second most insecure player onthe market; they didn’t want to be the ﬁrm that Hollywood was beating up on,but they wanted prospective customers to be conﬁdent that their player’s regioncoding could be hacked.
This left CSS, which was known to be vulnerable by the time that DVDwas launched [1494].
 It has a keylength of 40 bits so the equipment wouldn’tfall foul of US export regulations, but the design was so poor that the e↵ectivekeylength was only 16 bits.
 A Norwegian teenager, Jon Lech Johansen, reverseengineered the algorithm and wrote decryption software for it, DeCSS.
 Industrylawyers got injunctions against people who put it online but these were seen ascensorship, so it started appearing on websites outside the USA, on T-shirts,in songs, and in other forms of speech that traditionally enjoy constitutionalprotection6.
 This just got it distributed ever more widely, and made Hollywoodlook foolish [1127].
 Their lawyers blundered on, persuading the government of6There was a full description of CSS and how to break it in the ﬁrst and second editionsof this book; as DVDs are going the way of the dinosaur, I’ve dropped it for this edition.
Security Engineering756Ross Anderson24.
3.
 DRM ON GENERAL-PURPOSE COMPUTERSNorway to prosecute Johansen.
 He was acquitted on appeal in 2003.
Another set of problems came from the fact that the PC is an open plat-form.
 The DVD consortium required people producing DVD player software toobfuscate their code so that it would be hard to reverse engineer.
 Papers dulyappeared on tricks for systematic software obfuscation [141].
 But this closedapproach came into conﬂict with Linux, the open-source PC operating systemthat was already used by millions of people.
 The DVD consortium’s philosophywas not consistent with making DVD drivers available to the Linux community.
So as PCs with CD drives started being replaced in the shops with PCs ﬁttedwith DVD drives, the Linux user community either had to break CSS, or giveup using Linux in favour of Windows.
 Under the circumstances, it was only amatter of time before someone ﬁgured out CSS and DeCSS appeared.
Anyway, DVD followed the usual pattern: Hollywood terriﬁed, and refusingto release their best movies; technical measures taken to prevent copying, whichquickly got broken; then litigation.
 I wrote in 2001: “A reasonable person mighthope that once again the studios will see sense in the end, and make a lot ofmoney from selling DVDs.
 There will be copying, of course, but it’s not entirelytrivial yet – even a DSL modem takes hours to send a 4Gb DVD movie to afriend, and PC disk space is also an issue.
” This came true; although somestudios held out for a year or two, they all climbed on the DVD bandwagon,and by the second edition in 2008, Disney was making most of its money fromDVD sales.
There was then an attempt to market higher-density optical media, with aformat war in 2007 between HD-DVD and Blu-Ray, which both used shorterwavelength lasers to encode information more densely giving up to 50Gb perdisk.
 Both used the Advanced Access Content System (AACS), which I de-scribed in the second edition of this book.
 However, only the Playstation 3 dida full implementation of Blu-Ray, and HD-DVD never got real traction at all.
They were destroyed, as distribution media, by the growth of broadband, andas storage media by the falling cost of USB memory sticks.
24.
3DRM on general-purpose computersVictor Shear patented self-destruct software in the 1980s and his company be-came InterTrust [1793]; their DigiBox system is described by Olin Sibert, DavidBernstein and David Van Wie in [1735].
 This enabled a DRM mechanism toreﬂect real-world ownership, so that I could sell you a photo and you’d be able todecrypt it once you had the receipt; what’s more, you could give it to somebodyelse after which you’d no longer have it.
Intertrust were the most successful of a number of ﬁrms who worked inthe mid-90s on ways to control the sale and distribution of digital goods overthe Internet to customers with personal computers7.
 The original applicationsincluded the distribution of newspapers and articles from scientiﬁc journals [315],7The InterTrust patents were one of only four computer-related patents from the 20thcentury that caused a nine-ﬁgure sum to change hands, the others being the Harvard virtualmemory patents, the RSA public-key patents and the Fraunhofer MP3 patents.
Security Engineering757Ross Anderson24.
3.
 DRM ON GENERAL-PURPOSE COMPUTERSalthough it was always understood that music and video would follow oncenetworks had enough bandwidth.
The basic problem is that a PC, being a general-purpose computer, can inprinciple copy any ﬁle and send it to any other computer; unlike with analogcopying, copies are perfect, so millions of copies might be made from one original.
The problem is compounded by the fact that, from the viewpoint of the contentvendor, the PC owner is the ‘enemy’.
 The music industry believed that unlimitedcopying would destroy their business; the computer industry told them thatDRM was intrinsically impossible on a general-purpose computer, so they’dbetter get a new business model.
 The music and ﬁlm industries, despite beinga tenth of the computer industry’s size, had much more clout in Congress (aMicrosoft guy complained that the average Congressman was much keener to bephotographed with Madonna than with Bill), and they still controlled access tothe music and video that the computer industry wanted their PCs and phonesto be able to play.
 The result was a push for DRM.
24.
3.
1Windows Media Rights ManagementWindows Media Player (WMP) was an early deployment of DRM, replacing anearlier media player when Windows 98 was released.
 It enabled a user to playmusic, watch video and view photos, with features ranging from MP3 playersupport to synchronisation of lyrics for karaoke.
 It introduced Windows MediaRights Management (WMRM), which works as follows.
A store wanting to sell digital media encrypts each item using a content keyand puts the encrypted ﬁles on a streaming media server linked to their web site.
In order to access a media object, the customer must get hold of a license, whichconsists of the object identiﬁer, the license key seed, and a set of instructions ina rights management language which state what they can do with it; how manytimes they may play it, whether they can burn it to a CD, and so on.
 The licenseis generated by a license server and encrypted using a public key generated bythe customer’s WMP application.
 License acquisition may involve registrationor payment, but it may also happen silently in the background [1558].
The architecture is similar to pay-TV conditional access, in that the bulkencryption task of protecting the music or video is separated from the person-alised task of key management, so the video doesn’t have to be encrypted anewfor each customer.
 And just as pay-TV smartcards can be replaced when keysare leaked or the key management mechanism compromised, so the key manage-ment functions of WMRM are performed in an ‘individualized blackbox’ (IBX)component of the software, which gets replaced as needed during the Windowsupdate process.
The IBX internals have been reverse-engineered from time to time [1693].
The customer’s private key is obscured by the blackbox and hidden in a ﬁle;licenses the customer has previously acquired are kept in a license store; con-tent keys are encrypted using the customer’s public key; and the protocol getstweaked from time to time as Microsoft has to recover from hacks.
 I described insection 6.
2.
5 how in the early 2000s Microsoft, Intel and some other big playersformed the Trusted Computing Group to try to build DRM properly into theSecurity Engineering758Ross Anderson24.
3.
 DRM ON GENERAL-PURPOSE COMPUTERSPC architecture.
 The attempt failed for both business and technical reasons,but led to TPM chips for trusted boot, to TrustZone enclaves in Arm processors,and eventually to SGX enclaves in Intel chips.
Microsoft launched Information Rights Management (IRM) with WindowsServer 2003, which aimed to extend DRM to general users; the idea was thataccess controls over a document or other digital object would be retained byits creator.
So DRM wouldn’t just beneﬁt Hollywood; I could send you anemail that you could only read, and never copy, and that would vanish after amonth.
 The vision was that this would be supported by Trusted Computingmechanisms across the entire Windows ecosystem, and conveniently fortify theecosystem against challenges from the likes of Linux or Google docs.
 CorporateAmerica didn’t like the lock-in, though, and Microsoft couldn’t get the operatingsystem mechanisms to work.
 Nowadays, it’s easy to implement such distributeduse controls in cloud-based systems such as O�ce365 or Gmail, but it’s too hardto work across such ecosystems; so we’ve ended up not too far from where wemight have been had Trusted Computing been made to work.
WMRM was then replaced in Windows 10 by PlayReady, a newer Microsoft‘media ﬁle copy prevention technology’.
 WMP is used at its most basic to pro-vide a streaming media service, to support music subscription services, andgeographically-linked services, such as MLB.
com which makes major leaguebaseball games available everywhere except in the team’s home area – for whichthe rights have usually been sold to local TV stations.
24.
3.
2Fairplay, HTML5 and other DRM systemsThe Microsoft o↵ering was fairly typical of rights-management systems.
 Apple’sFairPlay, which was launched in the iPod and in its media player QuickTime,also has tunes encrypted under master keys.
 When a tune is bought the cus-tomer is sent the master key encrypted under a random session key, plus thesession key encrypted under his iTunes player’s RSA public key.
 Session keys arebacked up online on Apple’s servers.
 As with Windows, a number of programshave appeared from time to time that unlocked protected content, and Appleduly upgraded iTunes.
 Apple iTunes was replaced with Apple Music in 2020.
Some ﬁrms’ rights-management systems were downright abusive, and a par-ticularly extreme case arose in 2005 with Sony’s XCP system.
 The ﬁrst timea user inserted a CD with this system into a PC, it presented an end-user li-cense agreement; if the user declined, the CD was ejected, and if they acceptedit loaded and hid a rootkit that intercepted all accesses to the CD drive andprevented Sony music being played by any other media player.
 Microsoft classi-ﬁed it as malware and had it removed by Windows Defender and the MaliciousSoftware Removal Tool [1307].
 It later turned out that Sony had even includedin their rootkit some software that violated the copyrights of others.
There was signiﬁcant controversy in 2012–14 when the World Wide WebConsortium (W3C) was debating whether to adopt HTML5 which provides fora sandbox in browsers to support multimedia content with DRM, and EncryptedMedia Extensions (EME) as a means for the software in the sandbox to com-municate with online license managers.
 When they eventually went ahead inSecurity Engineering759Ross Anderson24.
3.
 DRM ON GENERAL-PURPOSE COMPUTERS2014, W3C chair Tim Berners-Lee was ﬁercely criticised for adopting a stan-dard which excludes open-source browsers in the future.
 Since 2017, browsersneed to license ‘Widevine’ DRM software from Google to support services suchas Netﬂix.
 Mozilla was the last major browser to switch, after they concludedthat refusing would just cause most of their users to switch browsers.
 In 2020,Google stopped supplying this technology to open-source browsers; thereafterall new browsers will have to be proprietary; this had been predicted by EFFduring the debate in 2012–4 [571].
The other development in 2020 is Microsoft’s launch of “double encryption”,a kind of DRM to make regulated industries like banking happier about keepingsensitive data in the O�ce365 / Azure cloud: content keys are kept on thelocal device, but the whole thing is integrated with the Microsoft structure ofaccess controls [432].
 Whether DRM operated by Microsoft would stop an FBIagent armed with a FISA warrant getting access to data on a Microsoft cloudis an interesting question; I suppose we’ll only know the answer when the nextSnowden comes out.
24.
3.
3Software obfuscationAs I already mentioned, early software protection mechanisms used softwareobscurity to hide keys and to check for the presence of machine ﬁngerprints,dongles and license servers.
 Kids with disasssemblers and time on their handstended to defeat such tricks, so where possible ﬁrms would move some criticalfunctionality to the cloud, to trustworthy hardware, or both.
But that is not always possible, and in 2020 the critical applications includeruntime application self-protection (RASP).
 As I discussed in section 12.
7.
4, thisis a set of techniques used by some mobile app developers to protect apps onphones that may have been rooted or jailbroken by malware.
 It’s used by Face-book to protect customers using its Android app in less developed countrieswhere many Android phones are secondhand, out of patch support and rooted,often by local sales agents.
 And following a mandate from the European Cen-tral Bank, RASP is becoming mandatory for banking apps in Europe, or forauthenticator apps on which they rely.
 In both cases the objective is to protectcryptographic keys from an attacker who roots the device.
 This was also thethreat model for 1990s products such as Windows Media Player.
There were early attempts to write obfuscating compilers that would producetamper-resistant software; an early Intel project is described at [141] and led totools used in early software DVD players.
 These were duly broken, as I describedin section 24.
2.
5 earlier, and led Intel to move towards Trusted Computing andeventually SGX, as I described in section 6.
3.
1.
Theoretical computer scientists have written many papers on obfuscationand indistinguishability; a seminal result by Boaz Barak and colleagues in 2001suggests that we can’t write obfuscating compilers with strong and sustainableprotection properties [166].
 But – as with other impossibility results in securitysuch as those on malware detection – the question then arises whether even ifperfect obfuscation isn’t possible in theory, practical obfuscation might be goodenough for some purposes.
Security Engineering760Ross Anderson24.
3.
 DRM ON GENERAL-PURPOSE COMPUTERSMicrosoft moved to a philosophy of security renewal: the key-managementcode for Windows Media Player was hidden in IBX and moved around, so itmight be in the Windows error handler one month and an obscure device driverthe next.
Malware writers took a similar trajectory.
As I described in sec-tion 21.
3.
5, they often obfuscate their code by running it through a packer thatcontains a polymorphic header which in turn decrypts the malware body.
 Keysand headers are all di↵erent, making malware harder to recognise.
 Approacheslike this can sometimes be made to work moderately well, provided the main-tainers are capable and motivated.
 Very often, though, they aren’t; naive ﬁrmsbuying RASP from salesy vendors should expect the worst.
The main security research conferences have tended not to accept papers onobfuscation as they see it as a tactical arms race rather than the accumulation ofscientiﬁc knowledge.
 There is nonetheless a small research community workingon obfuscation, and as of 2020 the state of the art when protecting an engine forauthentication or decryption is to implement a virtual machine that has an oddinstruction set, in which you implement the crypto, and then further obfuscatethe virtual machine itself (custom opcodes had already been used in Sky-TVsmartcards back in the 1990s).
 It is still a real problem though to evaluate sucha scheme, or even guess how much e↵ort it will take to break it [555].
 If a RASPtester can’t extract the crypto key despite trying for a fortnight, that doesn’tgive you any guarantee against someone who tries for a month8.
 Decompilationtools and techniques improve all the time, and many engineers spend much ofour lives trying to ﬁgure out what other people’s code actually does.
Somepeople acquire a real knack for this, but they might not be working in yourcompliance testing lab! A lemons market is therefore to be expected.
All that said, there are some less heavyweight aspects to this.
 Some toolsobfuscate Java bytecode as they shrink and optimise it; one such, ProGuard,is distributed as part of the Android SDK.
 And for entertainment, there’s theInternational Obfuscated C Code Contest, where people have fun trying to hidefunctionality in plain sight.
24.
3.
4Gaming, cheating, and DRMGames were one of the ﬁrst applications of all – pretty well as soon as theworld’s ﬁrst proper computer, the EDSAC, was operational, research studentswere writing games for it.
 Computer games have been big business for decades.
They drove the home-computer boom of the 1970s that in turn spawned thePC industry; games consoles have been a huge market for microprocessors andmemory chips; and gaming – whether on consoles or PCs – has largely driventhe development of computer graphics [2056].
 Game sales in the USA surpassedmovie box-o�ce sales in 2001; and as games moved online, game ﬁrms startedto sell subscriptions, not just one-o↵ tickets [280].
8I bear the scars personally.
 Back in the 1990s, Intel paid us to spend a fortnight tryingto hack a prototype DVD player binary that had been produced by Beelzebub, their internalobfuscating compiler.
 We only got about halfway through, and the company then boasted toits customers that ‘Cambridge couldn’t break this’.
 Jon Lech Johansen later spent a monthstaring at the code and broke it, making us look stupid – but at least Intel ended up lookingstupider.
Security Engineering761Ross Anderson24.
3.
 DRM ON GENERAL-PURPOSE COMPUTERSWhen Nintendo moved console games into the home, they subsidised theconsoles from later sales of software cartridges and other add-ons, so a lot ofe↵ort was put into controlling which accessories could be used, as I discuss laterin section 24.
6; copy-protection of game software for PCs was also a big deal.
However the move to online computer games has mitigated these concerns.
 As acritical part of the game logic runs on a server, the client software can be givenaway, and the residual issue is whether players can get an unfair advantage.
There are very many ways in which gamers can cheat [2057].
 Some gamesban collusion, such as contract bridge, and it’s hard to stop people playing onan online platform from using an entirely separate channel to cheat.
 In the realworld, allegations of cheating are heard by a jury of experienced players, whotake a view on whether the outcome was better than could have been expectedin honest play.
 Even so, some decisions remain controversial for years: playersmay be lucky, and partners who’ve played together for years may communicatesubconsciously without trying to.
 Online play can help as you can have onlinerecords for statistical analysis, online tournaments where many players use thesame deal of cards, and new forms of play where people play with many partnersrather than just one.
Other games require collusion, such as adventure games involving teams ofpeople.
 As I discuss in section 8.
6.
8, these are currently, in 2020, the biggestmarket for DDoS-for-hire services.
 Players, who are often schoolkids, pay a fewdollars for a service that will knock key members of the opposing team o✏ineat a critical time.
The third type of cheating tactics are those that emerge from the natureof computer games.
 In tactical shooters, for example, success should dependon the player’s tactics and shooting skill, not on the game mechanics.
Yetthere are always shortcomings in the game’s physics model, often introduced bynetwork latency and by the optimisations game designers use to deal with it.
 Forexample, you’d normally expect that in a shooting duel, you’d have an advantageif you have the lowest network latency, or if you move ﬁrst.
 Yet the predictionalgorithms used in many game clients cache information about nearby players,so if you leap round a corner, see your enemy and shoot, then the slower yournetwork connection is, the longer it will take him to see you and respond.
 MikeBond coined the term ‘neo-tactic’ to refer to players subliminally exploiting suchanomalies [280].
 That may not of itself be cheating, but in recent years playershave started manipulating network connections deliberately to create artiﬁciallag, whether of incoming packets to delay other players, or our outgoing ones inorder to see what other players are about to do.
That brings us on to one of the classic game cheats, namely to have code ofyour own for automation and support.
 People have written a huge variety oftools, from simple routines that repeatedly click a ﬁre button (to hack the gameswhere the rate at which you can physically ﬁre is a factor) through proxies thatintercept the incoming network packets, identify the bad guys, examine youroutgoing shots, and optimise their aim.
 These aimbots come with di↵erent levelsof sophistication, from code that does all the target acquisition and shooting, tohuman-controlled versions that merely improve your aim.
 They can hook intothe packet stream as proxies, into the graphics card, or even into the client code.
Another variant on the same theme is the wall hack, where a player modiﬁes hisSecurity Engineering762Ross Anderson24.
3.
 DRM ON GENERAL-PURPOSE COMPUTERSsoftware to see through walls – for example, by changing the graphics softwareto make them translucent rather than opaque.
 Such hacks are possible becauseﬁrst-person shooters typically send out raw positional information to all playersin the game, and leave it up to client software to render it according to the localphysics model.
Game companies who sell ﬁrst-person shooters reckon that aimbots and otherclient-side hacks seriously spoil other players’ fun, so they use a variety of en-cryption, authentication and DRM mechanisms to reduce not only cheating,but also the perception of cheating – which is almost as damaging to the op-erator [281].
 Guard software such as Punkbuster has been around since 2000,using anti-virus techniques to detect attempts to hook into game code or thedrivers on which it relies.
 The large gaming platforms such as Steam have theirown DRM mechanisms that attempt to block aimbots and other game cheats,as well as protecting their own revenue by making it harder for customers toresell games [1288].
 This is a constant battle, as I discussed in section above,and some techniques such as artiﬁcial lag are di�cult to deal with completely.
However, gaming is one of the applications in which trustworthy client software,whose protection involves DRM-like mechanisms, has become well entrenched,even though most modern games are locked to customer accounts and most oftheir logic now runs on a server.
 The server is also often fortiﬁed with analyticsto detect cheating after the event, just like in a professional bridge tournament.
24.
3.
5Peer-to-peer systemsFrom the late 1990s, peer-to-peer ﬁle-sharing became one of the main waysin which music was distributed online.
 Once people had CD drives on theircomputers and broadband connections, they could copy and share their favouritetracks.
 In 1999, Shawn Fanning, an 18-year-old drop-out, revolutionised themusic business by creating the Napster service, which enabled people to shareMP3 audio ﬁles with each other [1381].
 Rather than keeping the ﬁles centrally,which would invite legal action, Napster just provided an index so that someonewanting a given track could ﬁnd out who else had it and was prepared to shareor trade.
 It attracted tens of millions of users, but lawsuits from Hollywoodclosed it down in September 2002.
 Systems such as Gnutella and Freenet thenborrowed ideas from the world of censorship-resistant systems to set up networkswithout a central node that could be closed down by legal attacks [439].
 Thesewere followed by other systems such as Kazaa and Bittorrent.
I was the designer of an early censorship-resistant system, the Eternity Ser-vice.
 The motivation came when an early anonymous remailer, anon.
penet.
fi,was used to post a message that upset the Scientologists and was closed downafter they got a court order forcing its operator to disclose the linkage betweenusers’ real email addresses and the pseudonyms they used on his system [881].
The messages that were the subject of the case contained an a�davit by a formerminister of their church to the e↵ect that once members had been fully initiatedthey were told that the rest of the human race was su↵ering from false con-sciousness; that, in reality, Jesus was the bad guy and Lucifer was the good guy.
Well, history has many examples of religions that denounced their competitorsas both deluded and wicked; the Scientologists’ innovation was to claim thatSecurity Engineering763Ross Anderson24.
3.
 DRM ON GENERAL-PURPOSE COMPUTERStheir scriptures were their copyright, so the whistleblower’s leak was a breachof copyright.
 They got away with this argument in a number of jurisdictionsuntil eventually a court in the Netherlands put a stop to it by allowing an NGOthere to publish the ‘Fishman a�davit’, as it was called.
The Eternity Service was designed to provide long-term ﬁle storage by dis-tributing ﬁle fragments across the net, encrypted so that the people hosting themwould not be able to tell which fragments they had, and so that reconstructioncould only be performed via remailer mechanisms [61].
 A later version of thiswas Publius9, which also provided a censorship-resistant anonymous publishingmechanism [1974].
The United States Copyright O�ce deﬁnes peer-to-peer networks as net-works where computers are linked to one another directly rather than througha central server.
 The absence of a server that can be closed down by court ordercreates an interesting problem for music industry enforcers.
 The two tactics onwhich the music industry relied were suing uploaders and technical attacks onthe systems.
One way to attack peer-to-peer systems is to ‘walk the network’ by intro-ducing a modiﬁed peer, contacting as many other peers as possible, and thenidentifying them.
During the mid-2000s, the music industry tried harassingusers at scale, ﬁling tens of thousands of lawsuits.
 In many cases people agreedto cease and desist and pay a small penalty rather than ﬁght a case; but in Octo-ber 2007 a federal jury in Duluth, MN.
, convicted 30-year-old Jammie Thomasof copyright infringement for sharing material on Kazaa and ordered her to pay$9,250 for each of the 24 songs involved in the case.
 Firms working for themusic industry were also uploading damaged music ﬁles to spam out systems(which will usually be legal), and it was suspected that they were also conduct-ing denial-of-service attacks (which in many jurisdictions isn’t).
 In September2007, a company called Media Defender that worked for the music industry on‘ﬁle-sharing mitigation’ had several thousand of its internal emails leaked, afteran employee forwarded his email to Gmail and his password was compromised.
It turned out that Media Defender’s business model was to charge $4,000 per al-bum per month, and $2,000 per track per month, for ‘protection’ that involvedattacks on twelve million users of ﬁfteen P2P networks [1501].
Peer-to-peersystems have also allegedly been attacked by Comcast, which is said to havedisrupted its customers’ connections by sending forged reset packets to teardown Bittorrent connections.
 Comcast might prefer its customers to watch TVover its cable network, so they see its ads, but the allegations raise public policyissues if true: Comcast is not a law-enforcement agency [219].
The state of play in 2020 is that some jurisdictions su↵er from this kind ofextortion, from law ﬁrms sometimes referred to as Torrent trolls: in Sweden,for example, there have been tens of thousands of cases where lawyers demandlarge payments from families claiming that their kids uploaded some copyrightedmaterial [1655].
 This appears to be a function of local procedural law more thananything else; in many countries, lawyers can’t be as crooked, or at least not in9For non-US readers: the revolutionaries Alexander Hamilton, John Jay, and James Madi-son used the pen name Publius when they wrote the Federalist Papers, a collection of 85articles published in New York State newspapers in 1787–8 and which helped convince NewYork voters to ratify the United States constitution.
Security Engineering764Ross Anderson24.
3.
 DRM ON GENERAL-PURPOSE COMPUTERSthis particular way.
In the larger global ecosystem, the big service ﬁrms are now dominant andthe deciding factor in copyright infringement is the notice-and-takedown regimeset up under the US DMCA, and followed by similar laws elsewhere.
I willdiscuss this further in section 24.
5.
24.
3.
6Managing hardware design rightsAnother rights-management ecosystem is the protection of designs licensed foruse in hardware.
 Companies like Arm earn their living by licensing designs forprocessors and other components that to ﬁrms who make custom chips, whetherby designing application-speciﬁc integrated circuits (ASICs) or by using Field-Programmable Gate Arrays (FPGAs).
The ﬁrst use case for hardware protection is when such devices are used tomake it harder to counterfeit products, for example by overrun production.
 Acamera company licenses a circuit that they integrate into a bitstream that’sloaded into an FPGA, that then becomes a key component in a new camerathat they have made in a factory in China.
 They pay for 100,000 licenses, yet200,000 cameras arrive on the market.
 There are two failure modes: the cameracompany could have ordered the extra production and lied to the IP owner, orthe Chinese factory could be cheating the camera company.
 In fact, they couldboth be cheating, each having decided to make an extra 50,000 units.
Nowthere are technical mechanisms that the camera company could use to stop thefactory cheating it, such as personalising each camera with a serial number andso on after manufacture – but these could make it harder to cheat the IP owner.
So the second problem is how the IP owner can tell whether a product con-tains a particular circuit.
 The camera company might have licensed a processoror a ﬁlter for one model, then built it into another cheaper model too withoutdeclaring it.
These risks cause some large IP vendors to prefer to license their best designsonly to other large ﬁrms, so small startups can be disadvantaged.
 They alsodepress sales of FPGAs, whose manufacturers o↵er mechanisms to tackle theﬁrst problem by distributing encrypted bitstreams and updates for whole chips;the second problem is harder, because chip design tools come within the trustboundary.
 Customers need to be able to evaluate designs, and debug designs,which is in tension with controlling dissemination.
 There has been some useof side-channels for forensics.
 Owners of semiconductor IP can buy samples ofsuspect goods, then measure the chips’ precise analog behaviour such as powerconsumption and timing, which can often reveal the presence of a given func-tional component.
 Components can even be deliberately designed to generatea suitable signal in their power trace.
 (Similar techniques are used by militarycontractors to look for hardware Trojans.
)This brings us to the question of copyright marking.
Security Engineering765Ross Anderson24.
4.
 INFORMATION HIDING24.
4Information HidingHollywood’s interest in ﬁnding new mechanisms for protecting copyright cametogether in the mid-1990s with the military’s interest in unobtrusive commu-nications and public concerns over government e↵orts to control cryptography,and started to drive rapid developments in the ﬁeld of information hiding.
 Thislargely refers to techniques for hiding data in other data, such as when a se-cret message is hidden in an MP3 audio ﬁle, or a program’s serial number isembedded in the order in which certain instructions are executed.
Hollywood sought salvation in copyright marks embedded unobtrusively indigital audio, video and artwork.
 These include watermarks, copyright messageswhich may or may not be hidden but are hard to remove, and ﬁngerprints whichare hidden serial numbers.
 For example, when you downloaded an mp3 fromApple’s iTunes music store, it contained a ﬁngerprint embedded in the audiothat identiﬁed you.
 The idea was that if you then uploaded your copy to a ﬁle-sharing system, the copyright owner could sue you.
 (Some people believed thatﬁngerprinting depressed sales overall because of the legal hazards it created forhonest purchasers.
 Amazon, for example, did not mark MP3 downloads [852].
)The privacy interest is in steganography whose purpose is to embed a messagein some cover medium in such a way that its very existence remains undetectable.
The conceptual model, proposed by Gus Simmons [1745], is as follows.
 Aliceand Bob are in jail and wish to hatch an escape plan; all their communicationspass through the warden, Willie; and if Willie detects any encrypted messages,he will frustrate their plan by throwing them into solitary conﬁnement.
 So theymust ﬁnd some way of hiding their secret messages in an innocuous covertext.
As in the related ﬁeld of cryptography, we assume that the mechanism in useis known to the warden, and so the security must depend solely on a secret keythat Alice and Bob have somehow managed to share [1753].
There is some similarity with electronic warfare.
 First, if steganography isseen as a low-probability-of-intercept communication, then copyright markingis like jam-resistant communication: it may use much the same methods but inorder to resist focused attacks it is likely to have a much lower bit rate.
 We canthink of Willie as the pirate who tries to mangle the audio or video signal in sucha way as to cause the copyright mark detector to fail.
 Second, techniques suchas direct-sequence spread spectrum that were originally developed for electronicwarfare found use in the information hiding community.
Copyright marks don’t have to be hidden to be e↵ective.
 Some TV stationsembed their logo in a visible but unobtrusive manner in the corner of the picture,and as I noted, academic journal downloads do something similar.
 However, inwhat follows I’ll concentrate on hidden copyright marks.
24.
4.
1Watermarks and copy generation managementThe DVD consortium became concerned that digital video or audio could bedecoded to analog format and then redistributed (the so-called ‘analog hole’).
They set out to invent a copy generation management system that would workeven with analog signals.
 The idea was that a video or music track might beSecurity Engineering766Ross Anderson24.
4.
 INFORMATION HIDINGunmarked, or marked ‘never copy’, or marked ‘copy once only’; compliant playerswould not record a video marked ‘never copy’ and when recording one marked‘copy once only’ would change its mark to ‘never copy’.
Commercially soldvideos would be marked ‘never copy’, while TV broadcasts and similar materialwould be marked ‘copy once only’.
In this way, the DVD players availableto consumers would allow unlimited copying of home videos and time-shiftedviewing of TV programmes, but could not easily be abused for commercialpiracy.
 The mechanisms depended on hiding copyright marks in the content,and are reviewed in [1167].
 For each disk, choose a ticket X, which can be arandom number, plus copy control information, plus possibly some informationunique to the physical medium such as the wobble in the lead-in track.
 Use aone-way hash function h to compute h(X) and then h(h(X)).
 Embed h(h(X))in the video as a hidden copyright mark.
 Have compliant machines look for awatermark, and if they ﬁnd one refuse to play a track unless they are suppliedwith h(X) which they check by hashing it and comparing it with the mark.
Compliant devices will only record a marked track if given X, in which caseonly h(X) is written to the new disc.
 In this way, a ‘copy once only’ trackin the original medium becomes a ‘copy no more’ track in the new medium.
This ended up in Blu-ray, but that failed in the marketplace, as well as being acomplete pain for developers to work with.
Robustness depends on many things including our old friend, the receiveroperating characteristic or ROC, which sets the trade-o↵ between false alarmsand missed alarms.
 It’s not enough for a marking mechanism to have a lowmissed alarm rate; it needs a low false alarm rate too [1318].
 If your player wereto detect a ‘no-copy’ mark by mistake in the video you made of your child’sbirthday party, then you’d have to buy a pirate player to watch it.
 So what sortof marks are possible, and how robust are they against forgery, spooﬁng andother attacks?24.
4.
2General information hiding techniquesInformation hiding goes back even further than cryptology, having its roots incamouﬂage.
 Herodotus records tricks used during the wars between the Greeksand the Persians, including hiding a message in the belly of a hare carried bya hunter, tattooing it on the shaven head of a slave whose hair was then al-lowed to grow back, and writing it on the wooden base under the wax of awriting tablet [889].
 Francis Bacon proposed a system which embedded a bi-nary message in a book at one bit per letter by alternating between two di↵erentfonts [1513].
 Until quite modern times, most writers considered hiding conﬁ-dential information much more important than enciphering it [2021].
 Militaryand intelligence organizations are keenly aware that tra�c security is often moreimportant than content conﬁdentiality, and have used all sorts of technologiesfrom the microdots used by spies to low-probability-of-intercept radios.
When it comes to hiding data in other data, the modern terminology of thesubject is as follows [1521].
 The copyright mark, or in the case of steganography,the embedded text, is hidden in the cover-text producing the marked text orin the case of steganography the stego-text.
 In most cases, additional secretinformation is used during this process; this is the marking key or stego-key,Security Engineering767Ross Anderson24.
4.
 INFORMATION HIDINGand some function of it is typically needed to recover the mark or embeddedtext.
 Here, the word ‘text’ can be replaced by ‘audio’, ‘video’ and so on, asappropriate.
A wide variety of embedding schemes has been proposed.
• Many people have proposed hiding mark or secret message in the leastsigniﬁcant bits of an audio or video signal.
 This isn’t usually a very goodstrategy, as the hidden data is easy to detect statistically (the least sig-niﬁcant bits are no longer correlated with the rest of the image), and it’strivial to remove or replace.
 It’s also severely damaged by lossy compres-sion techniques.
• A better technique is to hide the mark at one or more locations determinedby a secret key.
 This was ﬁrst invented in classical China.
 The sender andreceiver had copies of a paper mask with holes cut out of it at randomlocations.
 The sender would place his mask over a blank sheet of paper,write his message in the holes, then remove it and compose a cover messageincluding the characters of the secret embedded message.
 This trick wasreinvented in the 16th century by the Italian mathematician Cardan andis now known to cryptographers as the Cardan grille [1001].
• A modern version of this hides a mark in a .
gif format image as follows.
A secret key is expanded to a keystream which selects an appropriatenumber of pixels.
 The embedded message is the parity of the color codesfor these pixels.
 In practice even a quite large number of the pixels in animage can have their color changed to that of a similar one in the palettewithout any visible e↵ects [972].
 However, if all the pixels are tweaked inthis way, then again the hidden data is easy to remove by just tweakingthem again.
 A better result is obtained if the cover image and embeddingmethod are such that 1% of the pixels can safely be tweaked.
 Then, if thewarden repeats the process but with a di↵erent key, a di↵erent 1% of thepixels will be tweaked and only 1% of the bits of the hidden data will becorrupted.
 These can then be recovered using an error-correcting code.
• In general, the introduction of noise or distortion – as happens with lossycompression – will introduce errors into the hidden data almost regard-less of the embedding method unless some kind of error correcting codeis added.
 A system proposed for banknote marking, Patchwork, uses arepetition code – the key selects two subsets of pixels, one of which ismarked by increasing the luminosity and the other by decreasing it.
 Thisembeds a single bit; the note is either watermarked using that key, or itisn’t [225, 830].
 This is reminiscent of di↵erential power analysis: the keytells you how to sort your input data into two piles, and if the key wasright they’re noticeably di↵erent.
• In the general case, one may want to embed more than one bit, and havethe embedded data survive very high levels of induced errors.
 So a commontechnique is to use direct-sequence spread-spectrum techniques borrowedfrom electronic warfare [1890].
 You have a number of secret sequences,each coding a particular symbol, and you add one of them to the contentto mark it.
Security Engineering768Ross Anderson24.
4.
 INFORMATION HIDING• Spread spectrum encoding is often done in a transform space to make itse↵ects less perceptible and more robust against common forms of com-pression.
 These techniques are also commonly used in conjunction withperceptual ﬁltering, which emphasises the encoding in the noisiest or per-ceptually most signiﬁcant parts of the image or music track, where it willbe least obtrusive, and de-emphasises it in quiet passages of music or largeexpanses of color [288].
• Some schemes use the characteristics of particular media, such as a schemefor marking print media by moving text lines up or down by a three-hundredth of an inch [315], or adding extra echoes to music below thethreshold of perception [225].
 So far, such techniques don’t seem to havebecome as robust, or as widely used, as generic techniques based on keyedembedding using transform spaces, spread spectrum and perceptual ﬁlter-ing.
Progress in copyright marking was very rapid in the late 1990s: people in-vented marking schemes which other people broke, until some systems wereadopted in banknotes and in some tools such as Adobe’s.
 From the mid-2000s,interest in copyright marking waned with the move to broadband, but researchin steganography and steganalysis continued, merging with research in imageforensics.
24.
4.
3Attacks on copyright marking schemesThroughout this book, we’ve seen attacks on cryptographic systems that occa-sionally involved cryptanalysis but more often relied on mistaken assumptions,protecting the wrong things, protocol failures and implementation bugs.
 Andin the history of technology as a whole, inventions tend to end up being used tosolve problems somewhat di↵erent from the problems the inventor was originallythinking about.
 Copyright marking has been no di↵erent on either count.
• In the beginning, many people tackled the problem of embedding hiddencopyright messages so that ownership of a work could be proved in court.
But this is a non-problem.
 Lawyers almost never have any di�culty inproving ownership of an exhibit; they don’t rely on technical measureswhich might confuse a jury, but on documents such as contracts withbands and model release forms.
• As usual, many designers ignored Kerckho↵s’ principle – that the securityof a system should reside in the choice of key, not in the algorithm in use.
But when marks are used to prove whether a particular digital object waslicensed, this means disclosing them in court together with the markingkeys, so it may be necessary to use multiple keys.
• As an example, color copiers sold in the US hide a Machine IdentiﬁcationCode (MIC) in the bit patterns of copies as an extra means of detectingcurrency forgers [2002].
 Introduced by Xerox and Canon in the 1980s,apparently following a secret agreement with one or more governments,its existence was disclosed in a court case in the Netherlands in 2004.
 TheSecurity Engineering769Ross Anderson24.
4.
 INFORMATION HIDINGmechanism was then reverse engineered in a crowdsourced e↵ort led byEFF.
 The MIC is a pattern of yellow dots 0.
1mm in diameter that is barelyvisible to the human eye and repeated about 150 times on an A4 colourcopy.
 There is now software to identify and remove it, so whistleblowerscan sanitise sensitive documents before leaking them to the press [1602].
• Many marks simply add some noise to the signal.
 But if all the frames ina video carry the same mark, you can average them to get the mark andthen subtract it out.
 Or you supply some known content to a markingsystem, and compare its input and output.
 Even if the mark is applied ina tamper-resistant process immediately after decryption, and every deviceadds a di↵erent mark, then if the mark consists of small signals addedat discrete points in the content, an opponent can just decrypt the sameciphertext with several di↵erent devices and compare them to remove themarks.
• There have been attempts to develop a marking equivalent of public-keycryptography, so that (for example) anyone could insert a mark whichonly one principal could detect, or anyone could detect a mark that onlyone principal could have inserted.
 The former seems just about feasibleif the mark can be inserted as the cover audio or video is being manufac-tured [494].
 The latter seems a lot harder.
 First, you can’t authenticateall of an image by embedding a signature in it, as then you’d be modifyingit in order to prove that it has not been modiﬁed.
 Second, if you try toauthenticate just the high-order bits or the salient features, then thereare robustness issues: given a device that will detect a mark, an attackercan remove it by applying small changes to the image until the decodercannot ﬁnd it anymore [1511, 1168], then apply their own signature.
 Sothe main e↵ort was invested in mechanisms that put a di↵erent mark ineach instance of the content, as it is decrypted.
• Steganalysis techniques were developed to break most embedding schemes.
For over a decade, people would propose new information hiding mecha-nisms at the Information Hiding Workshop, and the following year they’dbe broken.
 The most proliﬁc attack team was Jessica Fridrich and herstudents at Binghamton; her book on steganography is the starting pointfor serious work on the subject [724].
• The most successful marking startup – Digimarc – set up a service to trackintellectual property on the web.
 They supplied tools to let picture ownersembed invisible ﬁngerprints, and had a bot which crawled the web lookingfor marked pictures and reported them to the copyright owner.
 There werevarious ways to defeat this.
 For example, a marked image could often bechopped up into smaller images which together look just like the originalwhen rendered on a web page but in which a copyright mark won’t bedetected (Figure 24.
6) [1516].
 Digimarc worked for a while on monitoringbroadcast streams; but over time, AI improved to the point that softwarecan identify which song is being played directly.
Digimarc moved intosecurity printing, licensing their marking technology to central banks as acounterfeit detection measure.
 For example, it’s found in Euro banknotes,Security Engineering770Ross Anderson24.
4.
 INFORMATION HIDINGFigure24.
6:–theMosaicattack(courtesyJetPhotographic,www.
jetphotographic.
com)which it prevents from being scanned or copied using the latest equip-ment [2061].
Software packages such as Photoshop and Paintshop Pronow refuse to handle marked images.
 Digimarc now monitors packagingand provides labeling systems.
• The most general attacks on imperceptible copyright marking schemesinvolve suitably chosen distortions.
 Audio marks can be removed by ran-domly duplicating or deleting sound samples to introduce inaudible jitter;techniques used for click removal and resampling are also powerful mark re-movers.
 For images, a tool my students developed, called Stirmark, intro-duces the same kind of errors into an image as printing it on a high qualityprinter and then scanning it again with a high quality scanner.
 It appliesa minor geometric distortion: the image is slightly stretched, sheared,shifted, and/or rotated by an unnoticeable random amount This defeatedalmost all the marking schemes in existence when it was developed and isnow a standard benchmark for copyright mark robustness [1516].
For a fuller account of attacks on copyright marking schemes, see [724].
It’s still di�cult to design marking schemes that remain robust once the markdetection algorithm is known.
Perhaps the key technical factor that killed copyright marking wasn’t an at-tack but latency.
 This is really important for streamed sports events; you don’twant to hear cheering from next door before you see the goal.
 Recently mediastreaming standards (DASH, HLS) have been updated to support downloadingmedia chunks before they have been written completely to ‘ﬁx’ this.
 Apparentlyserver-side watermarking to identify who re-streamed a stream can introduce alot of latency.
 This helped drive the adoption of direct recognition of infringingmaterial instead.
 One pioneer, Shazam, was bought by Apple in 2017; GoogleSecurity Engineering771Ross Anderson24.
5.
 POLICYdeveloped its own Content ID for YouTube with a database of content ﬁnger-prints with information about where copyright has been claimed, and whenvideos are uploaded or live streamed they are looked up in this database.
 Copy-right owners can opt to monetize the video by getting a share of ad revenue,or block it.
 Similar technology is used to block content that’s objectionable forother reasons: child sex abuse material is mostly recognised using a Microsoftsystem called PhotoDNA.
24.
5PolicyThere was a vigorous policy debate in the 1990s and 2000s between the techindustry and many of the owners of ‘intellectual property’ (IP) – copyright,patents and trademarks – as the opening up of the Internet made copying easyand threatened traditional music, book and ﬁlm publishers10.
 The reaction in-cluded a series of laws from copyright term extension through America’s DigitalMillennium Copyright Act (DMCA) to an IP Enforcement Directive in Europe,which shifted power in ways that many people in tech and elsewhere felt to bethreatening.
 The get-out for tech was section 230 of the US CommunicationsDecency Act of 1996 (CDA) which states that ‘No provider or user of an in-teractive computer service shall be treated as the publisher or speaker of anyinformation provided by another information content provider’ so platforms can-not be held liable for copyright infringement by users.
 This favoured the growthof information service ﬁrms in the USA rather than Europe.
The US DMCA does give copyright owners the power (‘Notice and TakeDown’) to compel ISPs to take down websites with infringing material.
Al-though there is also a provision (‘Notice and Put Back’) for the subscriber toﬁle a counter notice and have his stu↵ put back within 14 days unless the copy-right owner ﬁles suit, in practice many ISPs will just terminate a customer’sservice rather than get involved in litigation.
 This led not just to a lot of mu-sic copying using peer-to-peer systems, but to ﬂoods of takedown requests frommusic industry lawyers, as well as to the push for DRM that we discussed earlier.
Over half of the takedown requests to Google come from the top 16 copyrightowners, with the top three generating over a billion a year – many of them tolinks that are not even on Google.
 Many complaining organisations get few ornone of the links they complain about removed, as they are either not relevant orjudged to be non-infringing; see Google’s transparency reports for details [800].
This has real policy consequences: censoring a Chinese shop that pretends tobe Nike is one thing, while censoring Black Lives Matter Peckham in responseto a complaint from a white supremacist is quite another.
There are many side-e↵ects: for example, the legal rules that allowed copy-ing for personal use (‘fair use’ in the USA and ‘fair dealing’ in the UK) are beingreplaced by technical controls that don’t.
 For example, when I applied for plan-ning permission to extend my kitchen, I had to ﬁle four copies of a local plan;10The term ‘intellectual property’ is controversial.
 Many activists object to it as a pro-paganda term coined by corporate lobbyists who want people to start seeing patents andcopyrights as permanent natural rights, like title to real estate or human rights, rather thanas the temporary monopolies that they are.
Security Engineering772Ross Anderson24.
5.
 POLICYbut the map software at our university library only lets you print three copies.
This is an entirely deliberate act by the Ordnance Survey to maximise its rev-enue.
 Legal controls are supplemented by access controls, and the legal privilegegiven to those access controls by the DMCA and comparable EU laws creates anew bundle of rights, described by legal scholars as ‘paracopyright’ [532].
In e↵ect, copyright regulations are no longer made by lawmakers in Washing-ton or Brussels, but by programmers working for Microsoft or Apple or Amazon.
The result has been to erode the rights of copyright users.
 In one spectacular ex-ample, Amazon quietly removed from its customers’ Kindles an edition of GeorgeOrwell’s ‘1984’ and ‘Animal Farm’ over which some dispute had arisen [1831].
This was a sobering reminder of the huge gap between owning a physical copyof a book, and ‘owning’ an e-book – in fact you just bought a license from avendor who wrote the license so as to give you next to no rights at all.
At the same time, copyright law suddenly became relevant to millions ofpeople.
 Whereas in the past it was only a concern of specialists such as pub-lishers, it now touches the lives of everyone who downloads music, time-shiftsmovies, or maintains a personal web page.
 As the law has failed to keep upwith technology, the gap between what it permits and what people actually dohas become wider.
 In the UK, for example, it’s technically illegal to rip a CDto listen to on your phone; yet as this is one of the main reasons that peoplestill buy CDs, the British Phonographic Industry (the trade body) graciouslysays it won’t sue anybody.
 But many of the minor infringements that used totake place in private, or unsurveilled public spaces (such as singing a song in apub), now go online (as when a phone video clip of the song gets on someone’ssocial-network page).
 John Tehranian calculates that a typical law professorcommits over 80 copyright infringements a day, carrying statutory penalties ofover $10m [1866].
 In e↵ect, we only tolerated copyright law because it wasn’tenforced against private individuals.
 Technology makes enforcement possible,the consolidation of copyrights into an ever smaller number of corporate own-ers and collecting societies makes for a concentrated lobby, greed makes abuseshappen, and the frictions increase.
The consolidation of copyrights also leads to injustice in the distribution ofincome.
 I already mentioned the problems with collecting societies, which ine↵ect tax venues and distribute the proceeds in such a way that the rich getlots and the small fry not so much at all; this has become worse with streaming,whose payouts are a function of plays rather than users.
 So if my granddaughterpays £10 a month and listens to Ariana Grande four hours a day while I pay thesame and listen to Kathryn Tickell two hours a week, then rather than givingthem £10 each (less Apple’s 30% commission), Ariana will get fourteen timeswhat Kathryn gets [1553].
 This means that most of your subscription – or atleast of the money the tech ﬁrms don’t take one way or another – goes to themegastars like Ariana, and Ed Sheeran and Lady Gaga.
There are also privacy concerns.
 In the old days, people would buy a book ora record for cash; the move to downloads means that servers run by ﬁrms suchas Google, Spotify and Apple have a record of what people watch and listento, and this can be subpoena’ed.
 (The move to online bookselling and then toKindles has created similar records at Amazon.
) These records are also usedfor marketing.
 A survey for the Privacy Commissioner of Canada found manySecurity Engineering773Ross Anderson24.
5.
 POLICYexamples of intrusive behavior, including e-book software proﬁling individuals,DoubleClick advertising in a library service, systems tracking individuals via IPaddresses, and contradictions between vendors’ stated privacy policies and ob-served behaviour – including undisclosed communications to third parties [682].
Why do copyright owners, or big tech ﬁrms claiming to act on their behalf, getaway with so much? The answer lies in the dynamics of lobbying.
24.
5.
1The IP lobbyThe IP lobby has its modern origins in an e↵ort by the drug company Pﬁzer toextend patent protection on its drugs from the USA to less developed countrieslike Brazil and India in the 1970s.
 The history is told by Peter Drahos andJohn Braithwaite [581]; in summary, Pﬁzer and the other drug companies alliedthemselves with the music and ﬁlm industry (who wanted to cut bootleggingand copying), the luxury-goods industry (who wanted to reduce the number ofcheap knock-o↵s), and a number of other US players (including the BusinessSoftware Alliance), and persuaded the US government to start applying pres-sure on other countries to bring their patent, copyright and trade-mark lawsin line with America’s.
 From the mid-1980s this was largely a matter of bul-lying less developed countries who wanted trade deals, but in 1995 a treaty onTrade-Related Aspects of Intellectual Property Rights (TRIPS) took e↵ect formembers of the World Trade Organisation (WTO), followed by two treaties ofthe World Intellectual Property Organisation (WIPO) in 1996.
 Essentially theUSA and the EU got together and bullied holdouts like India and Brazil.
The implementation of these treaties stirred up opposition in developed coun-tries as people began to realise how they might be a↵ected.
 In the USA, theDigital Millennium Copyright Act of 1998 made it an o↵ence to circumvent acopyright-protection mechanism, as required by WIPO, while in the EuropeanUnion the Copyright Directive of 2001 had a similar e↵ect.
 This was seen asenabling vendors to create closed platforms and control competition; it was alsoseen as a threat by the free and open source software movement, and by secu-rity researchers – especially after the Russian researcher Dmitri Sklyarov wasarrested at a US conference at the request of Adobe, after his employer had soldtools circumventing password protection on PDF documents.
There were many other high-proﬁle incidents; for example, I was on theprogram committee of the 2001 Information Hiding Workshop when an attemptwas made by the Recording Industry Association of America (RIAA) to forcethe program chair to pull a paper by Ed Felten and his students describingvulnerabilities in a copyright marking scheme being touted for a digital musicstandard [495].
 Ed then sued RIAA, in a landmark academic-freedom case [620].
The irony is that the promoters of this scheme had issued a public challengeto academics and others to break it.
 The next case was Bunnie Huang’s book“Hacking the Xbox”: this described how, as an MIT student, he’d overcome theprotection mechanisms in the ﬁrst version of Microsoft’s games console [930].
The book he wrote caused his publisher to take fright, but he found another one.
The encroachment on liberties threatened by rights-management mechanismsand anti-hacking laws led to the growth of digital-rights NGOs in a number ofcountries (others had them already as a result of the ‘Crypto Wars’; I’ll discussSecurity Engineering774Ross Anderson24.
5.
 POLICYall this in more detail in section 26.
2.
7).
One turning point came in 2003–4, as the IP lobby was trying to steer afurther measure through Brussels, the IP Enforcement Directive.
 In its originalform, this would have further ratcheted up the penalties on infringers and re-moved the prospects for public-interest defences based on free speech or fair use.
This time opponents of the measure managed to assemble a su�ciently strongcoalition of opposing interests that the measure was substantially amended.
This opposition led to the establishment the following year of EDRi, an NGOthat promotes European digital rights, and is supported by several dozen NGOsin Europe who realised that a lobbying presence in Brussels was essential.
The IP lobby’s mistake was trying to compel every country in Europe tomake patent infringement a crime, rather than just a civil matter.
 This wasintended by Big Pharma to undermine ﬁrms who make low-cost generic ver-sions of drugs once they have come o↵ patent.
 At present, drug patent holderstry to prolong their patents by ‘evergreening’ – ﬁling subsidiary, later patents,with often dubious derivative claims – which the generic drugmakers deal withby o↵ering their distributors indemnities against having to pay damages.
 Mak-ing infringement a criminal matter would have upset these arrangements.
 Thiscaused the generic drugmakers to oppose the directive vigorously, along with su-permarkets, car parts dealers and consumer groups.
 Even the software industrystarted to get nervous: we pointed out to Microsoft that thousands of companiesbelieve that Microsoft is infringing their patents, but don’t have the money to gothe distance in a civil court.
 If patent infringement became a crime, surely theywould take their grievances to the police? Would Bill risk arrest on some futuretrip to Europe? The attempt to criminalise patent infringement collapsed whentech ﬁrms withdrew their support.
 A rich, powerful lobby isn’t stopped by ﬁnewords, or by outrage from university professors and free-software activists.
 It’sstopped when it comes up against another rich, powerful lobby pushing in theopposite direction.
Some copyright activists hope that once copyright expires – or assuming thatlots of material can be made available under a Creative Commons license – theneverything will be hunky-dory.
 I doubt it.
 The theory behind both copyrightand patent was to o↵er creators a temporary monopoly in order to increasethe supply of creations.
 Initially copyright was for 18 years, then 35, then 50,then the creator’s lifetime plus 70 years after that.
 Cynics noted that wheneverMickey Mouse was in danger of going out of copyright, the US government wouldstep in to increase the copyright term, and bully other governments to fall inline.
 (Other cynics noted that the copyright term for musical performance wasextended from 50 years to 70 after Sir Cli↵ Richard let the then Prime MinisterTony Blair holiday at his mansion in Barbados.
) Some lawyers would like toextend copyright term indeﬁnitely, but that violates the social contract on whichcopyright is based and it also doesn’t solve the problem of preservation: manypublishers have failed to look after their own back catalogue properly and hadto retrieve copies from national deposit collections.
Curating old bits costs money, just as curating old manuscripts does; indeedthe ﬁlm industry has recently discovered that archiving digital productions ac-tually costs more than they used to pay in the old days, when they just lockedaway the master copies in an old salt mine.
 There’s just an awful lot of bitsSecurity Engineering775Ross Anderson24.
5.
 POLICYgenerated during digital production, and copying them to new disks every fewyears isn’t cheap.
 In the long term, once bitstrings belong to nobody, who willpay for their upkeep? Might we extend the existing taxpayer-funded deposit li-brary system to digital materials? But such organisations typically fail to makemuch progress with digital materials for a number of reasons, from lack of un-derstanding to being too defensive about copyright law11.
 There has been a verycreditable e↵ort by the Internet Archive, a San Francisco NGO, to preserve on-line material for future generations, and it has run an open library project since2006.
 Google scanned many books in university libraries, eventually getting alegal settlement with authors and other interested parties following a long courtcase12.
 As a result, Google Books can make millions of volumes searchable, andsupply the full contents of books that are out of copyright.
 Where a books isstill in copyright, it can let people search and see snippets as a fair use allowedunder copyright law, but it cannot sell an electronic version without the pub-lisher’s agreement.
 (It had wanted to sell electronic versions of everything andsimply pay the publishers a ﬁxed royalty, so as to challenge Amazon’s hold onthe book market.
) The latest development in 2020 is a lawsuit by book publish-ers (including Wiley, the publisher of this book) to stop the Internet Archivelending out electronic copies of books [1000].
 The copyright wars drag on, evendespite the pandemic.
24.
5.
2Who beneﬁts?As I mentioned in section 8.
6.
4, a turning point in the copyright wars came in2005.
 In January of that year, Google’s chief economist Hal Varian addresseda DRM conference in Berlin and asked who would beneﬁt from stronger DRM.
He pointed out that, in classical economic theory, a technical link between twoindustries would usually beneﬁt the more concentrated industry (for example,car makers and car parts).
 But the platform industry was concentrated (thenit was Apple, Microsoft and Sony) while the music industry was less so (fourmajors and many independents): so why should the music industry expect tobe the winners from better DRM? Economic theory says that platform vendorsshould win more.
 The music industry sco↵ed, and yet by the end of that yearthey were hurting – by the fall of that year, they were tearfully lobbying theUK government and the European Commission to ‘do something’ about Apple,such as forcing it to open its FairPlay DRM scheme.
Over the next few years, Hal’s prediction came true.
The music majorslost their market power to ﬁrms like Apple, Amazon and Spotify, while Netﬂixestablished a dominant position in distributing video.
 Music downloading – withor without DRM – changed the structure and dynamics of the music industry.
Bands used to rely on the majors to promote them, but now they can do thatthemselves by giving away their albums on their websites; they always made11When the British Library wanted to archive our NGO web page they wanted us to signcopyright release and indemnity forms, which we couldn’t do for material from third partiesor written by people who’d left or died.
 The only practical way forward is to just put stu↵online and take it down if anyone makes a convincing objection.
 That’s what tech ﬁrms do;legacy organisations often don’t have the conﬁdence.
12The Authors Guild, Inc.
 et al v.
 Google, Inc.
; October 16, 2015 (2d Circuit); November14, 2013 (SDNY).
Security Engineering776Ross Anderson24.
6.
 ACCESSORY CONTROLmost of their money from performances, and now they make more than ever –just as John Perry Barlow had predicted back in 1994.
 In fact, smart bands nowgo with an indie label, as then they’ll get a bigger share of the streaming andother revenues.
 And thanks to the pandemic, there is now a rapidly-growingnew sector of online concerts, where bands perform in empty venues and streamlive to their fans, cutting out both the subscription streaming services and thebig ﬁrms that own the big venues [1685].
24.
6Accessory ControlOne of the most important and rapidly-growing uses of cryptographic mecha-nisms and of rights-management technology generally is in accessory control.
The story starts in 1895 when King Camp Gillette invented the disposablerazor blade, and subsidised razors from later sales of blades.
 Economists call thisstrategy two-part pricing, or even just the ‘razors and blades’ model, in Gillette’smemory.
The tech industry ﬁrst adopted it for games consoles; it was thenadopted by printer makers who subsidise the printers from the ink cartridges,starting in 1996 with the Xerox N24 (see [1822] for the history of cartridge chips).
In a typical system, if the printer senses a third-party cartridge, or a reﬁlledcartridge, it may silently downgrade from 1200 dpi to 300 dpi, or even refuse towork at all.
 In 2003, expiry dates and ink usage controls were added [1207]; andmodern cartridges now limit the amount of ink dispensed electronically ratherthan waiting for it to run out physically.
The latest development is regioncoding: you can’t use US ink cartridges in a recently UK-purchased HP printer.
Other industries are adopting this technology.
 For example, the amount of RAMyou are allowed to use in our lab oscilloscope depends on how much you paidfor it.
After some grumbling, European regulators decided to put up with this,but in the USA, the matter was decided in court.
 The printer maker Lexmarksued SCC, which had reverse-engineered their print-cartridge crypto, allegingviolation of the Digital Millennium Copyright Act.
 Although they won at ﬁrstinstance, they lost on appeal in 2004 [1157].
 In a similar case, Chamberlain(who make garage door openers) sued Skylink (who made compatible openers)and also lost, losing the appeal too in 2004.
 This settled US law in favour ofa free market for cryptologists, which was the position before the DMCA camealong [1647].
 A ﬁrm wanting to control its aftermarket using crypto chips is freeto hire the smartest cryptographers it can ﬁnd to build authentication chipsthat are really hard to hack, while its competitors are free to hire the smartestcryptanalysts they can ﬁnd to try to reverse-engineer them.
There are many, many more examples.
Even things that never used tohave electronics in them, and that don’t need electronics for any purpose, haveacquired chips to enforce predatory business models.
 There are hundreds ofexamples: one that came up in 2020 as I was revising this chapter is their usein water ﬁlters in GE fridges.
 Six months after he bought a ‘smart’ fridge, JackBusch got a demand that he buy another water ﬁlter for $54.
99.
 It turned outthat the ﬁltered water option would turn itself o↵ unless you bought a new ﬁlterevery six months, whether you needed it or not.
 Jack duly ﬁgured out a hackSecurity Engineering777Ross Anderson24.
6.
 ACCESSORY CONTROLand published it [353].
Is accessory control objectionable? The view that I took in the second edi-tion of this book was that of standard economics: depends on how competitivethe markets are.
 If ink cartridges have a high proﬁt margin but the marketfor printers is competitive, competition will push down the price of printers tocompensate for the high-priced cartridges [1942].
 But in many other industriesit might be anticompetitive; it just depends on how concentrated the industryis, and in winner-take-all platform markets it could be particularly objection-able [73].
I have since changed my mind.
 Competition matters, and we’re seeing lessof it as one industry after another adopts software in its products and becomesmore like the software industry, with the tendency to monopoly that we dis-cussed in Chapter 8.
 For example, John Deere now ﬁts its tractors with locksthat limit repairs to authorised dealers, causing great resentment among farmersat having to pay a $230 call-out and $135 an hour for a technician to authorisea spare part [1070].
 The use of cryptographic mechanisms for product tying andbundling is among the anti-competitive factors with which our policymakers arenow realising they have to deal.
 In the case of tractors, a right-to-repair lawmay be one of the necessary mitigations.
Sustainability also matters, and technical tying mechanisms are often aboutshortening product lives, leading to unnecessary consumption.
 Forcing a six-monthly change of water ﬁlter cartridges is a good example; we use ours forabout ﬁve years.
 Such mechanisms also lead to products that are fragile anddi�cult to maintain.
 Another common outcome if you buy a ‘smart fridge’ isthat it will turn into a frosty brick a couple of years later, when the vendor stopsmaintaining the server that it speaks to.
 I will discuss this at greater length insection 28.
5.
The covid pandemic has illustrated other side-e↵ects of accessory control.
Early in the lockdown, some hospitals didn’t have enough batteries for therespirators used by their intensive-care clinicians, now they were being used24 x 7 rather than occasionally.
 The market-leading 3M respirators and thebatteries that powered them had authentication chips, so the company couldsell batteries for over $200 that cost $5 to make.
 Hospitals would happily havebought more for $200, but China had nationalised the factory the previousmonth, and 3M wouldn’t release the keys to other component suppliers.
 Theﬁx in this case was indeed competition.
 Respirators from other suppliers arecheaper and don’t insist on proprietary batteries, while in Southampton, PaulElkington and colleagues at the medical school designed their own respirator,making the design open to everyone in the world who wants to make them [623].
With luck 3M will lose the dominant market position they abused, but therewas a real cost to clinical sta↵ who didn’t have enough personal protectiveequipment in the early months of the pandemic.
 Market-control mechanismscan have implications not just for sustainability tomorrow, but for safety today.
Security Engineering778Ross Anderson24.
7.
 SUMMARY24.
7SummaryThe technical protection of digital content against unauthorised copying is awicked problem both technically and politically.
 It’s di�cult technically becausegeneral-purpose computers can copy bitstrings at no cost, and it’s di�cult politi-cally because rights-management technology has done a lot of collateral damage.
That the music industry itself was one of the casualties may have been just, butdoesn’t solve the continuing problems.
 These are tied up with much broaderand deeper problems of competition, consumer protection and sustainability.
Research ProblemsMany of the tough problems around copyright in 2020 are policy problems ratherthan technical ones.
 If you want to do technical work on information hiding ordigital image forensics, you might read Jessica Fridrich’s books as a startingpoint [724].
For software obfuscation, you might start with the report of a2019 Dagstuhl seminar on the subject organised by Bjorn De Sutter and col-leagues [555].
 One open problem that spans both technology and policy is theprivacy of the anti-cheat engines used in computer games.
 What informationdo they collect from your PC, where do they send it, and is this reasonable? Isit even legal?Further ReadingKahn is, as usual, good historical background reading [1001].
The softwarecopy protection techniques of the PC era are discussed in [829]; there’s a his-tory of pay-TV systems in [1255].
 As for information hiding, there’s a bookby Katzenbeisser and Petitcolas [1023], as well as Jessica Fridrich’s books [724].
The standard reference on game security is by Greg Hoglund and Gary Mc-Graw [912]; see also Je↵ Yan and Brian Randell for the history of computergame cheating [2054, 2056].
For a principled discussion of the policy issues around copyright and open cul-ture, you might start with Pam Samuelson [1646, 1647] and Larry Lessig [1144,1145].
 Then I’d suggest you read up on whatever application areas are rele-vant to you.
 If you’re an academic, you ought to read up about the tragedy ofAaron Swartz – the founder of Reddit who killed himself after putting millionsof scientiﬁc papers online and being hounded by publishers’s lawyers – and thelong-running battles around Sci-Hub, which makes scientiﬁc papers available toall in deﬁance of copyright.
 If you play music for money you may want to followthe tussles around streaming and the antitrust settlement between Live Nationand Ticketmaster.
 If you play music in pub sessions you might be interested inthe controversy around the Irish Music Rights Organisation.
If you’re a lawyer or policymaker, you would do well to talk to NGOs en-gaged on copyright issues.
 Here for example is the view of European DigitalRights (EDRi): “In the digital environment, citizens face disproportionate en-forcement measures from states, arbitrary privatised enforcement measures fromSecurity Engineering779Ross Anderson24.
7.
 SUMMARYcompanies and a lack of innovative o↵ers, all of which reinforce the impressionof a failed and illegitimate legal framework that undermines the relationshipbetween creators and the society they live in.
 Copyright needs to be funda-mentally reformed to be ﬁt for purpose, predictable for creators, ﬂexible andcredible.
”Security Engineering780Ross Anderson